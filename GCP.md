# GCP勉強時のメモ

## 用語
<details><summary>Blobstore</summary>
blob は、データストア サービスのオブジェクトに許可されているサイズよりはるかに大きいサイズのオブジェクトです。blob は、動画や画像などのサイズの大きいファイルを提供する場合や、ユーザーがサイズの大きいデータファイルをアップロードする場合に便利です
</details>

<details><summary>Cloud Trace</summary>
本番環境におけるパフォーマンスの障害検出
分散トレースシステム
アプリ(VM　コンテナ　APP　Engine)からレイテンシデータを収集しクラウドに表示
リアルタイムでパフォーマンス分析をすることができる
要点としてはボトルネックを検出できる（自動検出
</details>

<details><summary>CloudDataLossPrevention</summary>
機密データを自動的に検出して秘匿化する
DLPを使うことでクレジットや氏名、電話番号、身分証明書を秘匿化する
準識別情報とは、部分的であっても特定の個人や非常に小規模なグループを特定する手がかりとなる可能性のあるデータ要素またはその組み合わせのことです。Cloud DLP では k-匿名性、l-多様性といった統計指標を測定することで、データ プライバシーの現状を把握し、それを保護する能力を高めることができます。
</details>


<details><summary>CloudCDN</summary>
Content delivery network
グーグルのネットを使用してユーザーの近くからコンテンツ配信をする
これによりウェブサイトやアプリケーションを高速化させる
コンテンツ配信向け
</details>

<details><summary>Dedicated interconnect</summary>
オンプレミスネットワークとグーグルネットワークを
直接物理的に接続することで大量のデータをネットワークに
転送できます。公共のインターネットより優れている
</details>

<details><summary>フェイルオーバー</summary>
高可用性構成(HA構成)の時に使う
プライマリインスタンス (マスター)とスタンバイインスタンスで構成する
どちらもゾーンを別とするものとし同期レプリケーションをするとする
マスターがゾーンごと落ちてもスタンバイが引きつぐことができ
アプリケーションを持続することができる
この切り替えのことをフェイルーバーという
</details>

<details><summary>HorizontalPodAutoscaler</summary>
水平ポッドオートスケーラー
k8s
ReplicationControllerまたはDeployment, ReplicaSetのPodの数を自動的にスケールします。スケールの判定に利用するメトリクスはCPUやカスタムメトリクスを利用することができます。
Horizontal Pod AutoscalerはKubernetes APIオブジェクトとコントローラとして実装されています。このコントローラは定期的にユーザによって設定されたしきい値とメトリクスの値を比較しReplica数を調整します。
</details>

<details><summary>maxUnavailable</summary>
k8s
maxUnavailable はRolling Update中に無効なPodをどの程度許容するかを指定
</details>

<details><summary>maxSurge</summary>
k8s
Rolling Update中に複製数をどの程度超えていいかを指定
</details>



<details><summary>オペレーション(旧Stackdriver)</summary>
インフラストラクチャとアプリケーションのパフォーマンスをモニタリングして
トラブルシューティングを行い、パフォーマンスを向上させる
主な機能として
Cloud Logging
Cloud Monitoring
Cloud Profiler
がある
Loggingを使う場合は格インスタンスにインストールする必要がある
</details>

<details><summary>ingress</summary>
k8s
クラスタ外からクラスタ内サービスへのHTTPとHTTPSのルートを公開する
Serviceに対して、外部疎通できるURL、負荷分散トラフィック、SSL/TLS終端の機能や、名前ベースの仮想ホスティングを提供するように構成
</details>

<details><summary>Cloud AutoML</summary>
機械学習の知識がかぎれていても使用できる。
グーグルの機械学習機能を元にしてビジネスニーズに合わせ機械学習モデルを
作成し、アプリケーションやウェブサイトを統合する。
導入事例　ディズニーの商品関連検索
</details>

<details><summary>Conmpute Engine</summary>
高性能でスケーラブルな仮想マシン
VMのライブマイグレーション
プリエンプティブルVM
単一テナントノード
永続ディスクHDD　SSD
ローカルSSD（停止するとデータを保持できない)
グローバル負荷分散（複数のリージョンインスタンス)
秒単位課金、確約割引、継続利用割引
一般的に言われているIaaSだと思って良い
オンプレミスからの環境移行はこれが良いとされる
</details>

<details><summary>単一テナントノード</summary>
使用者のワークロードのみに使用される専用Compute Engine サーバー
使用者のワークロード意外に物理サーバーは使われない
CPUメモリなどのスペックが選べる
同一ノードでのインスタンスの共存やインスタンス分離が確実にできる
</details>

<details><summary>App Engine</summary>
フルマネージド型サーバレスなプラットフォームでアプリを構築
一般的な言語(nodejs java ruby C# go python php etc)
カスタムランタイムではDockerコンテナ提供がされ任意のライブラリや
フレームワークをインストール可能
インフラストラクチャは考え無くても使用できる
Cloud Monitoring Cloud Loggin Colud Debugger Error Reporting
などのパフォーマンス、モニタリング、バグを診断修正できる
開発環境、テスト環境、ステージング環境、本番環境をたやすく構築
トラフィック分割によりA/Bテストが容易
SSL/TLS 証明書やファイアウォールを使用して保護できる
アクセスに応じてスケールできるのでリソース不足による障害対策ができる

スタンダード環境:
フレキシブルより細かい自動スケーリング
一日に1GBストレージトラフィック無料
java Python php GOなどといった指定からバージョン指定まで
サンドボックスで生成されるのでOS、ハード、サーバーに依存しない
デメリットとしてローカルファイルシステムに書き込めない
リクエストは60秒でタイムアウト
アプリがアイドル状態だった場合請求料は無い
ネットワークはApp　Engine経由のみ
即時スケーリングを必要とする時使用推奨
ルート権限アクセスできる

フレキシブル環境:
定期的にスケールをする必要がある時使用推奨
サンドボックスでは無い
App Engineのデータストア、Memchach、タスクキューなどの
サービスにアクセス
ネットワークアクセス可能
様々な言語の使用ができる
サードパーティソフトをインストールできる
VMにSSH接続できる
料金はメモリーディスクCPUの使用量から
毎週再起動
ルート権限アクセスできる


制限
スタンダード環境でじっこできるインスタンスに対する同時接続は最大100個
php5.5は60個に制限される
</details>

<details><summary>Migrate for Compute Engine(旧 velostrata)</summary>
稼働中のアプリケーションでも影響を与えることなく移行できる
グーグルクラウドへ移行
オンプレミスのアプリケーションを移行するケース
複数のデータセンター
クラウドに分散された１０００のアプリ
を移行するようなケースに対応できる
組み込みテストで移行後に検証
インテリジェント ストリーミング(アプリ稼働に必要なものから移行する)
予測外が発生してもオンプレミスの高速ロールバック
仕組み
1.クラウドでテスト検証
2.移行ウェーブ作成
3.グーグルクラウドへのワークロードデプロイ
4.バックグランドデータの移行
5.アンプレミスへのステーツフルロールバック(必要時)
</details>

<details><summary>プリエンプティブル仮想マシン</summary>
バッチジョブ、フォールトトレントラントなどと行った
少し起動させたい時に使えるVM
通常のインスタンスより最大で80%の消費を削減する
プリエンプションが発生した場合30秒の猶予が与えられる
プリエンプティブル インスタンスは Compute Engine
の余剰のキャパシティを利用する機能であり
他のタスクがリソースへのアクセスを必要とする場合に、
Compute Engine によって終了(プリエント)される可能性がある

制限
いつプリエントされてもおかしく無い
24時間実行した後は必ずプリエントされる
プリエンプティブルインスタンス は有限compute Engineリソースなので
常に利用できるわけでは無い
ライブマイグレーションできない
サービスレベル契約の対象となら無い
Compute Engineの無料わくに適用されない

</details>

<details><summary>shielded VM</summary>
ルートキットやブートキットによる攻撃対策強化されている
リモート攻撃や権限昇格、内部関係者からの驚異から保護できる
カーネルレベルで改竄されてないことを確認できる
セキュアブートはブートコンポーネントのデジタル証明を検証し
失敗した時自動てブートコンポーネントを停止する
</details>

<details><summary>Bare Metal Soolution</summary>
特別なワークロードの実現ハードウェアの提供
認定されたハードウェア、複雑なライセンス、サポート契約
が必要でクラウド環境へ移行しづらい環境をモダナイズ（近代化）
をすることができる。

</details>

<details><summary>Cloud Storage</summary>
デベロッパーや企業向けの統合型オブジェクトストレージ
四つのストレージクラスが存在する
Multi-Regional 地理的冗長　世界中からのアクセス
Regional 単一リージョン　Compute Engineなどからの頻繁なアクセス
Nealine 月一回アクセス　バックアップ　データ　コンテンツ
Coldline 年一回　アーカイブデータ
使用したいストレージの場所を世界中から選べる（アメリカ　ヨーロッパ等)



</details>

<details><summary>プロジェクト</summary>
クラウドストレージ内のデータは全てプロジェクト内に属する。
一連のユーザー
一連API
APIno請求
認証
モニタリング
で構成され複数のプロジェクトを保持できます。
</details>

<details><summary>バケット</summary>

データを格納するコンテナ
クラウドストレージ内のデータは  
全てバケットに格納する必要がある
入子構造にできない
作成と削除セイゲインがある為バケットを少なく設計することを推奨
バケット作成時にグローバルに一意な名前と地理的ロケーション、ストレージクラスを指定する
作成後ストレージクラスの変更ができる
バケット名とロケーション変更はバケットを削除して再度作成しないとできないバケット名はリダイレクトで使用するのでDNS命名規則に準じる
バケットラベルは仮想マシンインスタンス や永続ディスクなどのリソースと共にバケットをグループ化できるkey-valueです
</details>

<details><summary>オブジェクト</summary>
Cloud Storage　内に保存するここのデータ
オブジェクトデータとオブジェクトメタデータでコンポーネントが構成
オブジェクトデータはCloud Storageに保存するファイル
オブジェクトメタデータはオブジェクトの様々な性質を記述した名前と値のペア集合
オブジェクト名はオブジェクトメタデータとして扱われる(UTF-8)
オブジェクト名に/(スラッシュ)を入れることで階層状ディレクトリ構造の中に保存されているように見えるが実際には階層関係の無いオブジェクトとして認識する
メタデータは作成後に編集できるものとできないもの、表示しかできないものある

Cloud Storageのオブジェクトは複数のバージョンを持つことができる
デフォルトではオブジェクトを上書きすると古いバージョンを削除して新しいバージョンに置き換わる。バケットでオブジェクトのバージョニングを有効にすることで上書きまたは削除が行われても古いバージョンがバケットに残る
バージョンはメタデータに含まれる世代番号によって識別される

固有キーメタデータ
・アクセス制御 (IAM ACL)
・Content-Disposition 転送データ
・Content-Encoding 圧縮型
・Content-language 言語
・コンテンツタイプ ブラウザが読むこむための指標？

</details>

<details><summary>リソース</summary>
Google Cloud 内のエンティティ
プロジェクト　バケット　オブジェクトがリソース

リソース名　（使用はPub/Sub Notifications for Cloud Storage と Identity and Access Managementに限られている)
リソースにはファイル名のような固有名がついている
パケットのリソース名の形式は以下のようになる
`projects/_/buckets/[BUCKET_NAME]`
BUCKET_NAMEにバケットID
オブジェクトリソースだと
`projects/_/buckets/[BUCKET_NAME]/objects/[OBJECT_NAME]`
OBJECT_NAMEはオブジェクトID
リソース名の末尾に付加されるのは#[NUMBER]でオブジェクトの特定世代を表す

</details>

<details><summary>地域的な冗長性</summary>
地理的に冗長なデータは少なくとも100マイル離れている２つ以上の場所に保存されている
マルチリージョンとデュアルリージョンには地理的に冗長と呼べる
天才や災害が発生しても可用性が最大確保できる

</details>

<details><summary>データの不透明性</summary>
オブジェクトのデータコンポーネントはCloud Storageに対して完全に不透明
Cloud Storageは単なるデータの塊として認識されない
</details>

<details><summary>オブジェクトの不変性</summary>
後からプロジェクトに付加や切り捨てなどのオペレートで部分的な変更を加えることはできない
上書きすることはできる
一秒間に一回しか上書きできない(429 Too Many Requestsエラー)

</details>

<details><summary>Cloud Filestore</summary>
フルマネージドファイルストレージ
データ用のファイルシステムインターフェースと共有ファイルシステムを必要とするアプリ向け
ファイルシステムの機能を必要にするときに使用する
Filestore を使用すると、Google Compute Engine や Kubernetes Engine のインスタンスでマネージド NAS（ネットワーク接続ストレージ）を立ち上げ、ネイティブに使用できる
フルマネージメントNoOpsサービス
ファイルの共有はCompute Engine VMにマウント
k8sと統合できるので複数のコンテナから同じ共有データを参照できる
Elastifile(グーグルが買収したNFSサーバー提供会社)を使用するとファイルストレージを柔軟にスケールすることができ、GCPやGUIやAPIベースの制御でクラスタ拡張縮小が可能

上記ではわかりにくいので使用例
レンタリング(共有作業の効率化)
アプリケーションの移行(ファイルシステムの共有)
ウェブコンテンツ管理
メディア処理(大きなメディアファイル共有作業化)
ホームディレクトリ
</details>

<details><summary>ストレージオプション(永続ディスク)</summary>
Compute Engine には、インスタンス向けに複数のストレージ オプションが用意されています

マルチリーダー機能
スナップショット機能
リソースを中断せずにスケール
自動暗号化

ストレージオプション
ゾーン標準ディスク
リージョン永続ディスク
ゾーンSSD永続ディスク
リージョンSSD永続ディスク
ローカルSSD
Coud Storage パケット

ゾーン永続ディスクはインスタンス からアクセスできる
永続ディスク上のデータは複数の物理ディスクに分散(冗長の確保)
永続ディスクはVMとは独立しているのでインスタンスを削除しても保持できる。パフォーマンスはサイズに合わせてスケールされる

リージョン永続ディスク
堅牢なシステム設計をCompute Enigneで実現したい場合はこちらを使う
同じリージョンないに二つのゾーン間でのレプリケーションに対応
アプリレベルでのレプリケーションをする場合は同期レプリケーションを使用する
ゾーンが停止してもフェイルオーバーできる

ローカルSSDはVMインスタンス をホストするサーバーに物理的に接続
高スループット低レイテンシ
インスタンス が停止、削除されるとデータを保持できない
パフォーマンスの向上の代償として可用性、耐久性、柔軟性をある程度トレードオフする
インターフェースをSCSIかNVMeを選択できる(SSD接続するためのインターフェース)
自動的に書き込まれるとき暗号化されるが顧客指定の暗号化は使用きない（グーグル提供のみ)

Cloud StorageバケットはVMインスタンス で利用できる
アプリで低レイテンシの永続ディスク及ローカルSSDが特に必要なければデータを格納できる
データセンターメンテナンス中でもデータの可用性がある
全てのCloudStorageオペレーションに対してチェックサムが計算され読み取ったデータと書き込んだデータが一致する確認が容易
永続ディスクとは異なりインスタンスが存在するゾーンに限定しなくバケットに対して複数のインスタンスからデータを同時に読み書きできる
ファイルシステムとしてインスタンス にCloudeStorageバケットをマウントできる
マウントされたバケットはファイルの読み書きにたいして永続ディスクと同じように機能する
しかしバケットはPOSIXファイルと同等の書き込み制約が無いためブートディスクとして使用できない
さらに同時にデータに書き込んでいる他のインスタンス の重要なデータが上書きされる可能性もある
永続ディスクと同じように顧客指定の暗号鍵でバケット暗号できる

</details>

<details><summary>CloudStorageforFirebase</summary>
Cloud StorageをFirebaseで使用する
コンテンツ（動画画像等)を簡単に保存提供
SDKを使用することでクライアントから直接ファイルのアップロードとダウンロードを行う。ネットワーク接続がよく無い場合、動作が停止したところから再試行できる
個々のファイルやファイル グループごとにアクセス制御を設定できる宣言型セキュリティ言語を備えているため、必要に応じてファイルを公開したり非公開にしたりできる
</details>

<details><summary>CloudBigtable</summary>
大規模な分析ワークロードと運用ワークロードに対応
ペタバイト規模のフルマネージドNoSQL
アドテック(広告)、フィンテック(金融)、lotに最適
プロビジョニングとスケーリングの上限は数百ペタバイト、毎秒数百万のオペレーションを処理する
レプリケーションに
よってリアルタイムアプリの可用性がまし、データ提供や分析の目的に応じてワークロードを分離できる
Hadoop、Cloud Dataflow、Cloud Dataproc
などの一般ビックデータツールと統合でき、オープンソースでHBaseAPIもサポートしている。

財務分析中ら不正パターンを継続的に更新することでリアルタイムのトランザクションと比較する

時系列データ
複数のサーバーにおける時間の経過に伴う CPU とメモリの使用状況など。

マーケティング データ
購入履歴やお客様の好みなど。

金融データ
取引履歴、株価、外国為替相場など。

IoT（モノのインターネット）データ。電力量計と家庭電化製品からの使用状況レポートなど。

グラフデータ
ユーザー間の接続状況に関する情報など。

散在して格納するテーブル
数十億行から数千列の規模にスケール可能
各行の値がインデックスに登録され、行キーとなる
低いレイテンシで単一キーの超大容量を格納するのに向いている
MapReduceオペレーションが理想的なデータソース

ストレージモドエル
Key-Vule
行と列で構成されている
それぞれの行と列が交差する場所はタイムスタンプの異なるセルバージョンを含めることができるため保存されたデータが時間の経過とともにどのように変化されたかが記録できる
データベースはスパースで格納されていないセルが領域を奪うことは無い

全てのクライアントリクエストはフロントエンドサーバーを経由してノードに送信される。これらのノードをタブレットサーバーという
ノードはクラスタとして編成される。
クラスタはCloud Bigtableのインスタンスのコンテナに属している。
ノードはクラスタに対するリクエストを一部処理する。
クラスタにノードを追加することで処理できるリクエストや全体のスループットを増やせる。
レプリケーションを有効にするとクラスタごとに異なる種類のトラフィックを送信することや、一方のクラスタが使用できなかった時にフェイルオーバーできる。
Cloud Bigtableテーブルは連続する行ブロックでタブレットとして共有される。タブレットはHBaseリージョンに相当する。
タブレットはGoogleのファイルシステムである
ColossusにSSTable形式で格納
SSTableは永続的な順序付きの、キーから値への不変マップとなっています。
ここで、キーと値はどちらも任意のバイト文字列です
格タブレットはBigtableノードに関連づけられる
全ての書き込みはSSTableファイルに格納されるだけではなくBigtableに認識されると直ちにColossusの共有ログにも格納され耐久性がます

重要なことは
データはcloud Bigtableノード自体に格納されていないこと
各ノードはタブレットのセット(Colossus)に対するポインタを保持している
これにより以下を実現できる
・ノード間のタウブレット移動が高速になる（ポインタ
変更のみのため)
・Bigtableのノード障害復旧が高速に実行(置換先に新しいノードにメターデータのみを移動するため)
・Bigtableのノードが障害を起こしてもデータは失われない

負荷分散
Bigtabelゾーンはマスタープロセスによって管理される
マスタープロセスはクラスタ内の負荷とデータ量の均衡を図る。マスターはアクセス数の多い大量のタブレットをノード間で半分に分割しアクセスの少ないタブレットを結合する。
特定のタブレットのトラフィックが突出している場合、マスターはそのタブレットを2分割し、その一方を別のノードに移動する。これによりユーザーが手動でタブレットを操作する必要はない
Bigtableで最高パフォーマンスを実現するためには書き込み作業をできるだけ均等にノード間に分散することが重要です。目標を達成するには予測可能な順番に従わない行キーを使用する方法があります。例えばユーザー名はアルファベット順にほぼ均等に分散する傾向があるためユーザー名を行キーの先頭で使用すると書き込みの分散が均等になりやすくなります。
関連する行をグループ化して近くにまとまるようにすると便利です。これにより複数の行を同時に読み取る処理が効率的になります。
例
時間の経過に伴い様々な出いの天気情報データを書くのする場合、データ取集した場所とタイムスタンプを連結したものを行キーとして使用できます（例: WashingtonDC#201803061617）
このような行キーを使用すると１つの場所から得られた全てのデータが行の連続した範囲としてグループ化されます。他の場所については行が異なる識別子で始まります。多数の場所で同じ速度でデータが収集されるため書き込みはタブレット間で均等に分散されます。

Bigtableはアルゴリズムによりデータを自動圧縮する。
圧縮方法は変更することはできない。
ランダムデータはパターン化されたデータ（テキストなど）よりも圧縮効率が低くなる
圧縮は同じ値が互いに近接した場所にある場合動作効率が最も良くなる(同じデータチャンクが格納された行が互いに隣接するように行キーを調整すれば、データを効率的に圧縮できます)


セキュリティ
Cloud Bigtable テーブルへのアクセスは、Google Cloud プロジェクトと、ユーザーに割り当てた Cloud Identity and Access Management 役割によって制御されます。
プロジェクト、インスタンス、テーブルの各レベルでセキュリティを管理できます。Cloud Bigtable では、行レベル、列レベル、セルレベルでのセキュリティ制限をサポートしていません。


1TB未満のソーリューションには向いていない

Bigtabelインスタンスはデータのコンテナです。インスタンには１つ以上のクラスタがあり、別のゾーンの配置されているます。各クラスタには１以上のノードがあります。
テーブルはクラスタやノードではなくインスタンスに属します。インスタンに複数のクラスタがある場合は、レプリケーションを使用します。ここのクラスタにテーブル割り当てはできません。またインスタンス内のクラスタごとに一意のガベージコレクションポリシーを作成することができない。また各クラスタで同じテーブルに異なるデータセットを格納することもできない。

ストレージタイプは永続SSDまたは永続HDDを選択
インスタンス内の全てのクラスタが同じストレージタイプを使用しなければならない

インスタンスを作成するとBigtableはそのインスタンス使用してアプリケーションプロファイルを保存します。レプリケーションを使用する場合アプリプロフィルはアプリケーションがインスタンスのクラスタにどのように接続するかを制御します。レプリケーションを使用しなくともアプリ プロファイルを使用して、アプリケーション単位か 1 つのアプリケーション内の関数単位で、個別の識別子を指定できます。そうすると、アプリ プロファイルごとに個別のグラフを Cloud Console に表示できます。


クラスタは特定のロケーションにあるBigtableサービスを表します。各クラスタは１つのBigtableインスタンス に属し、１つのインスタンには最大で４つのクラスタがあります。アプリケーションがBigtableにリクエストを送信するとそのリクエストはインスタンスのいずれかによって処理される。
各クラスタは１つのゾーンに配置されまています。インスタンスの各クラスタは、それぞれ異なるゾーン内に存在する必要があります。Bigtabel利用可能なゾーンであればどこにでも追加クラスタを作成できます。クラスタが１つしか無い場合はレプリケーションはできない。クラスタを追加すると自動的にレプリケーションを開始する。
アプリケーションが接続するクラスタを選択できるのでトラフィックタイプ別に分離できる。またBigtableがクラスタ間でトラフィックを分散するように設定することもできる。

ノード
インスタンス内の各クラスタには、Cloud Bigtable がデータの管理に使用するコンピューティング リソースが 1 つ以上あります。
bigtableはバックグラウンドでテーブル内の全てのデータを別々のタブレットに分割する。タブレットはノードと同じゾーンにあるディスクにノートは別に格納されます。タブレットは一つのノードに関連づけられる。
役割
ディスク上の特定のタブレットをトラッキングする
受信するタブレットの読み取りと書き込みを処理する
定期的なコンパクションなどのメンテナンスタスクをタブレットで実行する

クラスタにはクラスタの現在のワークロードとクラスタに保存されているデータの量をサポートできるだけのノードが必要になります。十分なノードが供給されない場合受信されたリクエストを処理できずレイテンシが増加します。指標が推奨値と上限を超えた場合はインスタンスにノードを追加する
</details>

<details><summary>Colossus</summary>
Google内部の高い耐久性を持つファイルシステム
Googleデータセンター無いいのストレージデバイスを使用して構築されている
BigtableはHDFSクラスタや他のファイルシステムを稼働する必要はなく、インスタンス がレプリケーションを使用する場合、Bigtableはインスタンに含まれる各クラスタのデータのコピーを1つColossusに保持します。
各コピーは異なるゾーン、リージョンに配置される。
背後で独自ストレージ方式を使用して従来のHDFS3方向レプリケーションによって提供されている耐久性を超えるものを提供している
災害復旧の可能性も考えバックアップも生成している
</details>

<details><summary>Bigtableタブレットサーバ</summary>
Bigtableのテーブルデータを100m~200mbytes程度に分割した「タブレット」を管理するサーバー
一台のタブレットサーバは100個以下のタブレットを保存することができる
</details>

<details><summary>CloudFirestore</summary>
クラウドネイティブなアプリのデータをグローバル規模で保存する。
スケーラブルなリアルタイムデータベース
プロトタイプを迅速で作成
クライアントはFirestoreのデータをリッスンして変更が生じた時にはリアルタイムで通知を受け取ることができる。ネットレイテンシやインターネット接続に関係なく動作する応答性の高いアプリを構築できる。
クラウドホスト型NoSQLデータベース
値に対応するフィールドを含むドキュメントにデータが格納されている。これらのドキュメントはコレクションに格納される。コレクションはドキュメントの編成とクエリに使用できる単なるコンテナ。

データモデル
FireStoreはNoSQLドキュメント試行データベース
一連のキーと値のペアが含まれる。小型ドキュメントの大きなコレクションを格納するために最適化される。
ユーザーは、基盤となるインフラストラクチャ、メンテナンス、アップグレード、高可用性コンポーネントと機能（有効にしている場合）の維持およびサポートについて心配する必要がありません
ドキュメントにはサブコレクションとネストされたオブジェクト格納できる。どちらも文字列などの基本フィールドやリストなどの複雑なオブジェクトを含めることができる。
コレクションとドキュメントはFIrestoreで暗黙的に作成される。ユーザーはデータをコレクションないのドキュメントに割り当てるだけです。

ドキュメント
Firestoreはストレージ単位のドキュメントになります。ドキュメントは、値にマッピングされるフィールドを含む軽量のレコードで各ドキュメントは名前で識別する。
ユーザー alovelace を表すドキュメントは次のようになります。

class alovelace

first : "Ada"
last : "Lovelace"
born : 1815

ブール値、数値、文字列、地理的位置、バイナリ blob、タイムスタンプなど、さまざまなデータ型の値がサポートされています。マップと呼ばれる配列やネストされたオブジェクトを使用して、ドキュメント内のデータを構造化することもできます

ドキュメント内の複雑なネストされたオブジェクトはマップと呼ばれます。たとえば、上記の例のユーザー名をマップで構造化すると、次のようになります。

class alovelace

name :
  first : "Ada"
  last : "LoveLace"
born : 1815

見てわかるように、ドキュメントは JSON によく似ており、実際基本的には JSON と同じです。いくつかの違いはありますが（たとえばドキュメントでは追加のデータ型がサポートされており、サイズは 1 MB までに制限されています）、一般的にドキュメントは軽量の JSON レコードとして扱うことができます

コレクション
ドキュメントはコレクションの中にあります。
コレクションは単なるドキュメントのコンテナ。
ドキュメントはコレクションの中にあります。コレクションは単なるドキュメントのコンテナです。たとえば、users コレクションを作成して、さまざまなユーザーを表すドキュメントを格納できます。

collections_bookmark users

class alovelace

first : "Ada"
last : "Lovelace"
born : 1815

class aturing

first : "Alan"
last : "Turing"
born : 1912

スキーマレスなので各ドキュメントにどのフィールドを入れるか、フィールドにどのデータ型を格納するかは、自由に決めることができます。同じコレクション内のドキュメント全てに異なるフィールドを含めたり、それらのフィールドに異なるデータ型を格納できいる。ただし、複数のドキュメントで同じフィールドとでた型を使用する方がドキュメントのクエリが容易になる。

コレクションにはドキュメントだけが含まれる。コレクションに値を持つ生のフィールドを直接含めることはできず他のコレクションを含めることができない

コレクションないのドキュメントの名前は一意です。
ユーザーIDなどの独自のキーを設定する場合Firestoreの機能を使えばランダムな値を入れることができる。
コレクションを作成削除する必要はなくコレクションないの最初のドキュメントを作成すると作成され、ドキュメントが全てなくなるとコレクションは削除されます。

リファレンス（オブジェクト)
Firestoreの全てのドキュメントはデータベース内の場所によって一意識別されます。コード内でこの場所を参照するにはその場所へリファレンスを作成します。
データベース内の場所を参照する軽量オブジェクトです。そこにデータが存在するかどうかにかかわらず作成することができネットワーク操作は実行されない。コレクションへのリファレンスも作成できる。
便宜上、ドキュメントまたはコレクションへのパスを文字列として指定し、パス コンポーネントをスラッシュ（/）で区切ってリファレンスを作成することもできます

階層データ
Cloud Firestore で階層データ構造がどのように機能するかを理解するために、メッセージとチャットルームを使ったチャットアプリの例を見てみましょう。

さまざまなチャットルームを格納するための rooms と呼ばれるコレクションを作成できます。

collections_bookmark rooms
  class roomA
  name : "my chat room"
  class roomB

...

これでチャットルームができたので、メッセージを保存する方法を指定します。チャットルームのドキュメントには保存したくない場合もあるでしょう。Cloud Firestore 内のドキュメントは軽量にする必要があり、チャットルームには膨大な数のメッセージが格納される可能性があります。ただし、チャットルームのドキュメント内にサブコレクションとして追加のコレクションを作成できます。

サブコレクション
rooms コレクション内のすべてのルーム ドキュメントに、messages というサブコレクションを作成できます。

collections_bookmark rooms
  class roomA
  name : "my chat room"
    collections_bookmark messages
      class message1
      from : "alex"
      msg : "Hello World!"
      class message2
      ...
  class roomB
  ...
コレクショングループクエリを使用すると同じコレクションIDを持つ複数のサブコレクションに対してクエリを実行できる。


</details>

<details><summary>Memorystore</summary>
raidsとMemcached向けのフルマネージドのインメモリデータスタサービス

Memorystore for redis
セルフマネージドredisとの違い
・ニーズに合わせてデプロイ
・驚異的な速度を実現するために容易にスケーリングできる
・可用性と安全性が向上する
・アプリケーションに専念できる
・Redis プロトコルに対応している

主な用途
高速でリアルタイムのデータ処理を必要とする場合
・キャッシュ保存
・ゲーム
・ストリーム処理(lot)

Memorystore for Memcached
Google Cloud 向けのスケーラブルなフルマネージド Memcached サービスです。このサービスはオープンソースの Memcached 上に構築されており、バイナリ プロトコルおよび ASCII プロトコルに準拠しています。このサービスには、すべての言語で標準の OS Memcached クライアント ライブラリを使用してアクセスできるため、コードをほとんどまたはまったく変更せずに、既存のアプリケーションを簡単にリフト＆シフトできます。

高性能でスケーラブルなウェブ アプリケーションでは、多くの場合、低レイテンシと高パフォーマンスを実現するために、分散型インメモリ データストアが使用されます。Memcached は、このようなアプリケーションの構築に使用される一般的な分散型インメモリ Key-Value ストアです。Memcached の一般的な使用例には、参照データのキャッシュ保存、データベース クエリのキャッシュ保存などがあり、一部にはセッション ストアとしての使用例もあります。


</details>

<details><summary>CloudSpanner</summary>
グローバル及リージョナルアプリケーションデータ向けのスケーラブルなマネージドリレーションデータベースサービス
グローバルに分散され、スケーラビリティと強整合性を備えたエンタープライズデータベースサービス
クラウドに特化しており、RDBと非RDBの水平スケーラビリティの利点を持っている。二種類のデータベースの特性を組み合わせることにより業界最高水準となる 99.999% の可用性 SLA、計画的ダウンタイムの排除、エンタープライズ クラスのセキュリティに加え、高性能のトランザクションと、行、リージョン、大陸をまたぐ強整合性を実現しています

使用例は様々であり金融取引からゲーム。Eコマースまで様々

ほとんどのデータベースではスケーラビリティ と生合成のトレードオフは避けられないがSpannerではRDBの構造と非RDBのスケーラビリティ、行、リージョン、大陸をまたいだ外部生合成に支えられることで両方のパフォーマンスを実現している。
使い慣れた業界標準の ANSI 2011 SQL に対応しているため、取得済みの SQL スキルをそのまま業務に活かすことができます

機能
グローバルスケール（大陸にまたがる水平スケール)
多言語対応
フルマネージド
トランザクションの生合成(外部とのトランザクション)
リレーショナルセマンティクス (SQLクエリ等)
エンタープライズクラスのセキュリティ(IAM統合等)
バックアップと復元
高可用性

</details>

<details><summary>CloudSQL</summary>
MySQL、PostgreSQL、SQL Server 用のフルマネージド リレーショナル データベース サービスです。
上限30,000GB

主な機能
・フルマネージド
データベースの信頼性、安全性、スケーラビリティは自動的に確保されるため、アプリケーションに関する作業により多くの時間を費やし、管理に費やす時間を短縮できます。Cloud SQL は、バックアップ、レプリケーション、暗号化、パッチ、容量増加をすべて自動的に行います
・統合
SQL インスタンスには、あらゆるアプリケーションからアクセスできます。App Engine、Compute Engine、Google Kubernetes Engine、自社のワークステーションのいずれからでも、簡単に接続できます。BigQuery を使用して Cloud SQL データベースに直接クエリを行うことで、分析の可能性が広がります

・信頼性
レプリケーションとバックアップを簡単に構成してデータを保護できるうえ、自動フェイルオーバーを有効にしてデータベースの可用性を高めることも可能です。データは自動的に暗号化されます。Cloud SQL は SSAE 16、ISO 27001、PCI DSS v3.0 に準拠し、HIPAA をサポートしています

一般的なユースケース
スケーラブルなDBでコンテナかされたアプリケーションを構築する
Cloud SQL を Google Kubernetes Engine と統合することで迅速な解決とスケーラビリティを実現する

k8s Engineではアプリケーションやサービスのデプロイ、更新、管理が容易になり、アプリケーションの開発とイテレーションを迅速に行うことができます。
SQLを使用するとCloud上のPostgresDBのセットアップや管理運用が容易になります。

</details>

<details><summary>Firebase Realtime Database</summary>
JSONデータのリアルタイムな同期
クラウドホスト型NoSQL
デバイスをまたいだ連携が簡単
サーバー不要のアプリを構築
リアルタイムDBはモバイルSDKとウェブSDKが同梱されているためサーバーを必要とせずにアプリを構築でいる
Cloud　Function for Firebaseを使用してデータベースによってトリガーされたイベントに対応するバックエンドコードを実行することができる
オフラインでの使用に最適
ユーザーがオフラインになると、Realtime Database SDKはデバイス上のローカルキャッシュを使用してデータを表示し、変更を保存します。デバイスがオンラインになるとローカルデータを同期します。
RealtimeDatabaseとFire Authenticationの統合によりデベロッパーは直感的に認証システムを利用することができる。宣言型のセキュリティモデルを使用している

</details>

<details><summary>Cloud Armor</summary>
サービス拒否攻撃やウェブ攻撃からサービスを保護します。
セキュリティポリシーを使用して負荷分散されたアプリケーションを分散型サービス拒否攻撃DDoS攻撃などから保護します。
クロスサイト スクリプティング（XSS）攻撃と SQL インジェクション（SQLi）攻撃を防御
レイヤー 3、4、7 の属性に基づいてトラフィックをフィルタリングするルールで構成されています。たとえば、着信要求の IP アドレス、IP 範囲、国コード、または要求ヘッダーに一致する条件を指定できます
セキュリティポリシーは外部HTTP(s)ロードバランサーの後方にあるバックエンドサービスでのみ使用できる。ロードバランサはプレミアムでもスタンダード階層でも可能。HTTP、HTTPS、HTTP/2、QUICのかくプロトコルは全てサポートされている

バックエンド サービスのバックエンドは、インスタンス グループ内の VM、ゾーン ネットワーク エンドポイント グループ（ゾーン NEG）、インターネット ネットワーク エンドポイント グループ（インターネット NEG）のいずれかとなります。Google Cloud Armor を使用してハイブリッド デプロイまたはマルチクラウド アーキテクチャを保護する場合は、バックエンドはインターネット NEG にする必要があります。
cloudHTTP(s)負荷分散は、Googleの世界中の接続拠点でGoogleネットワークのエッジに実装されています。
プレミアム階層では外部HTTP(s)ロードバランサに向けられたユーザートラフィックはユーザーに最も近いPOPに入ったあとGoogleのグローバルネットワークで負荷分散されて十分な容量がある最も近いバックエンドに送られる。スタンダート階層ではユーザートラフィックはGoogle cloude デプロイをデプロイしたリージョンのピアリング、ISP、トランジットネットワークを介してGoogleネットワークに転送される。
セキュリティーポリシーを使用するとGoogle Cloude Edgeの外部HTTP(s)ロードバランサへのアクセスを着信トラックフィックのソースにできるだけ近い場所で許可または拒否をします。これによりVPCネットワークへの侵入を阻止します。

機能
Google Cloud Armor セキュリティ ポリシーを 1 つ以上の HTTP(S) 負荷分散バックエンド サービスに関連付ける機能。
複数のルールが設定されている場合は、優先度（評価順序）を指定します。
403、402、502エラーコードを表示する拒否ルールを設定
IPアドレス/CIDRの拒否許可リストによって送信元アドレスまたはCIDR範囲から外部HTTP(s)ロードバランサーへの拒否許可設定が行える
拒否許可リストはどちらもiPv4アドレスiPv6アドレスがサポートされている
ルール言語は様々言語を提供している。
着信要求の地域コードに基づいてリクエストを拒否または許可する機能
</details>

<details><summary>CloudCDN</summary>
世界中のユーザーにウェブコンテンツや動画コンテンツを素早く配信できる。
CloudCDNではエッジキャッシュがほぼ全ての主要なエンドユーザーのISPとグローバルにペアリングしている。世界中のユーザーにも接続性を提供できる。エニーキャストアーキテクチャによりお客様のサイトに単一なグローバルIPアドレスが割り当てられる。
CDNはグーグルで開発されたプロトコルHTTP/2やQUICなどに対応しているため従来のパフォーマンスを改善する。
CDNはCloud　Monitoring　Cloud　Loggingと緊密に統合されているため詳細なレイテンシの指標を使用できたり、可視性を実現する。または未加工のHTTPリクエストのログも利用できる。Cloude StorageやBigQueryに数回のクリックでログをエクスポートすることで分析も容易。
カスタム送信元機能によりオンプレミスや他のクラウドでのコンテンツをグーグルの分散型エッジキャッシングインフラストラクチャを介して配信できる
エニーキャストIP
TLS（SSL）証明が無料で提供
証明付きCookiesとURL
</details>

<details><summary>CloudDNS</summary>
信頼性と復元性に優れたレイテンシDNSサービスをグーグルネットワークから提供
Cloud DNS は、一般公開ゾーンと限定公開マネージド DNS ゾーンの両方を提供します。一般公開ゾーンは公共のインターネットに公開され、限定公開ゾーンは指定した 1 つ以上の VPC ネットワークからのみ公開されます。

一般的なコンセプト
DNSの基本コンセプトと同じ

サーバーの種類
・権威サーバー
DNS名レコードを格納しているサーバー。それ以外のサーバーにはキャッシュファイルが作成され、ドメインのクエリ結果が格納される。
・復帰リゾルバ
名前解決のために権威サーバーまたは他のサーバーにクエリを送信するサーバー。
例えば google.comという名前を解決する場合復帰リゾルバが「.」(DNSルートゾーン)の権威サーバーを特定する。次に「.com」の権威ネームサーバーに問合せを行います。最後にgoogle.comの権威ネームサーバーに問合せを行いAレコードのrdataをクライアントに返します。リゾルバは上位ネームサーバーにあるゾーンNSレコードにしたがって別のネームサーバーを参照し、最終的にゾーン情報を保持しているネームサーバまたはそのゾーンの権威サーバーに到達します。

ゾーン
・一般公開ゾーン
インターネットに一般公開されるゾーン
・限定公開ゾーン
公共のインターネットから検索できないゾーン
・委任サブゾーン
ゾーンのオーナーがNSレコードを使用してサブドメインを別のネームサーバーに委任できます
・スプリットホライゾンDNS
同じドメインに２つのゾーンを作成し１つを内部ネットワーク用に、もう一つを外部ネットワーク用に使用する状況を表す。スプリットホライゾンにすることで同じ名前の問合せに対してその紹介元に応じて異なる情報を返すことができます。例えば、クエリの送信元が開発用のネットワークの場合は開発ステージング版のアプリを、クエリの送信元が公共のインターネットの場合は本番環境一般公開版のアプリを返すことができる

レコード
DNSリソースとドメイン名のマッピング
個々の DNS レコードは、タイプ（名前と番号）、有効期限、タイプ固有のデータから構成されます
よく使用されるレコード
・A: ホスト名をIPv4アドレスにマッチングします
・AAAA: ホスト名をIPv６アドレスにマッチングします
・CNAME: エイリアス名(別名)を指定します。
・MX: メールサーバーへのリクエストルーティングで使用する
・NS: DNSゾーンを権威サーバーに委任します
・PTR: IPアドレスに対応する名前を定義する
・SOA: start of authority ゾーンのプライマリネームサーバーと管理者の指定に使
用 (ドメインのヘッダーみたいなもの)
・NS: ドメインとそのドメインのDNSサーバーを指定する
レコードセット
名前とタイプが同じでデータ値が異なるセット。
レコードを作成する時に同じ名前とタイプが存在するとそのセットにレコードを追加する
例
DNS 名	型	TTL（秒）	データ
db-01.dev.gcp.example.com	A	50	10.128.1.35
db-01.dev.gcp.example.com	A	50	10.128.1.10

</details>

<details><summary>CloudLoadBalancing</summary>
ユーザートラフィックをアプリケーションの複数にインスタンスに分散する。
負荷分散機能として以下の様なものがある
・フロントエンドとして機能する単一の IP アドレス
・バックエンドのインテリジェントな自動スケーリング
・ユーザーがインターネットからアプリケーションにアクセスしたときの外部負荷分散
・クライアントが Google Cloud 内にある場合の内部負荷分散
・アプリケーションが 1 つのリージョン内で使用できる場合のリージョン負荷分散
・世界各地でアプリケーションを利用できる場合のグローバル負荷分散
・パススルー負荷分散（ダイレクト サーバー リターン（DSR）またはダイレクト ルーティングもご覧ください）
・プロキシベースの負荷分散（パススルーの代わりとして）
・IP アドレス、TCP ポート、UDP ポートなど、ネットワークとトランスポート層プロトコルのデータに基づいてトラフィックを誘導するレイヤ 4 ベースの負荷分散
・HTTP ヘッダーやユニフォーム リソース識別子などの属性に基づいてコンテンツ ベースのルーティング決定を追加するレイヤ 7 ベースの負荷分散
・キャッシュに保存されたコンテンツ配信用Cloud CDNとの統合


種類
https://cloud.google.com/load-balancing/docs/load-balancing-overview
参照

グローバル負荷分散とリージョン負荷分散
バックエンドが複数のリージョンに分散しており、ユーザーが同じアプリケーションとコンテンツにアクセスする必要があって、単一のエニーキャスト IP アドレスを使用してアクセスを提供する場合は、グローバル負荷分散を使用します。グローバル負荷分散は、IPv6 終端も提供します。

バックエンドが同一のリージョン内にあり、IPv4 終端のみが必要な場合は、リージョンの負荷分散を使用します。

外部ロードバランサは、インターネットからのトラフィックを Google Cloud の Virtual Private Cloud（VPC）ネットワークに配信します。グローバル負荷分散では、Network Service Tiers のうちプレミアム階層を使用する必要があります。リージョン負荷分散では、スタンダード階層を使用できます。

内部ロードバランサは、Google Cloud 内部のインスタンスにトラフィックを分散します。

トラフィックの種類
・HTTP、HTTPSトラフィックには次の分散を使用
  ・外部HTTP(S)負荷分散
  ・内部HTTP(S)負荷分散
・TCPトラフィックの負荷分散には次の分散を使用
  ・TCP負荷分散
  ・ネットワーク負荷分散
  ・内部TCP/UDP負荷分散
・UDPトラフィックの負荷分散には次の分散を使用
  ・ネットワーク負荷分散
  ・内部TCP/UDP負荷分散

バックエンドリージョン
内部TCP/UDP、内部HTTP(S)ロードバランサーの全てのバックエンドはバックエンドサービスと同じVPCネットワーク及リージョンに存在する必要があります。バックエンドサービスも転送ルールと同じリージョン及VPCネットワークに存在する必要がある。

外部 HTTP(S) ロードバランサ、SSL プロキシ ロードバランサ、TCP プロキシ ロードバランサは、プレミアム階層を利用しているならバックエンドはどのリージョンでもVPCネットワークでも構わない。スタンダードの場合バックエンドは転送ルールと同じリージョンに存在しなければならないがどのVPCネットワークでも良い。

</details>

<details><summary>GFE</summary>
ロードバランサの基盤となるテクノロジー
Google　フロントエンド
googleの拠点PoPにあるソフトウェア定義の分散システム
他のシステムやコントロールプレーンと連携してグローバル分散の実行をする

サービスをインターネット上で利用可能にするには、それを Google Front End（GFE）と呼ばれるインフラストラクチャ サービスに登録する必要があります。GFE は、すべての TLS 接続が、正しい証明書を使用し、完全な前方秘匿性のサポートなどのベスト プラクティスに従って終端されることを保証します。加えて、GFE は、サービス拒否攻撃に対する防御（詳細は後述）を適用します。その後で、GFE が前述の RPC セキュリティ プロトコルを使用してサービスにリクエストを転送します。

実際には、外部に公開する内部サービスでは、GFE がスマートなリバース プロキシ フロントエンドとして使用されます。このフロントエンドは、パブリック DNS 名のパブリック IP ホスティング、サービス拒否（DoS）攻撃に対する防御、TLS 終端を提供します。GFE は、他のサービスと同様のインフラストラクチャ上で動作するため、着信リクエストの量に合わせてスケーリングできます。
</details>

<details><summary>Andromeda</summary>
ロードバランサの基盤となるテクノロジー
Google Cloudのソフトウェア定義のネットワーク仮想化スタック

</details>

<details><summary>Maglev</summary>
ロードバランサの基盤となるテクノロジー
ネットワーク負荷分散用の分散システム
</details>

<details><summary>Envoyプロキシ</summary>
ロードバランサの基盤となるテクノロジー
クラウドネイティブアプリ用に設計されたオープンソースのエッジ及サービスプロキシ
</details>

<details><summary>CloudNAT</summary>
GCPマネージド高性能ネットワークアドレス変換
外部IPアドレスのないGoogleCloudVMインスタンスと非公開のGoogleK8sEngineクラスタがパケットをインターネットに送信し応答する応答パケットを受信できる様になる。

アーキテクチャ
CloudNATは分散型ソフトウェア定義のマネージドサービスです
プロキシVMやプロキシサーバーに依存しません
CLoudNATはVPCネットワークを成立させるためにAndromedaを設定し、外部アドレスのないVMのソースネットワークアドレス変換SNATを提供します。確立された受信応答パケットの宛先ネットワークアドレス変換DNATも提供します。

利点
VM事に外部IPアドレスを持つ必要がなくなる。
Cloud NAT は、使用する NAT IP アドレスの数を自動的に調整し、自動スケーリングが有効されたものを含め管理対象インスタンスグループに属する VM をサポートします
Compute Engine 仮想マシン（VM）と Google Kubernetes Engine（コンテナ）の両方をサポートしています。

</details>

<details><summary>NetWorkIntelligenceCenter</summary>
クラウド内のネットワークについて可視性を提供し事前検証をする
モニタリングによってトラブルシューティングの労力を減らしセキュリティを高める
ネットワーク障害やパフォーマンス問題防止を実現
ネットワーク トポロジ全体とグローバル ネットワークの分析情報を併せて可視化することで、デプロイとトラフィック フローを簡単に把握
</details>

<details><summary>NetWorkServiceTiers</summary>
プレミアムティア
Googleのグローバルネットワークを使用して高いネットワークパフォーマンスを提供

スタンダードティアがある
他のクラウドプロバイダと同様のパフォーマンスでコスト削減

プレミアムにする場合パフォーマンス、信頼性、グローバルな展開、ユーザー エクスペリエンスを重視する時に使用する
スタンダードはネットワークパフォーマンスがある程度気にしなくてもいい時

プレミアムはグローバル負荷分散機能が使用できる
単一のエニーキャストIPv4IPv6の管理が容易
リージョンの枠を超えてシームレスに拡張し他のリージョンんいオーバーフローまたはフェイタルオーバーすることができる

スタンダードはマルチリージョンのデプロイが必要な場合はプレミアムより管理が複雑になりがちになる
</details>


<details><summary>Cloud Logging</summary>
ログは主にプロジェクトに関連付けられる
組織、フォルダ、請求アカウントなどの他のリソースにログが存在する場合もある
ログビューアは１つのプロジェクトしかログが表示されないがLogging APIを使用sルウことで複数のログを読み取ることができる。

ログエントリ
ログエントリで送受信するものはメッセージやペイロードよ呼ばれ単純な文字列やオブジ
ェクトデータの場合もあります。
Cloud EngineやBigQueryなどの定期的ログエントリやColoudオペレーションスイートをAWSに接続したこと、LoggingエージェントをVMインスタンス にインストールした場合、entries.writeメソッドをよびたした場合もログエントリが生成される

ログ
ログエントリがなければログは存在しない。
ログはCloufリソースないのログエントリの名前つけコレクション。
各ログエントリにはログの名前が記録されている。
ログ名はsyslogやcompute.googleapis.com.activitiyの様にログライターを含む構造化された名前もある。

保持期間
保持期間が経過するとエントリは削除されます。
さまざまなタイプのログの保持期間は、Logging 割り当てと上限にリストされています。
一部のログの保持期間を構成できる。
ログうのバックアップはCloud Loggingの外部でログをエクスポートする

モニタリング対象リソース
各ログエントリには、モニタリング対象リソースの名前など、ログの作成元が記録されます。たとえば、個々の Compute Engine VM インスタンス、個々の Amazon EC2 VM インスタンス、データベース インスタンスなどです。

クエリ
クエリは、Loggin クエリ言語のフィルタ式。
ログビューアや Logging API でログエントリを選択するときに使用されます。たとえば、特定の VM インスタンスで発生したログエントリや、特定の期間に受信した特定の重要度のログエントリを選択できます。

ログルーター
監査ログ、プラットフォーム ログ、ユーザーログを含むすべてのログは、Cloud Logging API に送信され、ここでログルーターを通過します。ログルーターは、各ログエントリを既存のルールと照合して、取り込むログエントリ、エクスポートに含めるログエントリ、破棄するログエントリを決定します。

シンクを使用してエクスポート
loggingが受信したログエントリはCloud Storageのバケットや、BigQueryデータセット、Pub/Subトピックにエクスポートできる。
エクスポートする際にはシンクを構成する。これによりログを受信しながらログエントリをエクスポートできる。

ログへのアクセス権
IAMを利用して制御できます。
Cloud IAM 閲覧者の役割を持つメンバーは、大半のログを読み取ることができます。データアクセス監査ログまたはアクセスの透明性ログを読み取るには、メンバーに Cloud IAM オーナーの役割または特別な権限を持つカスタム役割が必要です。
</details>

<details><summary>CloudMonitoring</summary>
アクセス制御
IAMの役割と権限を使用してワークスペースのモニタリングデータへのアクセスを制御する

VPCSeviceControls
IAMni加えてVPC Service Controlsを使用して、モニタリングデータへのアクセスをさらに制御できます。
VPC Service Controls により、Cloud Monitoring のセキュリティを強化して、データ漏洩のリスクを低減できます。VPC サービス制御を使用すると、境界の外部から発生するリクエストからリソースとサービスを保護するサービス境界にワークスペースを追加できます。


Monitoring を使用するには、該当する Cloud IAM 権限がワークスペースに付与されている必要があります。
一般に、API の各 REST メソッドには権限が関連付けられているので、特定のメソッドを使用するには、それに関連付けられている権限が必要です。権限はユーザーに直接付与されるのではなく、役割を通して間接的に付与されます。

モニタリング
・モニタリング閲覧者
Cloud　ConsoleとAPIでモニタリングに対する読み取り専用アクセス権を付与
・モニタリング編集者
Cloud　ConsoleとAPIでモニタリングに対する読み書き専用アクセス権を付与
ワークスペースにモニタリングデータを書き込むことができる
・モニタリング管理者
Cloud Console で Monitoring に完全アクセスできる
・モニタリング指標の書き込み
モニタリングデータをワークスペースに書き込むことを許可します。Google Cloud Console で Monitoring へのアクセスを許可しません。サービス アカウント用。

あとは
アラートポリシー
ダッシュボード
通知チャンネル
サービスモニタリング
稼働時間チェック構成
の閲覧者権限と編集者権限

Google Cloud
・プロジェクト閲覧者
Google Cloud Console と API で Monitoring に対する読み取り専用アクセス権を付与する
・プロジェクト編集者
Google Cloud Console と API で Monitoring に対する読み取り / 書き込みアクセス権を付与する
・プロジェクトオーナー
Google Cloud Console と API で Monitoring への完全アクセス権を付与する

カスタム役割
権限リストを独自にカスタム役割を作ることができる

API権限
様々なので省略

Monitoring のコンソール権限
Console の Monitoring の各機能には、機能の実装に使用する API の権限が必要
とえば、グループを参照するには、グループやグループ メンバーに適用される list および get メソッドに関する権限が必要

完全な読み取り専用アクセス	roles/monitoring.viewer 役割に含まれる権限のセット	プロジェクト1（ワークスペース内)
Console への読み書きアクセス	roles/monitoring.editor 役割に含まれる権限のセット	プロジェクト1
Console への完全アクセス	roles/monitoring.admin 役割に含まれる権限のセット
プロジェクト1


</details>

<details><summary>ワークスペース</summary>
ワークスペースは、1 つ以上の Google Cloud プロジェクトまたは AWS アカウントに含まれるリソースをモニタリングするためのツールです。各ワークスペースには、Google Cloud プロジェクトや AWS アカウントなど、1～100 個のモニタリング対象プロジェクトを作成できます。ワークスペースの数に制限はありませんが、Google Cloud プロジェクトと AWS アカウントを複数のワークスペースでモニタリングすることはできません。

ワークスペースは、モニタリング対象プロジェクトから指標データにアクセスしますが、指標データとログエントリは個々のプロジェクトに残ります。

ホスト プロジェクト
すべてのワークスペースには、ホスト プロジェクトがあります。ワークスペースの作成に使用した Google Cloud プロジェクトが、ワークスペースのホスト プロジェクトです。このワークスペースの名前が、ホスト プロジェクトの名前となります。次の図は、A という名前のワークスペースを示しています。ホスト プロジェクトには、ダッシュボード、アラート ポリシー、稼働時間チェック、通知チャネル、グループ定義の設定内容がすべて保存されます。

モニタリング対象プロジェクト
ホスト プロジェクトだけをモニタリングする場合は、新しい空白の Google Cloud プロジェクトを使用してワークスペースをホストしてから、モニタリングするプロジェクトと AWS アカウントをワークスペースに追加することをおすすめします。この方法を使用すれば、ホスト プロジェクトと Workspace の名前を自由に選択でき、ワークスペース間でモニタリング対象プロジェクトを柔軟に移動できます

</details>

<details><summary>KubernetesEngineMonitoring</summary>
Google Kubernetes Engine（GKE）には、Cloud Monitoring と Cloud Logging のネイティブ統合が含まれています。GKE クラスタを作成すると、Kubernetes Engine Monitoring がデフォルトで有効になり、Kubernetes 専用のモニタリング ダッシュボードが作成されます。
Kubernetes Engine Monitoring を使用すると、Cloud Logging がアプリケーション ログを収集するかどうかを制御できます。また、Cloud Monitoring と Cloud Logging の統合を完全に無効にすることもできます。
</details>

<details><summary>ContainerRegistry</summary>
非公公開コンテナイメージレジストリ
DockerイメージマニフェストV2とOCIイメージをサポートしている
多くのユーザーはDocker公開イメージを保存するための中央レジストリとしてDockerhubを使用しますがイメージへアクセスするためにはContainer Registry などの非公開レジストリを使用する必要があります

セキュアな HTTPS エンドポイントを使用して Container Registry にアクセスできるため、あらゆるシステム、VM インスタンス、所有のハードウェアからイメージを push、pull、管理することが可能です。さらに、Docker 認証ヘルパー コマンドライン ツールを使用して、Docker を Container Registry で直接認証するように設定することもできます。
</details>

<details><summary>CloudSourceRepositories</summary>
無制限のプライベートGitリポジトリー
GitHubやBitbucketからリポジトリをコードミラーリングして
コード検索、閲覧診断の協力な機能を使用できるます。
継続的にインテグレーションが統合され、pushするとCloudBuildでビルドとテストが自動的に行われる様にトリガーできます。
コード検索早い
本番環境でデバックできる

</details>

<details><summary>BigQuery</summary>
サーバレス
サーバーレスのデータウェアハウジングはgoogleリソースのプロビジョニングを任せられるため、お客様はインフラストラクチャのアプデートやセキュリティ保護に労力を使う必要がなくなるる

リアルタイム分析
高速ストリーミング挿入 API は、リアルタイム分析の強力な基盤となります
Pub/Sub と Dataflow を活用してデータを BigQuery にストリーミングすることもできます


追加料金も設定も不要
BigQuery では、複数のロケーションをまたいで高耐久性ストレージが複製されることで高可用性が確保されます。
これらの操作は透過的かつ自動的に実行されます。
追加料金や追加設定は必要ありません。

SQL
ANSI:2011 に準拠した標準の SQL 言語をサポートしている
無料の ODBC ドライバと JDBC ドライバを提供している

連携
Cloud Storage
ParquetやORC のオープンソース ファイル形式
Bigtable、Cloud SQLドライブのスプレッドシートの外部データソース
を、データを移動せずに処理できます


データ ウェアハウスとデータレイクの集約化
Storage API を使用して BigQuery でオープンソースのデータ サイエンス ワークロード（Spark、TensorFlow、Dataflow、Apache Beam、MapReduce、Pandas、scikit-learn）を直接実行できます。Storage API は、はるかに単純なアーキテクチャでデータ移動も少なく、同一データの複数のコピーを持つ必要もありません。

自動バックアップ
BigQuery では自動的にデータが複製され、変更履歴が 7 日間保持されるので、異なる時点のデータを簡単に復元したり比較したりできます。

地理空間データ型と関数
BigQuery GIS では、WKT や GeoJSON 形式の任意の点、線分、ポリゴン、マルチポリゴンの SQL サポートを提供しています。これにより地理空間分析を簡素化したり、位置情報に基づくデータを新たな方法で表示したりできます

BigQuery Data Transfer Service
あらかじめ設定されたスケジュールに基づいて Google マーケティング プラットフォーム、Google 広告、YouTube、パートナーの SaaS アプリケーションなどの外部データソースから BigQuery に自動的にデータを転送するフルマネージド サービスです。Teradata や Amazon S3 から BigQuery へのデータ転送も簡単に行えます

ビッグデータ エコシステムの統合
BigQuery では、Dataproc と Dataflow を介して Apache のビッグデータ エコシステムと統合できます。これにより、Storage API を使用して、既存の Hadoop、Spark、Beam のワークロードから BigQuery のデータを直接読み書きできるようになります

ペタバイト規模のスケーリング

料金モデル
従量制の場合は、実際に使用したストレージやコンピューティングに対してのみ料金が発生します。大容量をご利用のお客様や企業のお客様は、定額料金の予約ができるタイプをお選びいただくことで、料金の予測やワークロード管理がシームレスに行えます。

データ読み込み
Data Transfer Service（DTS）を使用して、数百もの一般的な SaaS ビジネス アプリケーションから BigQuery に無料でデータを自動的に移動したり、Cloud Data Fusion、Informatica、Talend などのデータ統合ツールを活用したりできます

プログラムによる操作
BigQuery に備わっている REST API を使用すると、プログラムによるアクセスやアプリケーションの統合が容易になります。また、Java、Python、Node.js、C#、Go、Ruby、PHP の各言語でクライアント ライブラリが提供されています。さらに、ビジネス ユーザーの方は、Google Apps Script を使ってスプレッドシートから BigQuery にアクセスできます。

公開データセット
Google Cloud 一般公開データセットは、さまざまな業界向けに需要の多い、100 を超える一般公開データセットの強力なデータ リポジトリを提供しています。Google では、すべての一般公開データセットに無料ストレージを提供していて、お客様は 1 か月あたり最大 1 TB のデータを無料でクエリできます。
例えばGitHubのものを使えば2億行からコミットの賢明で多いものランキングが出せたりする

商用データセット
さまざまな商用データ プロバイダが提供データを BigQuery や Cloud Storage で直接ホストしています。つまり、Google Cloud のいずれかのパートナーからライセンスを取得すると、すぐにデータにアクセスして処理できるようになります。データを保存または移動する必要はありません。
例えば天気やニュース、住宅価格とうさまざまなデータが共有できる

</details>

<details><summary>Dataflow</summary>
水平自動スケーリング

バッチ処理に適した、柔軟なリソース スケジューリング料金
深夜のジョブなど、スケジュールに柔軟性があるジョブの処理には、フレキシブル リソース スケジューリング（FlexRS）をお使いください。低料金のバッチ処理が可能です。このようなフレキシブル ジョブはキューに入り、6 時間以内に確実にキューから取り出されて実行されます。

統合されたストーリーむデータ処理とバッチデータ処理

処理を実行するリソースの自動プロビジョニング

統合されたストリーミング モデルとバッチ プログラミング モデル

ユースケース
・ストリーム分析
DataFlow、Pub/Sub、BigQueryの自動スケーリングインフラテクチャ上に構築された環境で変動するリアルタイムのデータボリュームを取り込み処理、分析し、プロビジョニングできる様にします。

・センサーとログデータ処理
デバイスのグローバルなネットワークからビジネスに有用な分析情報を導き出すインテリジェットなlotプラットフォーム

・リアルタイムAI
DataFlowによりGoogle Cloud の AI Platform と TensorFlowExtended（TFX）にストリーミング イベントが送信されます。これにより、予測分析、不正行為検出、リアルタイム パーソナライズなどの高度な分析ユースケースが可能となります。TFX は、分散データ処理エンジンとして Dataflow と Apache Beam を使用し、ML ライフサイクルの複数の段階を実現します。Kubeflow パイプラインを通じて、CI/CD for ML ですべてサポートされています。

</details>

<details><summary>FlexRS</summary>
高度なスケジューリング技術、Dataflow Shuffle サービス、プリエンプティブル仮想マシン（VM）インスタンスと通常の VM の組み合わせを使用することで、バッチ処理コストを削減します
</details>

<details><summary>Cloud Pub/Sub</summary>
イベントを処理するサービスとイベントを生成するサービスを切り離す非同期メッセージングサービス

・トピック: パブリッシャーがメッセージを送信する名前付きのリソース。
・サブスクリプション: 特定の単一のトピックからサブスクライブするアプリケーションに配信されるメッセージのストリームを表す、名前付きのリソース。
・メッセージ: パブリッシャーがトピックに送信し、最終的にはサブスクライバーに配信されるデータ。データと属性を組み合わせることもできます。
・メッセージ属性: パブリッシャーがメッセージに対して定義できる Key-Value ペア。たとえば、キー iana.org/language_tag、値 en をメッセージに付加すれば、英語圏のサブスクライバー向けメッセージとして識別できるようになります。

パブリッシャー アプリケーションによって、メッセージが作成され、トピックに送信されます。サブスクライバー アプリケーションによってトピックに対するサブスクリプションが作成されて、メッセージが受信されます。 通信は 1 対多（ファンアウト）、多対 1（ファンイン）、多対多にできます。

つまり
パブリッシャー→メッセージ→トピック→サブスクラクション→メッセージ→サブスクレイバー

ユースケース

・ネットワーククラスタでのワークロードバランス調整
Google Compute Engine インスタンスなど、複数のワーカー間で、タスクの大規模なキューを効率的に分配できます
・非同期ワークフローの実装
順序処理アプリケーションによってトピックに順序を設定し、そこから 1 つ以上のワーカーによって処理できるように設定できます
・イベント通知の配信
ユーザーからの登録を受け付けるサービスで、新規ユーザーが登録するたびに通知を送信することや、ダウンストリーム サービスがイベントの通知を受け取るようにサブスクライブすることができます
・分散キャッシュ更新
アプリケーションで無効なイベントをパブリッシュし、変更されたオブジェクトの ID を更新できます
・複数のシステムへのロギング
Google Compute Engine インスタンスでモニタリング システムにログを書き込み、データベースとして後で照会したりできます
・さまざまなプロセスまたはデバイスからのデータストリーミング
クラウドにホストされているバックエンド サーバーに人感センサーからデータをストリーミング
・信頼性の向上
シングルゾーンの Compute Engine サービスが、別のゾーンやリージョンで発生した障害から回復するために共通のトピックにサブスクライブして追加的なゾーンでの処理を遂行できます

Cloud Tasks か Pub/Sub かの選択
主な違い
Pub/Subっは、イベントのパブリッシャーとそれらのイベントサブスクレイバーを分離することを目的としているだけでパブリッシャーはサブスクライバーについて理解している必要はありません。そのため、Pub/Subではパブリッシャーは配信を保証すること以外にメッセージ配信を制御できません。この様に暗黙的な呼び出しをサポートします。
CloudTasksはこれと反して明示的に呼び出しを行ってパブリッシャーが実行を完全制御できる様にすることを目的にしています。パブリッシャーは書くメッセージが配信されるエンドポイントを指定します。
全体的にタスクのプロデューサーが特定のWebhookまたはリモートプロシージャコールの実行タイミングを延期または制御する必要があるユースケースに適している。Pub/Sub は、実行に対する制御がある程度制限される、一般的なイベントデータの取り込みと配信パターンに適しています。

</details>

<details><summary>DataProc</summary>
クラウド上で高速簡単かつ安全にオープンソースデータを分析
主な機能
・自動クラスタ管理
・OSSジョブのコンテナ化
Proc上にOSSジョブ(Apache Spark)を構築するとk8sを使ってそれらを素早くコンテナ化する。GKEクラスタがあればどこでもデプロイできる
。
・エンタープライズセキュリティー
Procクラスタを作成する時にセキュリティ構成を追加することでerberos による Hadoop セキュアモードを有効にできます。また、Dataproc でよく使用されている Google Cloud 固有のセキュリティ機能には、デフォルト保存時暗号化、OS ログイン、VPC Service Controls、顧客管理の暗号鍵（CMEK）などがあります

ユースケース
・Hadoop及Sparkクラスタをクラウドに移行する。
企業は、既存のオンプレミスの Apache Hadoop および Spark のクラスタを Dataproc に移行することでコストを管理し、柔軟なスケーリングを活用しています。Dataproc では、自動スケーリングによってあらゆるデータ処理ジョブや分析処理ジョブをサポートできる、フルマネージドの目的に特化したクラスタを利用できます。

・Dataprocのデータサイエンス
目的に特化したDataproc クラスタを起動して理想的なデータ サイエンス環境を構築します。Apache Spark、NVIDIA RAPIDS、Juypter ノートブックなどのオープン ソース ソフトウェアと Google Cloud AI サービスおよび GPU を統合することで、機械学習と AI の開発を加速できます。
</details>

<details><summary>GoogleBigQueryDataTransferService</summary>
Google BigQuery へのデータの移動を自動化するマネージド サービスです。そのため、1 行もコードを書くことなく分析用のデータ ウェアハウス基盤を構築できます


</details>

<details><summary>CloudDataTransfer</summary>
Cloud Storaage意外に使うかもしれない時はこっちで
Storage一択ならTransferServiceだと思う
ユースケース
　・データセンターの移行（オンプレミスの移行)
　・データライブラリとインフラストラクチャの廃止(オンプレミスの復旧目的のデータ使用を無くす)
　・機械学習(Dataflowを使用すれば即時に機械学習に移れる)
　・コンテンツの保存と配信(世界中にサービス展開するためにマルチリージョン)
　・バックアップとアーカイブ(cloud Storageのストレージクラスにより費用削減)
特徴
オンライン転送
・やりやすい
gsutil コマンドライン、ドラッグ＆ドロップ機能、JSON API を使用して、お好みの方法と言語でデータをアップロードできます
・直接接続
BigQuery Data Transfer Service では、Google 広告、キャンペーン マネージャー、Google アド マネージャー、YouTube のコンテンツおよびチャンネル所有者向けレポートといった主要アプリケーションに直接接続できます
・信頼性
Cloud Storage Transfer Service を使用すると、データを他のクラウド ストレージ プロバイダから Google Cloud Storage バケットにバックアップできます。Cloud Storage Transfer Service では、デフォルトでコンテンツを正しく転送できるようになっています。ファイルがデータシンク内に存在しない場合、またはデータソースとデータシンクの間でファイルのバージョンが異なる場合は、データソースからファイルがコピーされます。
・整合性
転送先バケットにすでに存在するオブジェクトのうち、データソース内に対応するオブジェクトがないものは削除できます。転送したソース オブジェクトは削除します。
・予測可能
1 回限りの転送または定期的な転送をスケジュールできます。ファイル作成日、ファイル名フィルタ、データをインポートする時刻に基づいた高度なフィルタを使用して、データソースからデータシンクへの定期的な同期をスケジュールする。

オフライン転送
・スケーラブル
1 台の Transfer Appliance から最大 1 ペタバイトのデータをキャプチャできます。複数台のアプライアンスを使用してより多くのデータを転送することも可能です。どの方法でも送信ネットワークに影響しません。
・安全性
データはキャプチャした瞬間に暗号化され、最終的なストレージ バケットに取り込まれた時点で復号できます。
・使いやすい
Transfer Appliance は、データセンターの空いているラックに簡単に取り付けることができ、ネットワーク接続ストレージ（NAS）としてマウントすることもできます。シンプルなユーザー インターフェースの案内に沿ってローカルデータをキャプチャし、Google Cloud Platform Console で復号して取り込むことができます。

</details>

<details><summary>CloudFoundationToolkit</summary>
Foundation Toolkit には、Google Cloud のベスト プラクティスを反映した、Deployment Manager 用と Terraform 用の参照テンプレートが用意されています。これらの既製のテンプレートを使って、Google Cloud で繰り返し使用できるエンタープライズ向けの基盤を迅速に構築できます。そのため、お客様はこの安全な基礎環境でアプリケーションをデプロイすることに集中できます。また、﻿Infrastructure as Code（IaC）を使用すると、ニーズの変化に合わせて基盤を簡単に更新できます
</details>

<details><summary>TransferService</summary>
オンラインまたはオンプレミスのソースから Cloud Storage へ大規模なオンライン データ転送を行います。

転送元がオンラインであるかオンプレミスであるかにかかわらず、Google のオンライン ストレージ転送ソリューションを使用すれば、大規模なデータ転送を簡単、安全、かつ効率的に管理できます

ユースケース
・データセンターの移行
・コンテンツの保存と配信
・バックアップとアーカイブ
・分析と機械学習


Storage Transfer Service
利点
・クラウド間のデータ転送
AWS S3 や Azure Blob Storage のようなオンライン ソースにあるデータを、単一の簡単なプロセスで Cloud Storage に迅速に転送します
・バケット間のデータ転送
ワークロードを最適化する際に、ストレージ クラスを越えてデータをシームレスに移動できます
・ウェブアドレスで参照できるデータの転送
ウェブアドレスで参照できる（HTTP）データをクラウドに移動することで、ウェブ コンテンツの提供がより簡単になり、数多くのクラウド ベンダーからデータにアクセスできます

特徴
・ジョブの一元管Google Cloud Platform Console UI、任意の言語のクライアント ライブラリ、または HTTP REST インターフェースを使用して転送ジョブを作成し、モニタリングします


Transfer Service for On Premises Data
利点
・大規模なデータをオンプレミス迅速にCloud Storageへ転送
・コードを一行も書かずにデータ検証や暗号化、エラー再試行が行われる


</details>

<details><summary>CloudIAM</summary>
Google Cloudのリソースアクセス権をきめ細かく設定できる
誰(ID)がどのリソースに対してどの様なアクセス権(ロール)を持つかを定義する
Google Cloud のリソースはCompute Engineやk8s、クラスタ、Storageなど
リソース整理は組織、フォルダ、プロジェクトです
IAMはリソースに対するアクセス権を直接エンドユーザーに付与することはない
複数の権限をロールにまとめ認証されたユーザーに付与します

アクセス管理モデルは、次の 3 つの主要な部分から構成されています。

・メンバー
メンバーは、リソースへのアクセスが許可されている
Google アカウント（エンドユーザー）、サービス アカウント（アプリまたは仮想マシン）、Google グループ、G Suite または Cloud Identity ドメインです。
ユーザー、サービス アカウントまたは Google グループに関連付けられているメールアドレス、あるいは G Suite または Cloud Identity ドメインのドメイン名がメンバーの ID になります。
・ロール
ロールは権限のコレクションです。
権限によって、リソースに対して許可されるオペレーションが決まります。
メンバーにロールを付与すると、そのロールに含まれるすべての権限が付与されます。
・ポリシー
Cloud IAM ポリシーは、1 つ以上のメンバーを 1 つのロールにバインドします。リソースに対してどのようなアクセス権（ロール）を誰（メンバー）に許可するのかを定義する場合、ポリシーを作成して、そのポリシーをリソースに接続します。


IDコンセプト
IAM では、メンバーに対してアクセス権を付与します。メンバーには次のタイプがあります。

・Google アカウント
Google アカウントは、Google Cloud を利用するデベロッパー、管理者、または他のユーザーを表します。Google アカウントに関連付けられているメールアドレス（gmail.com や他のドメインのアドレスなど）を ID として使用できます。

・サービス アカウント
サービス アカウントは、個々のエンドユーザーではなく、アプリケーションのアカウントです。Google Cloud にホストされているコードを実行すると、そのコードは指定したアカウントとして実行されます。利用するアプリケーションの個別の論理コンポーネントを表すために必要な数だけ、サービス アカウントを作成できます。

・Google グループ
Google グループは、Google アカウントとサービス アカウントの名前付きコレクションです。Google グループには、グループ固有のメールアドレスが関連付けられています。
グループを使用するとユーザーの集合に対してアクセスポリシーを適用できる。
Google グループにはログイン認証情報がありません。Google グループでは、リソースへのアクセスを要求する ID を設定することはできません。

・G Suite ドメイン
組織のG Suiteアカウントで作成されたすべてのグーグルアカウントの仮想グループを表します。
G Suite ドメインは、組織のインターネット ドメイン名（example.com など）を表し、G Suite ドメインにユーザーを追加すると、この仮想グループ（username@example.com など）内のユーザー用に新しいアカウントが作成されます
Google グループと同様に、G Suite ドメインを使用して ID を確立することはできませんが、G Suite ドメインを使用すると権限管理が容易になります。


・Cloud Identity ドメイン
Cloud Identity は IDaaS（Identity as a Service）ソリューションであり、企業向けモバイル管理（EMM）サービスです。G Suite で利用できる ID サービスとエンドポイント管理をスタンドアロン型のサービスとして提供します。Cloud Identity を利用することで、管理者は Google 管理コンソールからユーザー、アプリ、デバイスを一元管理できます。
G Suite ライセンスが必要なのは、Gmail など一部の G Suite サービスを利用するユーザーのみです。G Suite サービスを一切必要としないユーザーを管理するには、そうしたユーザー用に無料の Cloud Identity アカウントを作成してください。
個人の Gmail アカウントなどの一般ユーザー向けアカウントや、仕事用のメール ID が付加された一般ユーザー向けアカウントは、非管理型アカウントであるため組織で管理することができません。組織内のデベロッパーが非管理型アカウントで GCP リソースを使用する場合は、Cloud Identity アカウントを作成してこれらのデベロッパーを管理できます

・allAuthenticatedUsers
allAuthenticatedUsers は、すべてのサービス アカウント、および Google アカウントで認証されたユーザー全員を表す特殊な識別子です。この ID には、個人用 Gmail アカウントなど、G Suite または Cloud Identity のドメインに接続していないアカウントも含まれます。認証されていないユーザー（匿名の訪問者など）は含まれません。

・allUsers
allUsers は、認証されたユーザーと認証されていないユーザーの両方を含めた、インターネット上のユーザー全員を表す特殊な識別子です

・基本ロール: Google Cloud Console で従来から使用されているロール。オーナー、編集者、閲覧者のロールが該当します。これらのロールは、すべての Google Cloud サービスでさまざまな権限を持つため、使用を控えてください。

・事前定義ロール: 基本ロールよりも詳細なアクセス制御が可能なロール。たとえば、Pub/Sub パブリッシャー（roles/pubsub.publisher）は事前定義ロールです。このロールは、Pub/Sub トピックへのメッセージの公開のみを許可します。

・カスタムロール: 事前定義ロールではニーズを満たせない場合に、組織のニーズに応じて権限を調整するために作成するロール。

・Cloud IAM ポリシー
Cloud IAM ポリシーは、誰がどの種類のアクセス権を持つかを定義するステートメントの集合です。これを作成することによって、ユーザーにロールを付与できます。ポリシーはリソースにアタッチされ、そのリソースがアクセスされると常にアクセス制御が適用されます。

Cloud IAM ポリシーは、Cloud IAM Policy オブジェクトで表現されます。Cloud IAM Policy オブジェクトは、バインディングのリストで構成されます。Binding は、members のリストを role にバインドします。

・role: メンバーに付与するロール。role は、roles/service.roleName の形式で指定します。

・members:メンバータイプは接頭辞で識別できます。たとえば、Google アカウントには user:、サービス アカウントには serviceAccount:、Google グループには group:、G Suite または Cloud Identity ドメインには domain: が付いています。

リソース階層
・組織は階層内のルートノード
・フォルダは組織の子
・プロジェクトは組織またはそのフォルダの子
・各サービスのリソースはプロジェクトの子孫

ポリシーは継承推移的で組織＞フォルダ＞プロジェクト＞リソースと入れ子になっている

</details>

<details><summary>CloudKeyManagementSercice</summary>
GCPで暗号鍵を管理します。
クラウドでホスティングされる鍵管理サービスです。このサービスを利用することで、オンプレミス型と同じ方法でクラウド サービスの暗号鍵を管理できます
暗号鍵の生成、使用、ローテーション、破棄をサポートしています
IAMとCloud Audit Logsに統合されているのでここの鍵権利を管理しモニタリングできます
数百万もの暗号鍵の保持が可能で、データ暗号化の粒度レベルも選択できます。鍵の定期的な自動ローテーションを設定して、新しいプライマリ バージョンをデータ暗号化に使用し、1 つの鍵バージョンでアクセスできるデータ範囲を制限できます。アクティブな鍵バージョンはいくつでも保持できます。
さまざまな長さの RSA と楕円曲線鍵の両方を使って署名操作を実行することもできます
ローカルのデータ暗号鍵（DEK）を鍵暗号鍵（KEK）で保護することより鍵階層を実現します。アプリケーション レイヤでデータを暗号化するための鍵の管理を、保管先のストレージ システムが Google 内にあるかどうかを問わず行うことができます


</details>

<details><summary>CloudIdentity</summary>
ユーザーデバイスやアプリを管理するプラットフォーム
ID、アクセス、アプリ、エンドポイント管理（IAM / EMM）の統合プラットフォームが、IT チームやセキュリティ チームによるエンドユーザー効率の最大化と会社データの保護、デジタル ワークスペースへの移行をサポートします。
シングル サインオン（SSO）で何千ものアプリにユーザーがアクセスし、個人の Google アカウントと同じ方法で会社のアカウントを管理できるようになります。
Directory Sync を利用することにより、オンプレミスにあるディレクトリをクラウド環境に拡張できます

アカウントのキュリティ
oogle の脅威インテリジェンス シグナルと多要素認証（MFA）（プッシュ通知、Google 認証システム、フィッシング対策機能付き Titan セキュリティ キーなど）、およびセキュリティ キーとしての Android または iOS デバイスを使用して、フィッシング攻撃からユーザーを保護します


デバイスのセキュリティ
Android、iOS、その他統合コンソールを利用するデバイスにおける会社のデバイス セキュリティを改善できます。セキュリティ ポリシーの適用、会社データの消去、アプリのデプロイ、レポートの閲覧、そして詳細のエクスポートが可能です。
</details>

<details><summary>CloudRun</summary>
フルマネージド環境でステートレス コンテナを実行する
サーバーレスなのでインフラストラクチャ管理が一切不要で、最も重要な作業であるアプリケーション構築に集中できます

ルマネージドの Cloud Run、または Google Cloud とオンプレミスの両方をサポートする Anthos でコンテナを実行します。Cloud Run はオープン標準 Knative を基盤として構築されているため、アプリケーションの移植が可能になります。

さまざまな言語で作成できる
料金はコード実行時に発生
インファラテクチャ管理が不要

ユースケース

クライアント手動のウェブサービス
ラフィック需要に応じて自動スケーリングする従量課金制の動的なウェブやモバイルのアプリケーションを作成できます

・ウェブサイト
nginx、ExpressJS、django などの成熟したテクノロジーを活用してウェブサイトを構築し、Cloud SQL 上の SQL データベースにアクセスしてダイナミック HTML ページをレンダリングします。

・モバイル バックエンド向けの REST API
現在のモバイルアプリは通常、RESTful バックエンド API を利用することで最新のアプリケーション データのビューを取得し、フロントエンドとバックエンドの開発チームを分離します。Cloud Run で実行されている API サービスによって、開発者は Cloud SQL や Firestore（NoSQL）などのマネージド データベース上のデータの信頼性を維持できます

・バックオフィス管理
多くの場合、バックオフィス管理ではドキュメント、スプレッドシートやその他のカスタム インテグレーションが必要になり、ベンダー提供のウェブ アプリケーションを実行します。Cloud Run でコンテナ化された内部ウェブ アプリケーションをホストすれば、常に準備完了状態になり、使用した時間だけ課金されます。


軽量のデータ変換
すべてのデータでフルタイムで稼働する専用のビッグデータ処理ツールが必要となるわけではありません。処理のないときはゼロまでスケールダウンでき、新しいデータを受け取ったときに処理を実行する軽量な変換のほうが適する場合も多くあります。Cloud Run では、必要なデータ処理ライブラリを含むコンテナを構築し、マネージド型のサーバーレス環境で実行することができるため、サーバーを使用していない時間に課金されることはありません。変換は組み込みの Google Cloud プロバイダからのカスタマイズされた Cloud Tasks または Pub/Sub イベントによりトリガーできます。
Cloud Storage バケットに新しい .csv ファイルが作成されるたびに、イベントが発生し、Pub/Sub サブスクリプションによって Cloud Run サービスに配信されます。このサービスによりファイルからデータが抽出され、BigQuery テーブルに構造化されたデータとして保存されます。

ドキュメント生成のスケジュール設定
Cloud Scheduler を使用すると、Cloud Run サービスで請求書を生成するなど毎月のジョブをスケジュール化できます。カスタム バイナリを含むコンテナを Cloud Run にデプロイできるため、LibreOffice などの PDF 生成ツールをサーバーレスで実行できます。課金されるのは請求書を発行するときだけです。

webhook によるビジネス ワークフローの自動化
イベント ドリブンのアプローチによりオペレーションを接続します。多数の SaaS では「webhook」と呼ばれるリクエストの形式でイベントを push できます。Cloud Run はオンデマンドでスケーリングでき、webhook イベントを受け取って処理する間だけ課金されるため、webhook の送付先の実装に最適です。

たとえば、GitHub または Slack からのイベントに応答する場合、お客様のインフラストラクチャでも webhook イベントを送信することはできます。たとえば、購入されたとき、ジョブの準備ができたとき、アラートが発生したときなどです。Cloud Run サービスは基本的に「ジャストインタイム」で応答し、処理を実行してからこのメッセージを渡します。

</details>

<details><summary>CloudFunctions</summary>
イベント ドリブンのサーバーレス コンピューティング プラットフォームです。ローカルでもクラウドでも、サーバーをプロビジョニングせずにコードを実行できます。継続的デリバリー ツール、モニタリング ツールを使用して、コードからデプロイできます。Cloud Functions ではスケールアップやスケールダウンがなされるため、使用したコンピューティング リソースに対してのみ料金が発生します。既存の Google Cloud サービスやサードパーティのサービスと接続することで、エンドツーエンドの複雑な開発シナリオを簡単に作成できます


ユースケース

サーバーレスアプリケーションバックエンド
Cloud Functions を使用すると、独自のマイクロサービスを HTTP API 経由で公開したり、Webhook 統合を提供するサードパーティ サービスと統合したりできます。たとえば、Stripe による支払いが正常に行われた後の確認用メールの送信や、Twilio のテキスト メッセージ イベントへの応答など、有用な機能をアプリケーションにすばやく追加できます。

サーバーレス モバイル バックエンド
Firebase から直接 Cloud Functions を使用して、サーバーを立ち上げることなくアプリケーションの機能を拡張します。ユーザー アクション、分析、認証のイベントに反応するコードを実行します。たとえば、イベントベースの通知に対するユーザーの関心を維持したり、CPU やネットワークに大きな負荷がかかるタスクを Google Cloud にオフロードすることに活用できます

サーバーレス IoT バックエンド
Cloud Functions と Cloud IoT Core をはじめとするフルマネージド サービスを使用して、IoT（Internet of Things）デバイス テレメトリー データの収集、リアルタイム処理および分析のためのバックエンドを構築します。Cloud Functions を使用すると、届いたイベントのそれぞれにカスタム ロジックを適用できます。

リアルタイム ファイル処理
Cloud Functions を利用すると、Cloud Storage または Firebase Storage からのイベントに反応してアップロード直後のファイルを処理し、アップロード画像からのサムネイルの生成、ログの処理、コンテンツの検証、動画のコード変換、データの検証、集計、フィルタ処理をリアルタイムで行うことができます

リアルタイム ストリーム処理
Cloud Functions を使用することで、Pub/Sub からのイベントに反応し、ストリーミング データの処理、変換、拡充を行うことができます。トランザクション処理、クリック ストリーム分析、アプリケーション アクティビティ トラッキング、IoT デバイス テレメトリー、ソーシャル メディア分析をはじめとするアプリケーションに応用可能です。

仮想アシスタントと会話環境（人工知能)
Cloud Functions を Cloud Speech API および Dialogflow と組み合わせると、ユーザー サポート用に音声やテキストによる自然な会話環境を実装するなど、プロダクトやサービスの機能を拡張できます。Google アシスタント、Amazon Alexa、Facebook Messenger など、よく使われているプラットフォームやデバイスを利用してユーザーとの連携を強化しましょう

動画と画像の分析
Cloud Functions を Video Intelligence API および Cloud Vision API と組み合わせると、動画や画像から関連情報を取り出すなど、メディア コンテンツから問題解決のための分析情報を検索、発見、推論できます。

感情分析
Cloud Functions を Google Natural Language API と組み合わせると、テキストの構造と意味を明らかにして、感情分析やインテント抽出など強力な機能をアプリケーションに追加できます。


</details>

<details><summary>AppEngine</summary>
フルマネージド型のサーバーレス アプリケーション プラットフォーム
一般的な言語を使用して短時間でアプリケーションをビルドデプロイできる
デベロッパーはコーディングだけに集中するだけでインフラを管理する必要はない
またアプリケーションを自動的にスケールアップダウンできる機能があり、サーバー管理やパッチの適用もフルマネージドで運用される
App Engine のファイアウォール機能、IAM（Identity and Access Management）ルール、マネージド型の SSL/TLS 証明書を使用して、アプリケーションをセキュリティ上の脅威から保護できます
App Engine はアプリケーションのトラフィックに応じて自動的にスケールし、コードの実行中だけリソースを消費します。お支払いが発生するのは、消費したリソース分だけです


ユースケース
モダンウェブアプリケーション
スケーラビリティを備えたモバイル バックエンド

スタンダード環境
負荷が多くデータ量が多いい状況でも簡単にアプリをデプロイできる
セキュリティ保護されたサンドボックス環境で実行
このためリクエストを複数のサーバーに分散できトラフィック需要に合わせてサーバーがスケーリングされる。
言語はPython Jaca Node.js PHP Ruby Go
有料のアプリケーションを有効にすることで、1 GB のデータ ストレージとトラフィックを無料で利用できます。ただし、一部の機能には、割り当てに関係なく、システムの安定性を保護するために、制限が課されます

フレキシブル環境
スタンダード環境よりも多くの言語を選択できる
フレキシブル環境のインスタンス はComputer Engine仮想マシンであるのでデバック用にSSHを使用して独自のDockerコンテナをデプロイできる
アプリケーションの各インスタンス で必要なCPUとメモリを指定するとインフラストラクチャがプロビジョニングされる
イクロサービス、承認、SQL および NoSQL データベース、トラフィック分割、ロギング、バージョニング、セキュリティ スキャン、コンテンツ配信ネットワークなどの機能がネイティブにサポートされています。
インスタンスに対してヘルスチェックが行われ、必要に応じて修復され、プロジェクト内の他のサービスと同じ場所に配置されます
下位互換性のある重要な更新が、基盤となるオペレーティング システムに自動的に適用されます
VM インスタンスが、プロジェクトの設定に従って地理的なリージョンごとに自動的に配置されます。Google の管理サービスにより、プロジェクトのすべての VM インスタンスが同じ場所に配置され、最適なパフォーマンスが得られます
M インスタンスが毎週再起動されます。再起動中に、Google の管理サービスがオペレーティング システムとセキュリティの更新を適用します
Compute Engine VM インスタンスにはルート権限でアクセスできます。フレキシブル環境の VM インスタンスに対する SSH アクセスは、デフォルトで無効になっています。アプリの VM インスタンスに対するルートアクセスを有効にすることもできます

スタンダードを選択するケース
サポートされているプログラミングの特定バージョンで記述されている
無駄な投資を抑える
トラフィックの突然な急激増加対応

フレキシブルを選択するケース
Python、Java、Node.js、Go、Ruby、PHP、.NET
他の言語
ネイティブコードを含むフレームワーク
ComputeEngineネットワークにあるプロジェクトリソースやサービスにアクセスする

</details>

<details><summary>Knative</summary>
ケーネイティブ
最新のサーバーレスワークをビルド、デプロイ管理できるk8sベースのプラットフォーム
デベロッパー向けのソフトウェア
多数の煩雑なタスク（ソースコードからコンテナ イメージに至るアプリケーションのビルド、デプロイ中に生じるトラフィックのルーティングと管理、ワークロードの自動スケーリング、イベントソースの拡大するエコシステムに対する実行中のサービスのバインドといったワークフローなど）の解決に重点を置いた、再利用可能なコンポーネントのセットを提供します。 Knative はコンテナ イメージをデプロイメントの単位として認識します。したがって、デベロッパーは慣れ親しんだ言語やフレームワーク、イディオムを使用できます。デベロッパーにとって最も重要なのは、Knative を使えば、アプリケーションのビルド、デプロイ、管理の「退屈だが難しい」作業に気を取られることなく、コーディングに集中できることです。

デベロッパーにとってなじみのあるエクスペリエンスの提供に重点を置いています。GitOps、DockerOps、ManualOps などの一般的な開発パターンに加えて、Django、Ruby on Rails、Spring など多数のツールやフレームワークをサポートしています。

既存のビルドや CI / CD のツールチェーンに接続しやすくなるように設計されています。任意のクラウド、Kubernetes でサポートされる任意のインフラストラクチャで場所を選ばず実行できるオープンソース優先のテクノロジーを重視することで、実行に最適な場所にワークロードを自由に移動することを可能にしました。これにより、お客様独自の要件に合わせてシステムを調整するために必要な柔軟性と制御が得られます

サーバーレス ワークロードをお好みの環境で実行可能にするオープン API およびランタイム環境を提供します。Google Cloud 上のフルマネージド環境、Google Kubernetes Engine（GKE）上の Anthos、独自の Kubernetes クラスタすべてに対応しています。Knative を使用すると、Cloud Run で始めた後で Cloud Run for Anthos に移動したり、自分の Kubernetes クラスタで始めた後で Cloud Run に移行したりできます。Knative を基盤となるプラットフォームとして使用することで、スイッチング コストを大幅に削減しながら、ワークロードをプラットフォーム間で自由に移動できます。


</details>

<details><summary>GoogleKubernetesEngine</summary>
4芳香の自動スケーリングとマルチクラスタサポート、セキュリティを誇るマネージドk8s
Googleアカウントとロールの権限を使用してクラスタ内のアクセスを制御します。
クラスタ用にIPアドレス範囲が予約され、クラスタIPはGCVPNを介してプライベートネットワークIPと共存できる
HIPAA(医療)とPCIDSS(金融)の両方に準拠している
Cloud LoggingとCloud MOnitoringのチェックボックスをオンニするだけで動作を把握できる
トラフィックに合わせて個別調整されたクラスタが選択できる
CPU、メモリの自動スケーリング
クラスタを自動的に最新バージョンk8sに更新
ヘルスチェックでノードに異常が検知された場合k8s　Engineによってノードの修復
k8sは各コンテナに必要なCPUとメモリ(RAM)
GKE Sandboxを利用するとGKEでコンテナ化されたワークロード間に二番目の防御レイアを構築することでセキュリティの強化ができる
永続ストレージをコンテナに接続し、データベース全体をホストにすることができる
Dockerコンテナの形式をサポート
GKEは、Container-Optimized OS で実行されている
Google Container Registry を使用することで、専用 Docker イメージの保存とアクセスが容易
クラウドとオンプレミス全般の他の Kubernetes プラットフォームにワークロードを移動できる
プロジェクトのクラスタとそのリソース用のダッシュボードが存在する
プリエンプティブルVMが使用できる
永続ディスクHDD、SSDのどちらかを選択できスナップショットの取得やスナップショットからのディクス作成ができる
ローカルSSDの提供もしている
複数のリージョンのインスタンスプールに受信リクエストをグローバル負荷分散できる
LinuexとWindowsをサポートし両方のノードを実行できる
Cloud Runにより自動にスケーリングしサーバレスします
GKEクラスタのリソース使用量を名前空間とラベルで分類して表示でき使用量を意味のあるエンティティと見なすことができます
リリースチャンネルは、特定のクラスタがどの自動アプデートを受け取るかを制御できます。
Container Analysisによりインフラストラクチャコンポーネントとパッケージのセキュリティの強化します。

１請求先アカウントあたり１つのゾーンクラスタを無料で利用できる
Anthos GKE 以外では、1 時間、1 クラスタあたり $0.10 のクラスタ管理手数料が発生します。クラスタが削除されるまで、ワーカーノードでコンピューティング コストが発生します。

ユースケース
・継続的デリバリーパイプライン
アプリケーションとサービスのデプロイ、更新、管理が容易になり、アプリケーションの開発とイテレーションを迅速に行うことができます。GKE、Cloud Source Repositories、Cloud Build、Spinnaker for Google Cloud の各サービスを構成すると、アプリの構築、テスト、デプロイを自動化できます。アプリのコードが変更されると、その変更によって継続的デリバリー パイプラインがトリガーされて、新しいバージョンの再ビルド、再テスト、再デプロイが自動的に実行されます。
・GKEへの２層アプリケーション
Migrate for Anthos を使用すると、GKE のコンテナにワークロードを直接移行、変換できます。2 層の LAMP スタック アプリケーションをアプリケーションとデータベース VM とともに、VMware から GKE へ移行します。アプリケーション コンテナからのみデータベースにアクセスでき、外部のクラスタからはアクセスできないようにすることでセキュリティを強化します。 SSH アクセスを kubectl による、認証を受けたシェルアクセスに置き換えます。Cloud Logging の自動統合によるコンテナ システムのログを確認します。

</details>

<details><summary>Anthos</summary>
ビジネスのためのモダン アプリケーション プラットフォーム
一言でいうとGKEを中心とした、コンテナでサービスするところに必要なプロダクトの集合体

Anthos により、アプリケーションをどこでも安全で一貫した方法で構築、デプロイ、管理できます。ますますハイブリッド化、マルチクラウド化が進んだ環境の中、仮想マシンで実行している既存アプリケーションをモダナイズするとともに、コンテナでクラウド ネイティブなアプリケーションをデプロイできます。Google のアプリケーション プラットフォームにより、デプロイ全体で一貫性のある開発と運用ができ、運用上のオーバーヘッドを削減し開発者の生産性を改善します。

どこでもアプリケーションを管理
Anthos は、環境全体に対するサービス セントリック ビューを提供しながら、レガシーとクラウド ネイティブどちらにも、すべてのアプリケーションのデプロイに一貫したプラットフォームを実現します。基盤となっているインフラストラクチャからアプリケーションを分離することで、Google のプラットフォームではマルチクラウド、オンプレミス、さらにはエッジ ロケーションまでを含んだサービス全体を柔軟に実行できます。

ソフトウェアを迅速に届ける
クラウド環境やオンプレミス環境両方で管理された Kubernetes により、エンタープライズ クラスでコンテナ化されたアプリケーションの構築を高速化します。Anthos を使用すると、拡大を続ける Google のパートナー エコシステムから事前構築済みのデプロイ テンプレートを使って本番環境向けのコンテナ化したソリューションを活用できます。クラウド ネイティブなツールと専門家のガイダンスにより、デプロイ全体で高速かつスケーラブルなソフトウェア配信パイプラインを構築します。

コストを削減する
VM で実行中の従来型のアプリケーションのワークロードを、CI / CD パイプラインに簡単に追加できるコンテナへ自動的に移行することで、即時に運用コストの削減を実現します。Anthos はサードパーティー製のハイパーバイザー不要でベアメタル上で直接実行できるため、ライセンス コストを削減しながらパフォーマンスを向上できます

















</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

## 教材の資料箇条書きメモ
IaaSの未加工のコンピューティング、 ストレージ、ネットワークは データセンターと同様に編成されます
PaaSでは 作成するアプリコードが ライブラリにバインドされるため 必要なインフラにアクセスできます そのため アプリのロジックのみに集中できます
IaaSモデルでは 割り当てた分の料金を支払います
PaaSモデルでは使用した分を支払います
Google検索、Gmail、ドキュメント、 ドライブなどの人気アプリはSaaSアプリですエンドユーザーが インターネットで直接利用するからです


ゾーンは GCPリソースのデプロイ領域です
ゾーンはリージョンという 個々の地域にグループ化されています
リージョン内のゾーン間では 高速ネットワーク接続を使用できます
リソースをリージョン内の 複数のゾーンに分散できます こうするとアプリを 予期せぬ障害から保護できます
リソースは複数リージョンで実行できます
アプリを世界中のユーザーの 近くに配置するためです
さらに 自然災害などによる リージョン全体の機能停止からも保護できます
データの冗長性を確保するために 欧州内の160km以上離れた ２つ以上の場所にデータを保管できます


予算は請求先アカウントごと またはGCPプロジェクトごとに定義できます 予算には上限を設けることも 別の指標を関連付けることもできます
課金データエクスポートでは 詳細な課金情報を 分析用に取得しやすい場所に保管できます(Cloud Storageバケットなど)
レポートはGCP Console内の ビジュアルツールです 利用額を監視できます 割り当ても実装しています
これはアカウント所有者と GCPコミュニティ全体を保護する手段です エラーや悪意のある攻撃による リソースの過剰消費を防ぐことができます
割り当てには２種類あります
頻度に基づく割り当ては 一定期間後にリセットされます
数量に基づく割り当ては プロジェクトで使用できる リソースの数を制御します


Google Cloud Identity and Access Management（IAM）を使用して 誰が何をできるかをコントロールします
GCPのお客様はIAMを使用して最小権限を実装し こうした誤りを防ぐことができます GCPの管理レイヤを操作するには ４つの方法があります
ウェブベースのConsole、 SDKとコマンドラインツール、 API、モバイルアプリです
下位層のセキュリティはGoogleが管理します
セキュリティスタックの上位層は 引き続きお客様の管理になります
GoogleはIAMなどのツールを提供して お客様が上位層で任意のポリシーを 実装できるようにしています


VM、Cloud Storageバケット テーブル、BigQueryなどすべてが プロジェクトに整理されます
加えてプロジェクトをフォルダに まとめることもできます
フォルダには他のフォルダも格納できます
組織が使用する全フォルダとプロジェクトは 組織ノードの下にまとめられます
プロジェクト、フォルダ、組織ノードには まとめてポリシーを定義できます
一部のGCPリソースでは 個別にポリシーを定義できます
ポリシーは階層の下位に 継承される
GCPリソースは １つのプロジェクトに属します
プロジェクトはGCPサービスを 使用する際の基本単位です
APIの管理、課金の有効化、 共同編集者の追加と削除などを行います
各プロジェクトは独立した区画であり 各リソースは 1 つの区画にのみ属します
プロジェクトごとに異なるオーナーと ユーザーを作成して個別に管理できます
各GCPプロジェクトに 名前とプロジェクトIDを割り当てます
プロジェクトIDは永続的かつ不変で GCP全体で一意である必要があります
このIDをさまざまなコンテキストで使用して GCPに作業対象のプロジェクトを指示します
プロジェクトには 好きな名前を付けられます
各プロジェクトには固有の プロジェクト番号も割り当てられ さまざまなコンテキストで表示されます
プロジェクトIDは人が読める文字列にします
プロジェクトはフォルダにまとめることができます
フォルダは作業を楽にするためのツールです
フォルダ内のリソースは そのフォルダのIAMポリシーを継承します
フォルダを使用するには 階層の最上位に組織ノードが必要です
社内の全プロジェクトは １つの構造にまとめることができます
ほとんどの企業では リソースの使用状況の確認と ポリシーの適用を一元的に行う必要があります
それを可能にするのが組織ノードです 組織ノードは階層の最上位階層であり 特別な役割を持っています
たとえば 組織ポリシー管理者を指定して 管理者だけがポリシーを変更できるようにします
G Suiteドメインがある場合 GCPプロジェクトは 自動的に組織ノードに属します
そうでない場合は Google Cloud Identityを 使用して作成できます
新しい組織ノードを作成した時点では ドメイン内の全員が引き続き プロジェクトと請求先アカウントを作成できます
新しい組織ノードを作成したら まずこれらの操作を許可する チームメンバーを決定しましょう
組織ノードを作成すれば その下にフォルダを作成して そこにプロジェクトを配置できます
プロジェクトはいつでもフォルダに移せます リソースは親リソースからポリシーを継承します
プロジェクト内のすべてのリソースが ポリシーを継承します
階層の上位で実装されたポリシーが それより下位で付与された アクセス権限を削除することはできません




IAMを使えば特定のリソースへの 操作権限をユーザーに付与できます
IAMポリシーは「誰が」「何を」 「どのリソースに」対して行えるかを定義します
「何を」はIAM役割で定義します IAM役割とは権限の集合です
「誰が」は Googleアカウント、Googleグループ サービスアカウント、G Suite全体、 Cloud Identityドメインのいずれかになります
IAM役割には３種類あります
基本の役割は広範です GCPプロジェクトに適用するとそのプロジェクトの全リソースに適用されます
基本の役割には オーナー、編集者、閲覧者があります
閲覧者はリソースを確認できますが 状態の変更はできません
編集者は閲覧者の権限に加えて リソースの状態を変更できます
オーナーは編集者の権限に加えて リソースの役割と権限を管理できます
オーナーには 支払い / 請求の設定がある
通常 請求管理の担当者には プロジェクトリソースの変更権限は与えません
そのために 課金管理者の役割を付与できます
機密データが含まれるプロジェクトに 複数のメンバーが取り組む場合は注意が必要です
基本の役割では広範すぎるかもしれません
GCP IAMにはよりきめ細かい役割もあります
各GCPサービスには 独自の定義済みの役割があり 役割を適用できる対象が定義されています


Compute Engineの InstanceAdmin役割を持つユーザーは VMに対して特定の操作を行うことができます
たとえば VMの一覧表示、 構成の読み取りと変更、VMの起動と停止です 操作対象のVMは 役割の適用先によって決まります
ここでは 特定のGoogleグループの ユーザー全員がこの役割を持っています
この役割はproject_aの全VMに適用されます
さらにきめ細かい役割が必要な場合は カスタムの役割があります
多くの会社では最小権限のモデルを使って 各メンバーに必要最小限の 権限のみを付与しています
たとえば InstanceOperator役割を定義して 特定のユーザーにCompute EngineとVMの 起動と停止を許可し 再構成は許可しないとします
カスタムの役割を使えばこれを実現できます ただし注意点があります 第一に カスタムの役割を使うことを 明確に決める必要があります
権限の管理が必要になるからです 会社によっては 事前定義済みの役割を選択しています
第二に カスタムの役割を使用できるのは プロジェクトまたは組織レベルのみです フォルダレベルでは使用できません
権限を付与する対象がユーザーではなく Compute Engine VMだとしたら？ その場合はサービスアカウントを使用します
たとえばVMで実行しているアプリのデータを Google Cloud Storageに保管するとします
そのデータへのアクセスは インターネット上の全員に許可するのではなく VMだけに許可します
そこで Cloud Storageに対してVMを 認証するためのサービスアカウントを作成します
サービスアカウントの名前は メールアドレスにします ただし パスワードではなく 暗号鍵でリソースにアクセスします
こちらの例では サービスアカウントにCompute Engineの InstanceAdmin役割が付与されています
VMで実行中のアプリはこのアカウントを使って 他のVMを作成、変更、削除できます
また サービスアカウントの管理も必要です
たとえば Aliceが特定のサービスアカウントで 実行可能な操作を管理するとします
一方 Bobは表示さえできれば十分です サービスアカウントはIDであると同時に リソースでもあるため
IAMポリシーをそれ自体に適用できます サービスアカウントでAliceには編集者の役割を
Bobには閲覧者の役割を付与できます 他のGCPリソースの役割を 付与する場合と同じです
プロジェクト内のVMのグループごとに 異なるIDを付与できます
その結果 グループごとに 異なる権限を管理しやすくなります
また VMを再作成しなくても サービスアカウントの権限を変更できます

Consoleはウェブベースの 管理インターフェースです GCPでアプリを作成するときに使用します
Consoleではすべてのプロジェクトと 使用するリソースを確認、管理できます
GCPサービスのAPIの 有効化、無効化、確認も可能です Cloud Shellにもアクセスできます
Cloud ShellはGCPの コマンドラインインターフェースで ブラウザで簡単に使用できます
Cloud Shellでは Google Cloudソフトウェア開発キット（SDK） に含まれるツールを使用できます
インストールは不要です
Google Cloud SDKは GCPでリソースとアプリを 管理するためのツールの一式です
SDKに含まれるgcloudツールは GCPのプロダクトとサービスのメインの コマンドラインインターフェースです
Cloud Storage用のgsutilと BigQuery用のbq（BigQuery）も含まれています
SDKコマンドにアクセスするには ConsoleのCloud Shellボタンを クリックするのが簡単です
SDKコマンドがすでにインストールされた VM上のウェブブラウザに コマンドラインが表示されます
SDKを自分のマシンに インストールすることもできます
SDKはDockerイメージとしても提供されており システムを非常に簡単に扱うことができます
GCPを構成するサービスには APIが用意されています こうしたAPIは RESTfulと呼ばれます
APIではリソースとGCPをURLで指名します
コードでAPIに情報を渡すには JSONを使用します
GCP Consoleでは APIを有効または無効にできます 割り当てと制限も適用されます
必要なAPIだけを有効にして リソースが追加で必要になったら 割り当ての増加をリクエストできます
Googleのクライアントライブラリを使えば コードからGCPを呼び出す 面倒な作業を大幅に軽減できます
ライブラリには２種類あります Cloudクライアントライブラリは Google CloudのAPIに推奨される 最新のライブラリです
各言語のネイティブスタイルと イディオムを採用しています ただし 最新のサービスと機能を サポートしていない場合もあります
その場合は 使用する言語に対応する Google APIクライアントライブラリを使用します
こうしたライブラリは普遍性と完全性を 重視して設計されています
GCPで使用しているリソースを調べて管理できる AndroidとiOS向けのモバイルアプリです



最小限の作業ですぐに GCPの使用を開始するには GCP Marketplaceが便利です
GCPにソフトウェアパッケージを 迅速にデプロイするためのツールです
ソフトウェア、VMインスタンス、ストレージ、 ネットワークの手動構成は不要です
必要に応じて起動前に変更できます
GCP Marketplaceの ソフトウェアパッケージの大半は GCPリソースの通常料金の他に追加料金はかかりません
一部のGCP Marketplaceイメージでは 利用料がかかります
サードパーティが商用ライセンスソフトウェアで 公開しているものなどです
その場合は起動する前に 月額利用料の見積りが示されます
ネットワーキング費用は 見積りに含まれないことがあります
アプリの使用方法によって異なるためです
GCPでは重大な問題と脆弱性の修正のため ソフトウェアのベースイメージが更新されます
デプロイ後のソフトウェアは更新されません
デプロイ済みのシステムに アクセスすることは可能であるため 自分で保守することはできます

Compute EngineではVMを Googleのグローバルインフラで実行できます
VMの利点の１つは 本格的なOSの処理能力と普遍性を 備えていることです
VMは物理サーバーと同じように構成できます CPU処理能力、メモリ量、
ストレージの容量とタイプ、OSを指定できます VMは柔軟に再構成できます
さらにGoogle Cloudで稼働するVMには 比類ないネットワーク接続性があります

VPCネットワークがGCPリソースの相互接続と インターネットとの接続を可能にします
ネットワークをセグメント化し ファイアウォールルールで インスタンスへのアクセスを制限できます
静的ルートを作成すれば トラフィックを特定の宛先に転送できます
定義するVPCネットワークが グローバルスコープを持つということです
世界中のどのGCPリージョンにも サブネットを持てます
サブネットはリージョン内の 複数ゾーンをまたぐことも可能です
グローバルスコープのネットワーク レイアウトを簡単に定義できます
同じサブネットで複数ゾーンに リソースを配置することもできます
カスタムネットワーク内のサブネットの サイズは動的に拡大できます
割り当てるIP範囲を拡大するだけです

Compute EngineではVMを作成してGoogleのインフラで実行できます
先行投資は要りません
高速で一貫したパフォーマンスのシステムで 数千もの仮想CPUを実行できます
VMインスタンスを作成するには GCP Consoleまたは gcloudコマンドラインツールを使います
VMで実行できるLinuxまたは Windows Serverイメージには Google提供のものとカスタマイズバージョンがあります
物理サーバーからイメージを インポートすることも可能です
VMを作成するときにマシンタイプを選びます タイプによってメモリ量と 仮想CPUの数が決まります
タイプにはごく小さなものから 非常に大きなものまであります
事前定義済みのタイプで要件を満たせない場合は カスタムVMを作成できます
処理能力については 機械学習やデータ処理など GPUを利用できるワークロード向けに
GCPの多くのゾーンでは GPUを利用できます 物理的なマシンと同じように VMにもディスクが必要です
永続ストレージは２種類から選択できます 標準とSSDです
アプリに高パフォーマンスの 一時的領域が必要な場合は ローカルSSDを接続できます
ただし永続的な価値のあるデータは 別の場所に保管してください
ローカルSSDのコンテンツは VMが終了すると消去されるからです
もう１種類は 永続ディスクです　ブートイメージも選べます
さまざまなバージョンの LinuxとWindowsが用意されています
独自のイメージもインポートできます　
GCP VM起動スクリプトを渡すのが一般的です 他の種類のメタデータを渡すこともできます
VMが稼動したら 簡単にディスクのスナップショットを取れます バックアップとして保管したり
別のリージョンへのVMの移行時に 使用したりできます
完了するまで人が介入しない ワークロードがあるとします 大規模なデータセットを 分析するバッチジョブなどです
プリエンブティブルVMでジョブを実行すると 費用を節約できます
プリエンプティブルVMには通常の Compute Engine VMと異なる点が１つあります
他でリソースが必要になった場合に Compute Engineがそれを終了できるという点です
Compute Engine の余剰のキャパシティを利用する機能であり、使用できるかどうかは利用状況に応じて異なります
プリエンプティブルVMでは 費用を大幅に節約できますが 停止と再開が可能なジョブに使用してください
インスタンスに応じた適切なマシンは 仮想CPUの数やメモリ量を基に選択できます
事前定義済みマシンタイプを 使用することも カスタムマシンタイプを 作成することもできます
Compute Engineの 自動スケーリング機能を使用すると 負荷の指標に基づいて アプリのVM数を増減できます
この仕組みの一環として 着信トラフィックの負荷がVM間で分散されます


VPCでもルーティングテーブルを使用します 同じネットワーク内のインスタンス間で トラフィックを転送するためです
サブネット間やGCPゾーン間でも 外部IPアドレスを使用せずに転送できます
VPCルーティングテーブルはプロビジョニングや管理は不要です
ファイアウォールインスタンスの プロビジョニングと管理も不要です
VPCのグローバルな分散型ファイアウォールを使用してインスタンスへの送受信トラフィックを制限できます
ファイアウォールル―ルの定義では インスタンスのメタデータタグを使用できます
たとえばすべてのウェブサーバーに 「web」というタグを付けるとします
ファイアウォールルールで ポート80または443での受信トラフィックを 「web」タグが付いたVMに許可します
IPアドレスは何であろうと関係ありません VPCはGCPプロジェクトに属します
複数のGCPプロジェクトがありVPC間の通信が必要な場合は単に２つのVPC間にピアリング関係を確立してVPCピアリングを使用できます
IAMを機能を最大限に利用して別のプロジェクトのVPCに対して誰が何の操作を行えるか制御するには共有VPCを使用できます
その時々でアプリを提供するVMの数が変わる場合Cloud Load Balancingです
これはソフトウェアで定義された 完全分散型のマネージドサービスです
ロードバランサは管理対象のVM内で実行されないためスケーリングも管理も不要です
Cloud Load Balancingはすべての トラフィックに対応しています
これにはHTTPとHTTPS、 その他のTCPとSSLトラフィック、 UDPトラフィックも含まれます
Cloud Load Balancingでは １つのエニーキャストIPが 世界中のリージョンのバックエンドインスタンスのフロントエンドとなります
負荷はリージョン間で分散されます
さらに自動マルチリージョンフェイルオーバーにより バックエンドの不調時には トラフィックを分割して移動します
Cloud Load Balancingは ユーザー、トラフィック、バックエンドの状態、ネットワーク条件などの変化に瞬時に対応します
ウェブアプリの負荷をリージョン間で分散する場合は HTTPS負荷分散を使用します
HTTP以外のSSLトラフィックにはグローバルSSLプロキシロードバランサを使用します
SSLを使用しないTCPトラフィックであればグローバルTCPプロキシロードバランサを使用します
この２種類のプロキシサービスは 特定のポート番号とTCPでのみ機能します
UDPトラフィックや任意のポート番号の トラフィックを負荷分散する場合は リージョンロードバランサで リージョン全体に負荷を分散できます
これらすべてのサービスの共通点はインターネットから送信されるトラフィックを対象としていることです
アプリのプレゼンテーション層と ビジネスロジック層の間での負荷分散などは内部ロードバランサを使用します
GCP内部IPアドレスでの受信トラフィックの 負荷をCompute Engine VM間に分散します
GCPではCloud DNSを提供していますこれはGoogleと同じインフラで実行されるマネージドDNSサービスです
低レイテンシと高可用性を実現し 費用効率の高い方法で アプリとサービスをユーザーに提供できます
DNS情報を公開すると その情報は 全世界のあらゆる場所から配信されます
Cloud DNSはプログラムも可能です 数百万ものDNSゾーンとレコードを 公開して管理するには
GCP Console、コマンドライン インターフェース、APIを使用できます
Googleにはグローバルな エッジキャッシュシステムがあります
このシステムを使ってアプリのコンテンツ配信を加速化するには Google Cloud CDNを使用します
ユーザーは低レイテンシを実感するでしょう コンテンツの発信元の負荷が減り 費用も節約できまます
HTTPS負荷分散を設定した後にチェックボックスをオンにするだけで Cloud CDNを有効にできます
CDNは他にもたくさん存在します すでにCDNを使用している場合
GCPのCDN Interconnectパートナー プログラムの対象である可能性がありますその場合はそのまま使用できます
GCPのお客様の多くはGoogle VPCと 他のネットワークの相互接続を必要とします
オンプレミスネットワークや他の クラウド内のネットワークなどです
選択肢はたくさんあります 多くのお客様は 仮想プライベートネットワークを IPSECプロトコルを使用してインターネットで接続します
さらに 動的な接続にするために Cloud RouterというGCP機能を使用します
この機能を使用すると 他のネットワークとGoogle VPCの間で BGPを使って VPN経由でルート情報を交換できます
たとえば 新しいサブネットを Google VPCに追加すると オンプレミスネットワークが自動的に そのルートを取得します
インターネットを使用したくないお客様もいます
その場合はGoogleとの ダイレクトピアリングを検討できます
ピアリングとはルーターを Google POPと同じデータセンターに配置して トラフィックを交換することです
Googleは世界中に 100を超えるPOPを設けています POPでまだ接続を確立していない場合は
キャリアピアリングプログラムの パートナーに接続を依頼できます
ピアリングには欠点が１つあります それはGoogleのSLAの対象ではないことです
 Googleとの相互接続で 高い稼働率が必要な場合は Dedicated Interconnectを使用してください
Googleとの１つ以上の直接プライベート接続を確立できます
接続形態がGoogleの仕様を満たす場合 その接続は最大で 稼働率99.99％のSLAの対象になります

Cloud Storageについて説明しましょう
オブジェクトストレージとは何でしょう
フォルダの階層としてデータを管理する ファイルストレージとは異なります
OSがデータをディスクの塊として 管理するブロックストレージとも異なります
オブジェクトストレージとは データを保管するとその一連のバイトが オブジェクトとして扱われ
固有のキーでデータをアドレス指定できる ストレージを意味します
これらの固有のキーはURL形式です
Cloud Storageの仕組みも同じです
スケーラブルな フルマネージドサービスです つまり 容量の事前プロビジョニングは不要です
オブジェクトを作成するだけで 耐久性と可用性に優れたデータ保存が可能になります
Cloud Storageはウェブサイトコンテンツの配信や アーカイブ・復旧用データの保管
ユーザーの直接ダウンロードによる 大容量データの配布などで使用されます
Cloud Storageは ファイルシステムではありません
格納されているオブジェクトごとに URLがあるからです
各オブジェクトは多くの点で ファイルのようなものなので
オブジェクトを「ファイル」という言葉で 説明しても構いませんが 正確にはファイルシステムとは違います
Linuxマシンのルートファイルシステムとして Cloud Storageを使うことはありません
Cloud Storageはバケットで構成されます
ユーザーがバケットを作成して構成し そこにオブジェクトを格納します
ストレージオブジェクトは不変です
インプレースで編集するのではなく 新しいバージョンを作成します
Cloud Storageは必ずサーバー側で データを暗号化してからディスクに書き込みます
暗号化の追加料金はありません
またデフォルトでは 転送中のデータがHTTPSで暗号化されます
データ転送については 大量のデータをCloud Storageに 保存できる便利なサービスもあります
Cloud Storageに格納されたデータは他のGCPストレージサービスに移動できます
バケットの作成時に グローバルに一意の名前を付けます
バケットとそのコンテンツを保管する 地理的ロケーションを指定し デフォルトの ストレージクラスを選択します
ユーザーにとってレイテンシが最小になる ロケーションを選んでください
オブジェクトとバケットへのユーザー アクセスを制御する方法はいくつかあります
通常はCloud IAMで十分です 役割はプロジェクトから バケット、オブジェクトへと継承されます
よりきめ細かい制御が必要な場合は アクセス制御リスト（ACL）を作成します
ACLで定義するのはバケットとオブジェクトに アクセスできるユーザーと ユーザーのアクセスレベルです
各ACLは２つの情報で構成されます
１つは指定の操作を実行できるユーザーを 定義する「スコープ」で特定のユーザーや ユーザーグループを定義します
もう１つは実行できる操作を定義する 「権限」です
読み取り権限や書き込み権限などです
先ほど述べたように Cloud Storageオブジェクトは不変です
必要であればバケットでオブジェクトのバージョニングを有効にできます
その場合 Cloud Storageは 変更履歴を保持します
つまり バケット内の全オブジェクトを 上書きまたは削除します
オブジェクトのアーカイブバージョンを 一覧表示して オブジェクトを前の状態に復元したり
完全にバージョンを削除したりできます
オブジェクトバージョニングを 有効にしていない場合は 新しいオブジェクトが常に 古いオブジェクトを上書きします
バージョニングは便利ですが ゴミが溜まるのが心配であれば
Cloud Storageの ライフサイクル管理ポリシーを使用するといいでしょう


Cloud Storageではストレージクラスを ４つの中から選択できます
Multi-RegionalとRegionalは 高パフォーマンスのオブジェクトストレージです
NearlineとColdlineは バックアップとアーカイブ用のストレージです
いずれのストレージクラスにも Cloud Storage APIで同じようにアクセスできすべてミリ秒単位でアクセス時間が計測されます
Regionalでは 特定のGCPリージョンにデータを保管できます
us-central1、europe-west1、 asia-east1のいずれかです
Multi-Regionalより安価ですが 冗長性は低くなります
Multi-Regionalでは料金は高くなりますが地理的冗長性が確保されます
米国、EU、アジアなどの大まかな 地理的ロケーションを選ぶと
Cloud Storageが160km以上離れた２か所の 地理的ロケーションにデータを保管します
Multi-Regionalが適しているのは 頻繁にアクセスするデータです
たとえば ウェブサイトのコンテンツや インタラクティブなワークロード モバイルアプリやゲームアプリの データなどです
Regionalが適しているのは Compute Engine、VM、Kubernetes Engine クラスタの近くにデータを保管する場合です
データ集約型の計算パフォーマンスが 向上するためです
Nearlineは安価で 耐久性に優れたサービスです アクセス頻度が低い データの保管に適しています
このストレージクラスが Multi-RegionalやRegionalよりも適しているのは データの読み取りや変更を行うのが 平均で月に１回以下の場合です
Coldlineは非常に安価な 耐久性に優れたサービスで データアーカイブ、オンラインバックアップ、障害復旧に適しています
Coldlineは年に１度程度しか アクセスしないデータの保管に最適です なぜなら可用性が若干低く 90日の最小保存期間があるからです
データアクセスに費用がかかり １オペレーションあたりの費用も高めです
たとえば データのアーカイブや 障害復旧での使用に適しています
可用性はストレージクラスによって異なります
最も高いのは可用性99.95％の Multi-Regionalです 次は可用性99.9％のRegionalです
NearlineとColdlineの可用性は99％です
料金については すべてのクラスで１か月あたりの データ保存量に対しGB単位で料金が発生します
料金が最も高いのは Multi-Regionalで 最も低いのはColdlineです
下りトラフィックと データ転送の料金がかかることもあります
これらの料金に加えて Nearlineではデータ読み取りにも GB単位の料金が発生します
ColdlineではGB単位の データ読み取り料金はさらに高くなります
どのストレージクラスでも 複数の方法でデータをCloud Storageに取り込めます
多くのお客様は gsutil(コマンドラインアプリ)を使用しています
これはCloud SDKに含まれる Cloud Storageコマンドです
Chromeブラウザを使用していれば GCP Consoleでドラッグ＆ドロップでの データ移動も可能です
テラバイトからペタバイト規模の データをアップロードする場合は
GCPのオンラインStorage Transfer Serviceと オフラインTransfer Applianceを利用できます
Storage Transfer Serviceでは別のクラウドプロバイダ、別のリージョン、 HTTPSエンドポイントから
Cloud Storageへの一括転送を スケジュールして管理できます
Transfer Applianceはラックマウント型の大容量ストレージ サーバーで Google Cloudからリースできます
ネットワークに接続してデータを読み込んでからアップロード施設に配送するだけでデータがCloud Storageにアップロードされます
このサービスを使えば１台の機器で最大１ペタバイトのデータを安全に転送できます
Cloud Storageにデータを格納する方法は他にもあります
このストレージはGCPの多数のプロダクトと サービスと密接に統合されているためです
たとえば BigQueryとCloud SQLとの間で テーブルをインポート、エクスポートできます
App EngineのログやCloud Datastoreのバックアップ App Engineで使用するイメージなどのオブジェクトも保管できます
他にもインスタンスの起動スクリプトや Compute Engineイメージ Compute Engineアプリの オブジェクトなども保管できます
つまりCloud Storageはクラウドへの データ取り込みポイントになり データを長期間保存する場所としても 頻繁に使用されています

Cloud Bigtableはビッグデータ用の NoSQLデータベースサービスです
リレーショナルデータベースは 各行に一連の同じ列があるテーブルの 集合だと考えてください
このルールと各テーブルに指定したルールを データベースエンジンが適用します
これはデータベーススキーマと呼ばれます
スキーマが大きな助けになるアプリもあれば大きな障害になるアプリもあります
一部のアプリではもっと柔軟な手法が必要です たとえば NoSQLスキーマです
すべての行に同じ列がある必要はありません
データベースによってはこれを活かすためにデータを低密度で行に取り込みます
これはNoSQLデータベースの特徴の１つです
Bigtableにもこの特徴があります
Bigtableは低密度に格納されるテーブルで
数十億行、数千列にスケールして 数ペタバイトのデータを保管できます
GCPのフルマネージドサービスなので構成や調整は不要です
Bigtableが適しているのは単一の参照キーを持つデータです
一部のアプリ開発者はBigtableを 永続ハッチテーブルとみなしています
Bigtableは極めて低いレイテンシで 大容量データを格納するのに最適です
高スループットの読み書きに対応するため運用アプリと分析アプリの両方に理想的です
Cloud BigtableはHBaseと同じ オープンソースAPIを介して提供されます
HBaseはApache Hadoopプロジェクトの ネイティブデータベースです
同じAPIを使用するということは HBaseとBigtableの間で アプリを移植できるということです
独自のApache HBaseインストール環境を 管理している場合 なぜBigtableを選択するのか 疑問に思うかもしれません
その理由をいくつか説明します まず スケーラビリティです
独自のHbaseインストール環境ではある時点で１秒あたりのクエリ数をスケールするのが難しくなります
Bigtableではマシンの数を増やすだけでスケールできます
ダウンタイムも必要ありません
またBigtableはアップグレードや再起動などの管理タスクを透過的に処理します
Bigtable内のデータはすべて処理中にも保存時にも暗号化されます
IAM権限を使用してBigtableデータにアクセスできるユーザーも制御できます
Bigtableは Googleの多くのコアサービスを 支えるデータベースです
Google検索、アナリティクス、 マップ、Gmailなどのサービスです
Cloud Bigtableは GCPエコシステムの一部であるため
他のGCPサービスや サードパーティクライアントと連携できます
アプリのAPIの観点から見ると Cloud Bigtableでのデータの読み書きは データサービス層で行えます
つまりマネージドVMやHBase RESTサーバーHBaseクライアントを使用する Javaサーバーなどで行えます
通常はここでアプリ、ダッシュボード、 データサービスにデータが提供されます
各種のストリーム処理フレームワークでデータをストリーミングすることも可能です
Cloud Dataflow Streaming、 Spark Streaming、Stormなどを使えます
ストリーミングできない場合は Hadoop Map/Reduce、Dataflow、Sparkで データの読み書きを一括処理できます
通常は 集約データおよび 新しく計算されたデータが Cloud Bigtableまたは 下流のデータベースに書き込まれます

リレーショナルデータベース  これらのサービスは データベーススキーマを使用して アプリのデータの 一貫性と正確性を保ちます
トランザクションに役立つことです
データベースの一連の変更をアプリで オールオアナッシングとして指定できます
変更はすべて成功か すべて失敗のどちらかです
データベーストランザクションがなければ オンラインバンクで 預金を口座間で移動できません
たとえば ある口座から １万ドルを引き出したのに なんらかの不具合で振替先口座に 預金が移動できなかったとしましょう
銀行が１万ドルを 誤って移動したからかもしれません
リレーショナルデータベースの 設定、保守、管理には手間がかかります
これらの作業に時間を取られたくないが リレーショナルデータベースによる保護は必要という場合は Cloud SQLを検討してください
このフルマネージドサービスでは MySQLまたはPostgreSQLの データベースエンジンを選択できます
Cloud SQLのMySQLとPostgreSQLのデータベースはどちらもテラバイト規模のデータを処理できます
Compute Engine VM内で 独自のデータベースサーバーを実行できます
GCPの多くのお客様がそうしています
一方で Cloud SQLマネージドサービスには いくつかの利点があります
まず Cloud SQLは 複数のレプリカサービスを提供します
リード、フェイルオーバー、 外部レプリカなどです
あるゾーンが停止状態になっても
Cloud SQLの自動フェイルオーバーによってゾーン間でデータをレプリケートできます
オンデマンドまたはスケジュール設定した
バックアップでデータをバックアップできます
マシンタイプの変更による垂直スケーリングと リードレプリカによる 水平スケーリングも可能です
セキュリティについては Cloud SQLインスタンスには ネットワークファイアウォールがあり
顧客データは Googleの内部ネットワーク上でも データベーステーブル、一時ファイル、 バックアップ内でも暗号化されます
Cloud SQLインスタンスのもう１つの利点は 他のGCPサービスや外部サービスから アクセスできることです
Compute Engineインスタンスに Cloud SQLインスタンスへのアクセスを許可して
VMと同じゾーン内で Cloud SQLインスタンスを構成できます
Cloud SQLはSQL WorkBenchや Toadなどのアプリやツールに加え 標準のMySQLドライバを使った 外部アプリにも対応しています
水平スケーリングが必要なため Cloud SQLで対応できない場合は Cloud Spannerを検討してください
グローバル規模のトランザクション整合性、 スキーマ、SQLを提供し 自動同期レプリケーションで 高可用性を実現します
ペタバイト規模の容量も提供できます
Cloud Spannerを検討するのは リレーショナルデータベースの 容量を超えた場合 高スループットを得るために
シャーディングする場合 トランザクションの整合性、 グローバルデータ、強整合性が必要な場合 データベースを強化する場合などです
金融アプリや在庫管理アプリなどの ユースケースに適しています

Cloud Datastore App Engineアプリの 構造化データの格納に使用されます
App EngineとCompute Engineをまたぐ ソリューションを構築する際に Cloud Datastoreを統合ポイントにできます
フルマネージドサービスなのでシャーディングとレプリケーションは自動処理されます
高可用性と耐久性を兼ね備えているため自動でスケールして負荷に対処します
Cloud Bigtableとは異なり複数のデータベース行を対象としたトランザクションも実行できます
SQLのようなクエリも可能です
Cloud Datastoreには １日の無料割り当てがあるので
保存、読み取り、書き込み、削除などの 小規模オペレーションを無料で行えます
Cloud Datastoreを検討するのは 非構造化オブジェクトを格納する場合
またはトランザクションとSQLに似た クエリのサポートが必要な場合です
このサービスは テラバイト規模の容量を提供します
最大ユニットサイズは エンティティあたり１MBです

Cloud Bigtableを検討するのは 大量の構造化オブジェクトを格納する場合
Cloud BigtableはSQLクエリも 複数行のトランザクションもサポートしません
このサービスは ペタバイト規模の容量を提供します 最大ユニットサイズは セルあたり10MB、行あたり100MBです

Cloud Storageを検討するのは 大きな画像や映画などの 10MGを超える不変blobを格納する場合です
このサービスは ペタバイト規模の容量を提供します
最大ユニットサイズは オブジェクトあたり５TBです

Cloud SQLまたはCloud Spannerを 検討するのはオンライントランザクション処理システムで 完全SQLサポートが必要な場合です
容量については Cloud SQLはテラバイト規模 Cloud Spannerはペタバイト規模です

Cloud SQLのリードレプリカで対応できない 水平スケーリングが必要な場合は
Cloud Spannerの使用を検討してください

通常 BigQueryにデータを格納する目的は ビッグデータ分析とインタラクティブな クエリや機能を使用するためです
BigQueryは オンラインアプリの バックアップ保存先などには適しません

Cloud Datastoreは 半構造化データの格納に最適です
つまり App Engineアプリで 使用するデータです

Bigtableは 読み書きの多い 分析データの格納に最適です AdTech、金融、IoTのデータなどです

Cloud Storageは構造化、非構造化、 バイナリ、オブジェクトデータに最適です 画像、大きなメディアファイル、 バックアップなどです

SQLはウェブフレームワークと 既存アプリでの使用に最適です
ユーザー認証情報や顧客の注文を 格納する場合などです

Cloud Spannerは２TBを超える 大規模なデータベースアプリに最適です
金融取引やeコマースの ユースケースなどに適しています

Compute Engineは GCPのIaaSサービスです
クラウドでVMを実行して 永続ストレージと ネットワーキングを使用します

App EngineはGCPのPaaSサービスです

Kubernetes Engine
インフラの面倒な作業を省けるという点では IaaSサービスと似ています
PaaSサービスにも似ています
IaaSサービスはコンピューティング リソースを共有可能にするために
ハードウェアを仮想化するということです
App Engineにデプロイする場合 アプリに必要なサービスファミリーにアクセスします
必要な作業は 該当するサービスを使用したコードと 自己完結型ワークロードを作成して
独立したライブラリを組み込むことだけです アプリの需要が増加すると
プラットフォームがアプリをシームレスにスケールします
ワークロードとインフラとは 別に行われます スケールは迅速に行われますが
基のサーバーアーキテクチャーはコントロールできません
そこで登場するのがコンテナです
コンテナとは PaaSのようなワークロードの独立した環境によるスケーラビリティと
IaaS環境のようなOSとハードウェアの 抽象化層を提供するものです
コンテナはコードとその依存関係が存在する 見えないボックスであり
ファイルシステムとハードウェアの 独自のパーティションにのみアクセスできます
Windows、Linux、その他のOSでは プロセスとは実行中プログラムの インスタンスのことです
コンテナは新しいプロセスとして 迅速に起動します
各ホストで必要なのはコンテナをサポートするOSとコンテナランタイムだけです
この環境はPaaSのようにスケールする一方 IaaSと同等の柔軟性を備えています
コンテナによる抽象化はコードの移植性を高めます
OSとハードウェアを ブラックボックスとして扱えるからです
コードを開発環境からステージ環境、本番環境に移行する際も
ノートパソコンからクラウドに移行する際も 変更したり再構築したりする必要はありません
Kubernetesを使用すると 多数のホスト上の多数のコンテナのオーケストレーション スケール、
新しいバージョンのロールアウト 以前のバージョンへのロールバックを 簡単に行えます


Kubernetesはオープンソースの コンテナオーケストレーターです アプリの管理とスケーリングに役立ちます
Kubernetesが提供するAPIでは 許可されたユーザーのみが 複数のユーティリティを使って そのオペレーションを制御できます
Kubernetesでは「クラスタ」という 一連のノードにコンテナをデプロイできます
クラスタとは マスターコンポーネントのセットで システム全体と コンテナを実行する 一連のノードをコントロールするものです
Kubernetesでは ノードとは コンピューティングインスタンスであり
Google Cloudでは ノードとは Compute Engine内で実行されるVMです
Kubernetesを使用する際は 一連のアプリとアプリ間の対話方法を記述すれば
それらの実行方法がKubernetesで自動的に識別されます
Kubernetesを使用すると 前のレッスンで作成したような コンテナ化アプリを簡単に実行できますが
Kubernetesクラスタは どのように取得するのでしょうか
いつでもハードウェア上で自分で作成できます
あるいはVMを提供する環境でも可能です
自分で作成した場合は保守が必要になります
これは大変な作業です 保守作業に追われるのは 有意義な時間の使い方ではないため
Google Cloudでは Kubernetes Engineを提供しています
クラウド内のマネージドサービスとしての Kubernetesです
これを使えばGCP Consoleで Kubernetesクラスタを作成できます
Cloud SDKに含まれる gcloudコマンドでも作成できます
GKEクラスタはカスタマイズできます
各種マシンタイプ、多数のノード、 ネットワーク設定がサポートされています
進捗状況はConsoleで確認できます
Kubernetesがコンテナや 一連の関連コンテナをデプロイするときは 常に「ポッド」という 抽象化層の中にデプロイします
ポッドはKubernetesの最小デプロイ単位であり クラスタで実行中のプロセスのようなものです
アプリの一部であることも アプリ全体であることもあります
通常は各ポッドに １つのコンテナをデプロイしますが 強い依存関係を持つコンテナが複数ある場合は
単一のポッドにパッケージ化できます
これらは自動的にネットワークを共有し 共通のディスクストレージ ボリュームを使用できます
Kubernetesの各ポッドにはコンテナ用に固有のIPアドレスとポートが割り当てられます
ポッド内のコンテナ同士はローカルホストネットワークインターフェースで通信するため
デプロイされているノードは認識されません
kubectl runコマンドを実行すると ポッド内の実行中コンテナで Deploymentが起動されます
この例のポッド内で実行されるコンテナは nginxオープンソース ウェブサーバーのイメージです kubectlコマンドによって
リクエストしたバージョンのnginxイメージが Container Registryから取得されます
Deploymentとは何でしょう Deploymentは 同じポッドの レプリカのグループを表します
ノードのいずれかで障害が発生しても ポッドの実行状態を保つことができます
Deploymentにはアプリの一部またはアプリ全体を含めることができます
この例では nginxウェブサーバーが含まれています 実行中のnginxポッドを表示するには 「kubectl get pods」コマンドを実行します
デフォルトではDeployment内のポッドには クラスタ内からしかアクセスできません
では nginxウェブサーバーの コンテンツへのアクセスを インターネット上の全員に 許可するには？
Deployment内のポッドを一般公開するには ロードバランサを接続します
kubectl expose」コマンドで接続します KubernetesでServiceを作成し
そこにポッドの固定IPアドレスを設定します Serviceとは Kubernetesで 負荷分散を表す基本手法です
つまり Kubernetesに対して パブリックIPアドレスで外部ロードバランサを Serviceに接続するように指定し
クラスタの外部から アクセスできるようにしています
GKEではこうしたロードバランサは ネットワークロードバランサとして作成されます
これはCompute EngineがVMに提供する
マネージド負荷分散サービスの１つです
GKEではコンテナで この負荷分散を簡単に使用できます
このIPアドレスにアクセスするクライアントは Service背後のポッドにルーティングされます
この例ではポッドは１つしかありません
シンプルなnginxポッドです ではServiceとは厳密には何でしょう
Serviceは一連のポッドをグループ化して 安定したエンドポイントを提供するものです
ネットワークロードバランサが 管理するパブリックIPアドレスです
ただし 他の選択肢もあります ではなぜServiceが必要なのでしょう
ポッドのIPアドレスを 直接使用できないのでしょうか たとえばアプリがフロントエンドと
バックエンドで構成されているとします フロントエンドからバックエンドには
ポッドの内部IPアドレスでアクセスできるので Serviceは不要なはずです
しかし管理の問題があります
Deploymentがポッドを作成して破棄すると
ポッドに固有のIPアドレスが割り当てられますが このアドレスは変わります
Serviceは安定したエンドポイントを提供します

Kubernetesでは「クラスタ」という 一連のノードにコンテナをデプロイできます
クラスタとは マスターコンポーネントのセットで システム全体と コンテナを実行する 一連のノードをコントロールするものです
Kubernetesでは ノードとは コンピューティングインスタンスであり
Google Cloudでは ノードとは Compute Engine内で実行されるVMです
Kubernetesを使用する際は 一連のアプリとアプリ間の対話方法を記述すれば それらの実行方法がKubernetesで自動的に識別されます
Kubernetesを使用すると 前のレッスンで作成したような コンテナ化アプリを簡単に実行できますが
Kubernetesクラスタは どのように取得するのでしょうか
いつでもハードウェア上で自分で作成できます あるいはVMを提供する環境でも可能です
自分で作成した場合は保守が必要になります これは大変な作業です
保守作業に追われるのは 有意義な時間の使い方ではないため Google Cloudでは Kubernetes Engineを提供しています
クラウド内のマネージドサービスとしての Kubernetesです
これを使えばGCP Consoleで Kubernetesクラスタを作成できます
Cloud SDKに含まれる gcloudコマンドでも作成できます
GKEクラスタはカスタマイズできます 各種マシンタイプ、多数のノード、 ネットワーク設定がサポートされています
GKEを使用してKubernetesクラスタを作成するコマンドの一例を紹介しましょう
「gcloud container clusters create k1」です このコマンドでは 「K1」というクラスタが作成されます
 すぐに使える構成済みのクラスタです 進捗状況はConsoleで確認できます
 Kubernetesがコンテナや 一連の関連コンテナをデプロイするときは 常に「ポッド」という 抽象化層の中にデプロイします
ポッドはKubernetesの最小デプロイ単位であり
クラスタで実行中のプロセスのようなものです
アプリの一部であることも アプリ全体であることもあります
通常は各ポッドに １つのコンテナをデプロイしますが
強い依存関係を持つコンテナが複数ある場合は 単一のポッドにパッケージ化できます
これらは自動的にネットワークを共有し 共通のディスクストレージ ボリュームを使用できます
Kubernetesの各ポッドにはコンテナ用に固有のIPアドレスとポートが割り当てられます
ポッド内のコンテナ同士はローカルホスト ネットワークインターフェースで通信するため
デプロイされているノードは認識されません
Kubernetesでポッド内のコンテナを 実行する１つの方法は「kubectl run」コマンドです
このコマンドを使えばすぐに開始できます kubectl runコマンドを実行すると
ポッド内の実行中コンテナで Deploymentが起動されます
この例のポッド内で実行されるコンテナは nginxオープンソース ウェブサーバーのイメージです
kubectlコマンドによって リクエストしたバージョンのnginxイメージが
Container Registryから取得されます
Deploymentとは何でしょう
Deploymentは 同じポッドの レプリカのグループを表します
ノードのいずれかで障害が発生しても ポッドの実行状態を保つことができます
Deploymentにはアプリの一部 またはアプリ全体を含めることができます
この例では nginxウェブサーバーが含まれています
実行中のnginxポッドを表示するには 「kubectl get pods」コマンドを実行します
デフォルトではDeployment内のポッドには クラスタ内からしかアクセスできません
ではnginxウェブサーバーの コンテンツへのアクセスを インターネット上の全員に 許可するには？
Deployment内のポッドを一般公開するには ロードバランサを接続します
「kubectl expose」コマンドで接続します KubernetesでServiceを作成し
そこにポッドの固定IPアドレスを設定します
Serviceとは Kubernetesで 負荷分散を表す基本手法です
つまり Kubernetesに対して パブリックIPアドレスで外部ロードバランサを
Serviceに接続するように指定しクラスタの外部からアクセスできるようにしています
GKEではこうしたロードバランサはネットワークロードバランサとして作成されます
これはCompute EngineがVMに提供する
マネージド負荷分散サービスの１つです
GKEではコンテナでこの負荷分散を簡単に使用できます
このIPアドレスにアクセスするクライアントは Service背後のポッドにルーティングされます
この例ではポッドは１つしかありません シンプルなnginxポッドです
ではServiceとは厳密には何でしょう
Serviceは一連のポッドをグループ化して安定したエンドポイントを提供するものです
この例では ネットワークロードバランサが 管理するパブリックIPアドレスです
他の選択肢もあります ではなぜServiceが必要なのでしょう
ポッドのIPアドレスを直接使用できないのでしょうか
たとえばアプリがフロントエンドと バックエンドで構成されているとします
フロントエンドからバックエンドには ポッドの内部IPアドレスでアクセスできるので Serviceは不要なはずです
しかし管理の問題があります Deploymentがポッドを作成して破棄すると
ポッドに固有のIPアドレスが割り当てられますが このアドレスは変わります
Serviceは安定したエンドポイントを提供します
Kubernetesについて学習を進めれば 内部のアプリバックエンドに適する 他のServiceタイプがわかってくるでしょう
「kubectl get services」コマンドで ServiceのパブリックIPアドレスを確認できます
クライアントはこのアドレスで リモートからnginxコンテナにアクセスできます 追加の処理能力が必要になったら
「kubectl scale」コマンドで Deploymentをスケールできます
この例のDeploymentには ３つのnginxウェブサーバーがあります いずれもServiceの背後にあり
１つの固定IPアドレスでアクセスできます 自動スケーリングでも 便利なパラメータを設定できます
たとえばCPU使用率に応じて Deploymentを自動スケールするとします
このコマンドでは 最小ポッド数を10に指定しています 最大ポッド数は15です
スケールアップの基準として CPU使用率が処理能力の80％に達した時点で
ポッド数をスケールアップします ここまでは 命令型コマンドの実行方法を説明しました
exposeやscaleなどです
命令型は Kubernetesの 段階的な学習やテストには役立ちますが
Kubernetesの真の強みは宣言型です
コマンドを実行する代わりに 構成ファイルを渡します
このファイルで目的の状態を指定すれば Kubernetesがその方法を判断します
こうした構成ファイルは管理ツールになります
変更を加えるには 構成ファイルを編集し 変更後のバージョンをKubernetesに提示します
スライドのコマンドは これまでの作業に基づく構成ファイルの 操作の開始点として使用できます
バージョン管理システムに保存して インフラの変更を追跡することもできます
この例のDeployment構成ファイルは nginxポッドのレプリカ数を ３として宣言しています
selectorフィールドを定義して 特定のポッドをレプリカとして グループ化する方法を指示しています
ポッドを特定できるのは ラベルが共有されているためです
該当するポッドのアプリには 「nginx」のラベルが付いています
３つではなく５つのレプリカを実行する場合 Deployment構成ファイルを編集して ３を５に変更するだけです
非常に柔軟です そして「kubectl apply」コマンドを実行して 更新後のファイルが使用されるようにします
「kubectl get replicasets」コマンドで レプリカを表示して更新後の状態を確認します
さらに「kubectl get pods」コマンドで ポッドがオンラインになるのを観察します この出力例では５つのポッドがすべて 実行状態になっています
現時点で GKEでは nginxポッドの５つのコピーが実行されていて １つのServiceで５つのポッドへの トラフィックをプロキシしています
Kubernetesではこの手法により 負荷を分散してServiceをスケールします
前のレッスンでは Pythonアプリをコンテナ化しました それをnginxに置き換えて
同じツールを使って デプロイとスケールを行えます 最後にアプリのバージョンを 更新する方法を説明します
コンテナを更新して新しいコードを できるだけ早く適用する必要があります
しかし すべての変更を一度に ロールアウトするのはリスクが伴います
アプリの再ビルドと再デプロイの間 ユーザーがダウンタイムを 経験するのは避けたいはずです
そのため Deploymentには 更新戦略という属性があります
これはローリングアップデートの例です Deploymentのローリングアップデートを選択して
管理対象ソフトウェアの 新しいバージョンを指定すると Kubernetesが新しいバージョンの
ポッドを１つずつ作成し 各ポッドが使用可能になるのを待ってから
古いバージョンのポッドを破棄します ローリングアップデートを使用すれば ダウンタイムを生じさせることなく
アプリのバージョンを迅速に更新できます

典型的なオンプレミスの 分散システムアーキテクチャを見てみましょう
クラウドが登場するまで 企業はこの方法で コンピューティングニーズに対応していました
ほとんどの企業向けアプリケーションは 分散システムとして設計されます
サービス提供に必要なワークロードが 複数のネットワークサーバーに分散されます
ワークロードをマイクロサービスに分割し 管理と拡張を容易にする方法として ここ数年でコンテナの人気が高まっています
従来 企業向けシステムとそのワークロードは コンテナ化の有無にかかわらず
オンプレミスに格納されてきました
つまり自社のネットワークやデータセンター内の 一連の大容量サーバー上に格納されていました
この場合 アプリのコンピューティングニーズに 利用可能なリソースで対応しきれなくなると より高性能なサーバーが必要になります
サーバーをインストールするには ネットワークの変更や拡張が必要です
新しいサーバーを構成して そこにアプリとその依存関係を読み込まなければ
リソースのボトルネックを解決できません
このようなオンプレミスの アップグレードを完了するには 数か月から１年以上かかることもあります
サーバーの平均耐用年数が３～５年であることを 考えるとかなりの費用がかかります
今すぐコンピューティング能力の 増強が必要な場合はどうでしょう
または 一部のワークロードを オンプレミスからクラウドに再配置して
コスト削減と高可用性を実現したい一方で オンプレミスネットワークから アプリを移行したくない場合はどうでしょう
クラウドでしか利用できない サービスが必要な場合はどうでしょう
そこで役立つのが最新のハイブリッド/ マルチクラウドアーキテクチャです
この方法ではシステムインフラの一部を オンプレミスに維持したまま 他の部分をクラウドに移行できます
したがってニーズに応じた 固有の環境を構築できます ご自分のペースで特定のワークロードだけを クラウドに移行できます
なぜなら完全に移行する必要はないからです
クラウドの柔軟性、スケーラビリティ、 コスト削減を実現しながら 移行を決めたワークロードを実行できます
機械学習、コンテンツキャッシュ、データ分析、 長期保存、IoTなどの専門サービスも リソースツールキットに追加できます
ハイブリッドアーキテクチャによる 分散システムとサービスの運用は 最近盛んに話題になっています
AnthosはGoogleの ハイブリッド/マルチクラウドソリューションで
分散システムとサービス管理ソフトウェアの 最新技術が採用されています
Anthosフレームワークの基盤となるのは オンプレミスのKubernetesと Google Kubernetes Engine（GKE）です
これをアーキテクチャの基盤として ポリシーベースのライフサイクルをサポートする
中央コントロールプレーンを介し ハイブリッド/マルチクラウド環境を一元管理します
Anthosにはアプリの整合性をモニタリングし 維持するためのツールも揃っているので
オンプレミス、クラウド、複数のクラウドでも ネットワーク全体で整合性を維持できます
Anthosで最新のハイブリッドインフラスタックを 段階的に構築してみます
ハイブリッドネットワークのクラウド側の GKEを見てみましょう
GKEはコンテナ化アプリをデプロイするためのマネージド型の本番環境です
高可用性とSLAによりシームレスに動作します
Certified Kubernetesが実行されるためクラウドとオンプレミス間を自由に移動できます
自動ノード修復、自動アップグレード、 自動スケーリングも組み込まれています
リージョンクラスタを使用するため複数のマスターで高可用性を維持します
複数のゾーン間でノードのストレージをレプリケートします
ハイブリッドネットワークのオンプレミス側にもGKEがデプロイされます
オンプレミス側のGKEは本番環境レベルのターンキーKubernetesでベストプラクティスの構成が事前に読み込まれています
Googleが検証、テストしたKubernetesの 最新リリースに簡単にアップグレードできます
GCP上のコンテナサービスにもアクセスできます
たとえばCloud Build、Container Registry、 監査ロギングなどです
Istio、Knative、Marketplaceの 各ソリューションも統合されます
クラウド環境とオンプレミス環境での Kubernetesのバージョンと操作は一貫しています
クラウドとオンプレミスのGKEはどちらも Marketplaceと統合するため
ネットワーク内のクラスタは オンプレミスでもクラウドでも コンテナ化アプリの 同じリポジトリにアクセスできます
これによりネットワークのどちら側でも 同じ構成を使用できるためアプリの開発時間が短縮されます
正しい構成をどこにでもレプリケートしてクラスタ間の整合性を維持できます
アプリで何百ものマイクロサービスを使用してワークロードを処理することもあります
これだけの数のサービスを追跡して 正常性をモニタリングするのは至難の業です
AnthosはIstioオープンソースサービスメッシュとして勘に頼った判断をマイクロサービスの管理とセキュリティから完全に排除します
サービスメッシュのレイヤはハイブリッド ネットワークと通信する際にCloud Interconnectで データを同期して渡します
StackdriverはGogle Cloudに組み込まれた ロギングとモニタリングのソリューションです
完全に管理されたロギング、指標の収集、 モニタリング、ダッシュボード、アラートにより
ハイブリッド/マルチクラウドネットワークの あらゆる側面を監視します
簡単に構成できて高性能なクラウドベース可観測性ソリューションをお求めの場合Stackdriverが最適です
１つのダッシュボードですべての環境をモニタリングすることも可能です
最後に Anthos Configuration Managementはクラスタ構成の信頼できる唯一の情報源を提供します
この情報源が保持されるポリシーリポジトリは 実際にはGitリポジトリです
この図のリポジトリは オンプレミス側にありますが クラウドでホストすることもできます
Anthos Configuration Managementエージェントは ポリシーリポジトリを使って
各環境でローカルに構成を適用することで複数の環境でクラスタを所有する際の複雑さを省きます
Anthos Configuration Managementでは管理者とデベロッパー向けに
単一のリポジトリコミットでコード変更をデプロイする機能も提供しています
名前空間による構成の継承も実装できます

Compute EngineとKubernetes Engine
この２つの共通点はアプリを実行する インフラを選択できることです
Compute EngineではVM
Kubernetes Engineでは コンテナを基に選択します
 しかし インフラを 気にしたくない場合もあります コードのみに集中したい場合です
 そのためにあるのがApp Engineです
 PaaSは 「サービスとしてのプラットフォーム
 App Engineプラットフォームが コードの実行に必要なハードウェアとネットワークインフラを管理します
App Engineにアプリをデプロイするには コードを提供するだけです
残りの処理はApp Engineが行います
App Engineには多くのウェブアプリに必要なサービスが組み込まれています
NoSQLデータベース、インメモリキャッシュ、 負荷分散、ヘルスチェック、ロギング ユーザー認証機能などです
これらのサービスを利用する アプリコードを作成すれば App Engineがサービスを提供します
App Engineは受信トラフィック量に応じて アプリを自動的にスケールします
料金は使用したリソースの分だけです サービスのプロビジョニングや保守も不要です
したがってApp Engineは ワークロードが変動しやすいか予測できない
ウェブアプリやモバイルバックエンドに 特に適しています
App Engineにはスタンダード環境と フレシキブル環境の２つがあります

シンプルなのはスタンダード環境です フレキシブル環境よりもデプロイが簡単できめ細かい自動スケーリングが可能です
どちらの環境でも 一部のサービスに １日の無料割り当て使用量が設定されています
しかしスタンダード環境の特徴は 使用量の少ないアプリは 無料で実行できる場合があることです
GoogleではApp Engineソフトウェア開発 キットを複数言語で提供しているため
アプリをローカルでテストしてから App Engineサービスにアップロードできます
SDKには単純な デプロイコマンドも含まれています コードは実際にどこで実行されるのでしょうか
実行可能バイナリとは 何を意味するのでしょうか
App Engineではこのバイナリを「ランタイム」と呼びます
スタンダード環境ではGoogle提供のランタイムを使用します
選択肢について説明します
App Engineスタンダード環境で 使用できるランタイムは
特定のバージョンの Java、Python、PHP、Goです
ランタイムにはApp Engine API対応の ライブラリも組み込まれています
多くのアプリでは スタンダード環境のランタイムと ライブラリだけで十分です
他の言語でコードを作成する場合 スタンダード環境は適しません
フレキシブル環境をご検討ください
スタンダード環境ではコードの制限があり
サンドボックスでコードが実行されます
これはハードウェア、OS、物理的なサーバーの 場所に依存しないソフトウェア構成概念です
このサンドボックスこそが スタンダード環境でアプリをきめ細かく
スケールして管理できる理由の１つです
通常 サンドボックスには いくつかの制約があります
たとえば アプリは ローカルファイルシステムに書き込めません
データを存続させるには データベースサービスに書き込む必要があります
また アプリが受信するすべてのリクエストは 60秒でタイムアウトします
任意のサードパーティソフトウェアは インストールできません
以上の制約が問題になる場合は フレキシブル環境を選択してください
これはApp Engineスタンダード環境の 使用方法を示す図です
App Engine SDKを使ってアプリを開発し テストバージョンをローカルで実行します
準備ができたら SDKを使用して アプリをデプロイします
各App Engineアプリは GCPプロジェクト内で実行されます
App Engineが自動的にサーバーインスタンスを
プロビジョン、スケール、負荷分散します 一方 アプリは専用のAPIを使って
各種サービスを呼び出すことができます
たとえば データを保持するNoSQLデータストア
そのデータをキャッシュするMemcache 検索、ロギング、ユーザーログイン ユーザーリクエスト以外によって
アクションを開始できる タスクキューやタスクスケジューラなどです

スタンダード環境のサンドボックスモデルの制約がネックになっているとします
それでもApp Engineを利用したい場合 App Engineフレキシブル環境があります
App Engineフレキシブル環境では サンドボックスではなく App Engineを実行するコンテナを指定します
アプリはCompute EngineのVM上の Dockerコンテナ内で実行されます
App Engineが Compute Engine VMを管理します
ヘルスチェックを行い 必要に応じて修復します
VMを実行する地理的リージョンは ユーザーが選択します
さらに下位互換性を維持するための重要なOS更新も自動的に適用されます
その結果ユーザーはコードに集中できます
App Engineフレキシブル環境のアプリは
標準ランタイムを使用し App Engineのデータストア、Memchach、タスクキューなどのサービスにアクセスできます
スタンダード環境のほうがアプリのインスタンスを短時間で起動できます
ただしアプリを実行するインフラへの アクセスは制限されます
フレキシブル環境では アプリを実行するVMにSSHで接続できます
ローカルディスクへの書き込みが可能です
サードパーティソフトウェアも インストールできます
アプリがApp Engineを介さずに ネットワークを呼び出すことも可能です
スタンダード環境では アプリが完全にアイドル状態であれば 請求料金はゼロになります
前述のようにApp Engineは Dockerコンテナを使用するため
App EngineとKubernetes Engineの 違いも気になると思います
App Engineスタンダード環境は アプリのデプロイとスケーリングを 最大限コントロールしたい場合に適しています
Kubernetes Engineではアプリオーナーは Kubernetesの柔軟性を活用できます
App Engineフレキシブル環境は これらの中間に位置するものです
App Engine環境ではコンテナを 目的を達成する手段として扱いますが Kubernetes Engineでは コンテナは構築の基盤になります

ソフトウェアサービスの実装は 複雑で変わりやすいものです
たとえば 他のソフトウェアが そのサービスを利用するたびに
その動作を詳細に知る 必要があるとしたら非常に面倒です
そのためアプリデベロッパーは ソフトウェアを構造化して 簡潔で明快なインターフェースで 不要な詳細を抽象化し その情報をドキュメント化します
これがAPIです APIが変更されない限り 基盤となる実装はいくらでも変更できます
APIを利用している他のソフトウェアがその変更を知る必要はありません
機能の追加や廃止のためにAPIの変更が必要になることもあります
こうしたAPIの変更を適切に行うため デベロッパーはAPIのバージョン管理を行います
バージョン２のAPIにバージョン１にはない呼び出しが含まれるとします
このAPIを利用するプログラムでは呼び出しの際にAPIバージョンを指定できます
APIへの対応は非常に重要です GCPには２つのAPI管理ツールが用意されています
問題に対してのアプローチが異なりそれぞれの長所があります
ソフトウェアサービスとGCPのバックエンドを開発しているとします
APIを簡単に公開して信頼できるデベロッパーのみに使用してもらいたいと考えています
使用状況を監視して記録する
APIが呼び出し側のエンドユーザーを把握するための統一的な方法も必要です
そこで役立つのがCloud Endpointsです Cloud Endpointsでは簡単にデプロイできる
プロキシを使用して必要な機能を実装できます
さらにAPIコンソールの使いやすい インターフェースで機能を管理できます
Cloud EndpointsはGCPで実行される
アプリをサポートします アプリで使用している言語やクライアントテクノロジーは問いません
Apigee EdgeもAPIプロキシを 開発、管理するためのプラットフォームです
ただし位置付けが異なります レート制限、割り当て、分析などの ビジネス的な問題に重点を置いています
Apigee Edgeの多くのユーザーは 他社にソフトウェアサービスを提供しているため
こうした機能が重要になります Apigee EdgeはGCP外部の バックエンドサービスにも対応するため
エンジニアがレガシーアプリを 「分解」するときによく使われます
モノリシックアプリを 一度に移行することはリスクがありますが
Apigee Edgeを使用すれば サービスを１つずつ分離し レガシーアプリが完全に使用されなくなるまで
マイクロサービスに分解して 順番に実装することができます

開発、デプロイ、モニタリング用の 一般的なツールはGCPでも機能します
GCPに密接に統合されているツールも使用できます
GCPの多くのお客様はGitを使用して ソースコードツリーを保管、管理しています
独自のGitインスタンスを実行するかホスト型Gitプロバイダを使用しています
独自のインスタンスの利点は完全な制御です
ホスト型Gitプロバイダの利点は作業負担の軽減です
３つ目の手段としてコードの公開をGCPプロジェクトに限定してIAM権限で保護しながら
Gitインスタンスの保守を省けるとしたらどうでしょう
その手段がまさにCloud Source Repositoriesです
Gitバージョン管理によってチームによるアプリやサービスの開発をサポートします
App Engine、Compute Engine、Kubernetes Engineで実行するアプリなどです
Cloud Source RepositoriesではプライベートGitリポジトリをいくつでも使用できるので
クラウドプロジェクトの関連コードを任意の方法で整理できます
Cloud Source Repositoriesにはソースビューアもあります
GCP Console内からリポジトリのファイルを参照して表示できます
多くのアプリにはイベントで駆動される部分があります
たとえばユーザーが画像をアップロードできるアプリではアップロードのたびに画像を複数の方法で処理する必要があります
標準の画像形式に変換し複数のサムネイルを作成してサイズ別にリポジトリに保管するなどです
このような関数はアプリに統合できますがそれを処理するコンピューティングリソースが必要です
必要な画像処理を行う単一目的の関数を作成するだけで画像がアップロードされるたびに自動的に実行されると便利です
それを可能にするのがCloud Functionsです
サーバーやランタイムバイナリを気にする必要はありません
GCPのNode.js環境対応のコードをJavaScriptで作成して起動の条件を構成するだけです
サーバーの使用料金は不要です関数の実行時間分の料金を100ミリ秒単位で支払うだけです
Cloud Functionsのトリガーの基準は Cloud Sotrage、Cloud Pub/Sub、HTTP呼び出しのイベントです
Cloud Functionを設定するには まず対象のイベントを選択します
Cloud Functionsに各イベントタイプを指示します
この宣言は「トリガー」と呼ばれます
次に JavaScript関数をトリガーに関連付けます
以降は該当するイベントが発生するたびに関数が応答します
マイクロサービスアーキテクチャを使用するアプリなどは Cloud Functions内で完全に実装できます
Cloud Functionsは既存のアプリを拡張するためにも使用されています スケーリングの心配がなくなります


命令型アプローチではこれらを手動で行います
つまり意図した環境を設定するためのコマンドを見つける必要があります環境に変更を加える場合は
新しい状態に変更するためのコマンドを見つけます
環境のクローンを作成するにはすべてのコマンドを再び実行します
これは大変な作業です
テンプレートを使用したほうが効率的ですテンプレートとは目的とする環境の仕様です
命令型に対して宣言型の方法です
GCPのDeployment Managerではこれが可能です
このインフラ管理サービスはGCPリソースの作成と管理を自動化します
これを使用するにはテンプレートファイルを作成しYAMLマークアップ言語またはPythonを使用して環境に必要なコンポーネントを記述します
そのテンプレートをDeployment Managerに渡すと記述された環境の作成に必要なアクションが判断され実行されます
環境を変更する場合はテンプレートを編集し環境を更新するようDeployment Managerに指示します
テンプレートを保管して バージョン管理するには Cloud Source Repositoriesを利用します

モニタリングによりアプリに加えた変更の有効性を判断できます
アプリがダウンしたと苦情が来ても情報をもとに落ち着いて対処できます
Stackdriverはモニタリング、 ロギング、診断用のGCPツールです
Stackdriverでは 各種シグナルにアクセスできます
インフラプラットフォーム、 VM、コンテナ、ミドルウェア アプリ層、ログ、指標、 トレースなどのシグナルです
アプリの正常性、パフォーマンス、 可用性の分析情報を取得できます
Stackdriverのコアコンポーネントは Monitoring、Logging、Trace、 Error Reporting、Debuggingです
Stackdriver Monitoringがチェックするのは クラウド環境内のウェブアプリや インターネットでアクセスできる
その他のサービスのエンドポイントです
稼働時間チェックを構成して URL、グループのほか インスタンスや ロードバランサなどのリソースを関連付けます
基準に基づくアラートも設定できます
アクションが必要なヘルスチェック結果や稼働時間の減少などの基準です
Monitoringは多数の通知ツールと 組み合わせて使用できます
アプリの状態を可視化する ダッシュボードも作成できます
Loggingではアプリのログを 表示、フィルタ、検索できます
ログの内容に基づく指標を定義して ダッシュボードとアラートに 統合することもできます
ログはBigQuery、Cloud Storage、 Cloud Pub/Subにエクスポートできます
Error Reportingは アプリのエラーを追跡、グループ化し 新しいエラーが検出されると通知します
TraceではApp Engineアプリの レイテンシを抜き出して URLごとの統計レポートを作成できます
Debuggerでは別の方法を使用できます
アプリの本番環境データを ソースコードに関連付けて 本番環境の任意のコード位置でアプリの状態を調べられるようにします
したがってログステートメントを 追加しなくてもアプリの状態を確認できます
Debuggerが本領を発揮するのは アプリのソースコードが使用できる場合です
したがって Cloud Source Repositoriesなどの リポジトリにコードを保管すると役立ちます


Google Cloudの ビッグデータソリューションは 有用なデータ分析情報によってビジネスと ユーザーエクスペリエンスを変革します
Googleではこれを「統合サーバーレス プラットフォーム」と呼んでいます
つまり「サーバーレス」とはジョブを実行するインスタンスのプロビジョニングが不要ということです
フルマネージドサービスで かかるのはリソース使用分の料金だけです
プラットフォームは統合型です
Apache Hadoopはビッグデータ対応のオープンソースフレームワークです
ベースとなるのはGoogleが開発したMapReduceプログラミングモデルです(reduce　減らす)
MapReduceモデルの最もシンプルな形では 「map関数」と呼ばれる関数が並行して膨大なデータセットを処理し
それぞれに中間結果を生成します
そして別の「reduce関数」という関数がすべての中間結果に基づいて最終的な結果セットを生成します
「Hadoop」という用語は Apache Hadoop自体と関連プロジェクトの総称としてよく使用されます
Apache Spark、Apache Pig、 Apache Hiveなどのプロジェクトです
Cloud Dataprocという高速で使いやすいマネージドサービスを使用すると
Hadoop、Spark、Hive、Pigを GCP上で実行できます
Hadoopクラスタをリクエストするだけで90秒以内にクラスタが自動作成されます
クラスタを構成するCompute Engine VMの 数とタイプは指定できクラスタの実行中に
処理能力を増減する必要がある場合はスケールアップまたはダウンできます
クラスタではHadoopソフトウェアのデフォルト構成を使用することも構成をカスタマイズすることもできます
さらにStackdriverでクラスタをモニタリングできます
Hadoopジョブをオンプレミスで実行する場合はハードウェアへの資本投資が必要です
Cloud Dataprocで実行すればクラスタの存続中に使用したハードウェアリソースの料金を支払うだけです
料金設定は時間単位ですがCloud Dataprocの課金は秒単位です
すべてのCloud Dataprocクラスタは 秒単位で課金されます
最小課金時間は１分です クラスタを使い終わって削除すれば 課金は停止されます
オンプレミスのハードウェア資産よりも 俊敏にリソースを使用できます
費用を節約するためにCloud Dataprocでの一括処理に プリエンプティブルCompute Engine インスタンスを使用することもできます
終了されても正常に再起動できるジョブであればこの方法でインスタンスの費用を大幅に削減できます
Dataprocクラスタの費用に含まれるのはインスタンスの費用だけではありませんがかなりの部分を占めます
データがクラスタに取り込まれたらSparkとSpark SQLを使用して データマイニングを行えます
MLibというApache Sparkの 機械学習ライブラリを使用して 機械学習でパターンを検出することもできます

Cloud Dataprocが役立つのはデータセットのサイズが明らかな場合やクラスタサイズを自分で管理する場合です
一方リアルタイムのデータやデータのサイズとレートが予測できない場合はCloud Dataflowが最適です
この統合プログラミングモデル （マネージドサービス）を使えば 広範なデータ処理パターンを 開発して実行できます
抽出、変換、読み取り（ETL）から、 バッチ計算、連続計算にまで対応します
Dataflowで作成するデータパイプラインは バッチデータとストリーミングデータの 両方に適用できます
クラスタの起動も インスタンスのサイズ変更も不要です
処理に必要なリソースが何であれCloud Dataflowがリソース管理を完全に自動化します
Cloud Dataflowを使用すればリソース管理やパフォーマンス最適化などの作業から解放されます
この例のDataflowパイプラインでは「ソース」で BigQueryテーブルからデータを読み込み
「変換」で各種の方法でデータを処理し「シンク」で出力をCloud Storageに書き込んでいます
変換にはMapオペレーションとReduceオペレーションがあり
非常に高機能なパイプラインを構築できます
パイプラインの各ステップは 柔軟にスケールされます
クラスタの起動や管理は不要です
このサービスがすべてのリソースをオンデマンドで提供します
最適化された組み込みの自動パーティショニング機能により遅れている作業が動的に再調整されるためホットキーに関する懸念が減ります
過度に大きい入力チャンクが 同じクラスタにマップされるといった懸念です
Dataflowはさまざまな ユースケースで使用されます
前述のとおり これは汎用のETLツールです
さらにデータ分析エンジンとして使用するとさまざまな分野で役立ちます
たとえば不正検出、金融サービス、IoT分析、製造 ヘルスケア、ロジスティクス、クリックストリーム
小売業のPoSや セグメンテーション分析などです
パイプラインは外部サービスを含む 複数のサービスをオーケストレートできるため
パーソナライズされたゲーム体験などを 提供するリアルタイムアプリに使用できます

動的パイプラインではなく膨大なデータを探索してデータを実行したいとします
膨大なデータセットに対する アドホックSQLクエリが必要です
これを可能にするのがBigQueryです
ペタバイト規模で低料金のフルマネージド分析データウェアハウスです
インフラの管理は不要なので 有用な情報を見つけるための データ分析に専念できます
使い慣れたSQLを使えるだけでなく従量課金制モデルを利用できます
BigQueryにデータを取り込むのは簡単です
Cloud Storageや Cloud Datastoreから読み込んだり
BigQueryに1秒あたり最大10万行をストリーミングしたりできます
BigQuery内の数テラバイトのデータに対して わずか数秒でSQLクエリを実行できます
Googleインフラの処理能力を利用するからです
さらにCloud Dataflow、Hadoop、Sparkを使ってBigQuery内のデータを簡単に読み書きできます
BigQueryはスタートアップ企業から Fortune 500企業まで あらゆる組織で使用されています
小さな組織では 毎月の無料割り当てが 大きな組織では シームレスなスケーリングと 可用性99.9％のSLAが好評です
Googleのインフラと同じく BigQueryもグローバルです
BigQueryではデータを保持する リージョンを指定できます
たとえばデータをヨーロッパで保持する場合 ヨーロッパにクラスタを設定する必要はありません
データセットを作成する EUロケーションを指定するだけです
USとアジアのロケーションも選択できます BigQueryではストレージと 計算処理が分離されるため
クエリとデータストレージの 料金は別々に支払います
つまり クエリの料金を支払うのは 実際に実行しているときだけです
BigQuery内のデータへの ユーザーアクセスを完全に制御でき
プロジェクト間での データセットの共有も制御できます
料金やパフォーマンスに影響しない データセットを共有した場合
共有相手が実行したクエリの料金は 共有相手が支払います
BigQueryに長期間保存されているデータには長期保存割引料金が自動的に適用されます
データの保存期間が90日に達すると 自動的にストレージ料金が引き下げられます

リアルタイムのイベントを扱うときは メッセージングサービスが役立ちます
Cloud Pub/Subです ストリーム分析のための シンプルで信頼性の高いスケーラブルな基盤です
これを使えば 構築した個別のアプリ間で メッセージを送受信できます
アプリが分割されるため 独立してスケールできます
Pub/Subの「Pub」はパブリッシャーの略、 「Sub」はサブスクライバーの略です
アプリがメッセージをパブリッシュすると １つ以上のサブスクライバーが受信します
メッセージの受信は必ずしも 同期する必要はありません そのためPub/Subはシステムを分離するのに便利です
「at least once」（最低 １ 回）の 配信を低レイテンシで行う設計になっています
「at-least-once配信」とは メッセージが複数回配信される可能性が
 わずかにあることを意味します アプリの作成時は この点に注意してください
Cloud Pub/Subはオンデマンドでスケールし １秒あたり100 万件以上の メッセージを処理できます
IoTシステムなどです ストリーミングデータを分析する場合 Cloud DataflowとPub/Subを 組み合わせて使用できます
GCPのコンピューティングプラットフォームで 構築されたアプリにも使用できます
サブスクライバーを構成してpushまたはpullベースでメッセージを受信します
つまり サブスクライバーが 新着メッセージの通知を受けるようにするか
定期的に新着メッセージを確認するように構成できます
ノートブックのホスト環境として 一般的なのはProject Jupyterです
Pythonコードを含むウェブベースの ノードブックを作成して保守できるので
インタラクティブにコードを実行して 結果を確認できます Cloud Datalabはこの自然な手法から 管理作業を取り除きます
Compute Engine VM内で稼働するからです
Cloud Datalabを使うには VMのタイプと VMを実行するGCPリージョンを指定します
Datalabを起動すると すぐに使える インタラクティブなPython環境が提供されます
複数のGCPサービスが自動的にオーケストレートされるのでデータの探索に専念できます
料金は使用したリソースの分だけです
Datalab自体の追加料金はありません
BigQuery、Compute Engine、 Cloud Storageと統合されているため
データにアクセスする際の認証の煩わしさはありません
稼動中はGoogle Chartsでデータを可視化したり 線グラフを描画したりできます
活発なPythonコミュニティの公開ノートブックで 学習することもできます
統計や機械学習などに対応する 多数のパッケージもあります

機械学習（ML）を使用している主要なGoogleアプリには YouTube、フォト、Googleモバイルアプリ、 Google翻訳などがあります
Google MLプラットフォームがクラウドサービスとして提供されているので
革新的な機能を独自のアプリに追加できます
Cloud Machine Learning Platformは最新のMLサービスを提供します
事前トレーニング済みモデルを備え カスタムモデルも生成できます
他のGCPサービスと同様にサービスの幅は広く汎用サービスからカスタマイズ済みのサービスまであります
TensorFlowという オープンソースのソフトウェアライブラリは ニューラルネットワークなどのMLアプリで 並外れた効果を発揮します
これはGoogle Brainが社内用に開発し世界に役立つようオープンソース化したものです
TensorFlowはどこでも実行できますが理想的な場所はGCPです
MLモデルには大量のオンデマンドリソースとトレーニングデータが必要だからです
TensorFlowでは Tensor Processing Unit（TPU）も利用できます
これはTesorFlowでのMLワークロードを加速化できるハードウェアデバイスです
GCPではCompute Engine VMを使って クラウドでTPUを利用できます
Cloud TPU１個あたりのパフォーマンスは 最大180 TFLOPSです
料金は使用した分だけなので先行資本投資は不要です
より高レベルな マネージドサービスが必要な場合はGoogle Cloud Machine Learning Engineを
使用すればサイズを問わずあらゆるデータのMLモデルを簡単に構築できます
任意のTensorFlowモデルを使用して大規模なトレーニングをマネージドクラスタ上で行えます
アプリにさまざまなML機能を追加したいが機能の細々とした仕組みについては気にしたくない場合は
Google Cloudの特定の目的用の一連のML APIを利用することができます
これについては後ほど説明します
Cloud Machine Learning Platformはさまざまなアプリに使用されています
用途には主に２つのカテゴリがあります
構造化データの処理と非構造化データの処理です
構造化データを処理する場合 MLを使用して各種の分類タスクと回帰タスクを行うことができます
顧客離れ分析、 製品の診断、予測などです
レコメンデーションエンジンの中心としてコンテンツのパーソナライズ、クロスセルアップセルに対応できます
MLを使って不正検出、センサー診断、 ログ指標で異常を検出することも可能です
非構造化データを処理する場合 MLを画像分析に使用して 配送品の損傷やスタイルの識別、
コンテンツの報告などを行えます。テキスト分析にも使用できます。
コールセンター、ブログ分析、言語の識別、 トピックの分類、感情分析などです
とりわけ革新的なMLアプリの多くはこうした複数のアプリを組み合わせたものです
ある顧客が SNS で あなたの商品に好意的な投稿をした際にアプリが自動的にその顧客に連絡して
顧客が好みそうな別の商品の割引を提示したとしたらどうでしょう
Google Cloud Machine Learning Platformでは こうした双方向性を簡単に実現できます

Cloud Vision APIを使用して 画像の内容を理解することができます
このAPIは画像を何千ものカテゴリに高速で分類します
ヨット、ライオン、エッフェル塔などに分類して 画像内の個々の物体を検出したり
画像内の印刷文字を見つけて読み上げたりできます
ここで取り上げる他のAPIと同じように使いやすいAPIの背後には高度なMLモデルが組み込まれています
このAPIを使用して画像カタログのメタデータの作成不適切なコンテンツの管理画像の感情分析を行えます
Cloud Speech APIで音声をテキストに変換できます
グローバルなユーザーベースに対応するためこのAPIは80を超える言語と方言を認識します
アプリのマイクで入力された音声の文字起こしや音声コマンドコントロールの有効化、
音声ファイルの文字起こしが可能です
Cloud Natural Language APIは 自然言語を理解するためのさまざまなテクノロジーを提供します
各トークンで名詞、動詞、形容詞などの 品詞を識別して単語間の関係を把握します
エンティティ認識も可能です
テキストを解析して 人、組織、場所、イベント、商品、 メディアの言及にフラグを立てます
テキストブロックで表現されている 感情を総合的に読み取ることもできます
これらの機能は英語、スペイン語、日本語など 複数の言語で使用できます
Cloud Translation APIを使ってシンプルでプログラム可能なインターフェースで任意の文字列を
サポートされている言語に翻訳できます
原文の言語が不明でもAPIが特定できます
Cloud Video Intelligence APIは各種形式の動画にアノテーションを
付け動画内の主要エンティティ（名詞）を識別し それらが出現するタイミングを特定できます
このAPIを使用すれば動画コンテンツの 検索と検出が可能になります
