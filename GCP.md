# GCP勉強時のメモ

## 用語
<details><summary>Blobstore</summary>
blob は、データストア サービスのオブジェクトに許可されているサイズよりはるかに大きいサイズのオブジェクトです。blob は、動画や画像などのサイズの大きいファイルを提供する場合や、ユーザーがサイズの大きいデータファイルをアップロードする場合に便利です
</details>

<details><summary>Cloud Trace</summary>
本番環境におけるパフォーマンスの障害検出
分散トレースシステム
アプリ(VM　コンテナ　APP　Engine)からレイテンシデータを収集しクラウドに表示
リアルタイムでパフォーマンス分析をすることができる
要点としてはボトルネックを検出できる（自動検出
</details>

<details><summary>Cloud Data Loss Prevention</summary>
機密データを自動的に検出して秘匿化する
DLPを使うことでクレジットや氏名、電話番号、身分証明書を秘匿化する
</details>


<details><summary>Cloud CDN</summary>
Content delivery network
グーグルのネットを使用してユーザーの近くからコンテンツ配信をする
これによりウェブサイトやアプリケーションを高速化させる
コンテンツ配信向け
</details>

<details><summary>Dedicated interconnect</summary>
オンプレミスネットワークとグーグルネットワークを
直接物理的に接続することで大量のデータをネットワークに
転送できます。公共のインターネットより優れている
</details>

<details><summary>フェイルオーバー</summary>
高可用性構成(HA構成)の時に使う
プライマリインスタンス (マスター)とスタンバイインスタンスで構成する
どちらもゾーンを別とするものとし同期レプリケーションをするとする
マスターがゾーンごと落ちてもスタンバイが引きつぐことができ
アプリケーションを持続することができる
この切り替えのことをフェイルーバーという
</details>

<details><summary>HorizontalPodAutoscaler</summary>
水平ポッドオートスケーラー
k8s
ReplicationControllerまたはDeployment, ReplicaSetのPodの数を自動的にスケールします。スケールの判定に利用するメトリクスはCPUやカスタムメトリクスを利用することができます。
Horizontal Pod AutoscalerはKubernetes APIオブジェクトとコントローラとして実装されています。このコントローラは定期的にユーザによって設定されたしきい値とメトリクスの値を比較しReplica数を調整します。
</details>

<details><summary>maxUnavailable</summary>
k8s
maxUnavailable はRolling Update中に無効なPodをどの程度許容するかを指定
</details>

<details><summary>maxSurge</summary>
k8s
Rolling Update中に複製数をどの程度超えていいかを指定
</details>



<details><summary>オペレーション(旧Stackdriver)</summary>
インフラストラクチャとアプリケーションのパフォーマンスをモニタリングして
トラブルシューティングを行い、パフォーマンスを向上させる
主な機能として
Cloud Logging
Cloud Monitoring
Cloud Profiler
がある
Loggingを使う場合は格インスタンスにインストールする必要がある
</details>

<details><summary>ingress</summary>
k8s
クラスタ外からクラスタ内サービスへのHTTPとHTTPSのルートを公開する
Serviceに対して、外部疎通できるURL、負荷分散トラフィック、SSL/TLS終端の機能や、名前ベースの仮想ホスティングを提供するように構成
</details>

<details><summary>Cloud AutoML</summary>
機械学習の知識がかぎれていても使用できる。
グーグルの機械学習機能を元にしてビジネスニーズに合わせ機械学習モデルを
作成し、アプリケーションやウェブサイトを統合する。
導入事例　ディズニーの商品関連検索
</details>

<details><summary>Conmpute Engine</summary>
高性能でスケーラブルな仮想マシン
VMのライブマイグレーション
プリエンプティブルVM
単一テナントノード
永続ディスクHDD　SSD
ローカルSSD（停止するとデータを保持できない)
グローバル負荷分散（複数のリージョンインスタンス)
秒単位課金、確約割引、継続利用割引
一般的に言われているIaaSだと思って良い
オンプレミスからの環境移行はこれが良いとされる
</details>

<details><summary>単一テナントノード</summary>
使用者のワークロードのみに使用される専用Compute Engine サーバー
使用者のワークロード意外に物理サーバーは使われない
CPUメモリなどのスペックが選べる
同一ノードでのインスタンスの共存やインスタンス分離が確実にできる
</details>

<details><summary>App Engine</summary>
フルマネージド型サーバレスなプラットフォームでアプリを構築
一般的な言語(nodejs java ruby C# go python php etc)
カスタムランタイムではDockerコンテナ提供がされ任意のライブラリや
フレームワークをインストール可能
インフラストラクチャは考え無くても使用できる
Cloud Monitoring Cloud Loggin Colud Debugger Error Reporting
などのパフォーマンス、モニタリング、バグを診断修正できる
開発環境、テスト環境、ステージング環境、本番環境をたやすく構築
トラフィック分割によりA/Bテストが容易
SSL/TLS 証明書やファイアウォールを使用して保護できる
アクセスに応じてスケールできるのでリソース不足による障害対策ができる

スタンダード環境:
フレキシブルより細かい自動スケーリング
一日に1GBストレージトラフィック無料
java Python php GOなどといった指定からバージョン指定まで
サンドボックスで生成されるのでOS、ハード、サーバーに依存しない
デメリットとしてローカルファイルシステムに書き込めない
リクエストは60秒でタイムアウト
アプリがアイドル状態だった場合請求料は無い
ネットワークはApp　Engine経由のみ
即時スケーリングを必要とする時使用推奨
ルート権限アクセスできる

フレキシブル環境:
定期的にスケールをする必要がある時使用推奨
サンドボックスでは無い
App Engineのデータストア、Memchach、タスクキューなどの
サービスにアクセス
ネットワークアクセス可能
様々な言語の使用ができる
サードパーティソフトをインストールできる
VMにSSH接続できる
料金はメモリーディスクCPUの使用量から
毎週再起動
ルート権限アクセスできる
</details>

<details><summary>Migrate for Compute Engine(旧 velostrata)</summary>
稼働中のアプリケーションでも影響を与えることなく移行できる
グーグルクラウドへ移行
オンプレミスのアプリケーションを移行するケース
複数のデータセンター
クラウドに分散された１０００のアプリ
を移行するようなケースに対応できる
組み込みテストで移行後に検証
インテリジェント ストリーミング(アプリ稼働に必要なものから移行する)
予測外が発生してもオンプレミスの高速ロールバック
仕組み
1.クラウドでテスト検証
2.移行ウェーブ作成
3.グーグルクラウドへのワークロードデプロイ
4.バックグランドデータの移行
5.アンプレミスへのステーツフルロールバック(必要時)
</details>

<details><summary>プリエンプティブル仮想マシン</summary>
バッチジョブ、フォールトトレントラントなどと行った
少し起動させたい時に使えるVM
通常のインスタンスより最大で80%の消費を削減する
プリエンプションが発生した場合30秒の猶予が与えられる
プリエンプティブル インスタンスは Compute Engine
の余剰のキャパシティを利用する機能であり
他のタスクがリソースへのアクセスを必要とする場合に、
Compute Engine によって終了(プリエント)される可能性がある

制限
いつプリエントされてもおかしく無い
24時間実行した後は必ずプリエントされる
プリエンプティブルインスタンス は有限compute Engineリソースなので
常に利用できるわけでは無い
ライブマイグレーションできない
サービスレベル契約の対象となら無い
Compute Engineの無料わくに適用されない

</details>

<details><summary>shielded VM</summary>
ルートキットやブートキットによる攻撃対策強化されている
リモート攻撃や権限昇格、内部関係者からの驚異から保護できる
カーネルレベルで改竄されてないことを確認できる
セキュアブートはブートコンポーネントのデジタル証明を検証し
失敗した時自動てブートコンポーネントを停止する
</details>

<details><summary>Bare Metal Soolution</summary>
特別なワークロードの実現ハードウェアの提供
認定されたハードウェア、複雑なライセンス、サポート契約
が必要でクラウド環境へ移行しづらい環境をモダナイズ（近代化）
をすることができる。

</details>

<details><summary>Cloud Storage</summary>
デベロッパーや企業向けの統合型オブジェクトストレージ
四つのストレージクラスが存在する
Multi-Regional 地理的冗長　世界中からのアクセス
Regional 単一リージョン　Compute Engineなどからの頻繁なアクセス
Nealine 月一回アクセス　バックアップ　データ　コンテンツ
Coldline 年一回　アーカイブデータ
使用したいストレージの場所を世界中から選べる（アメリカ　ヨーロッパ等)



</details>

<details><summary>プロジェクト</summary>
クラウドストレージ内のデータは全てプロジェクト内に属する。
一連のユーザー
一連API
APIno請求
認証
モニタリング
で構成され複数のプロジェクトを保持できます。
</details>

<details><summary>バケット</summary>

データを格納するコンテナ
クラウドストレージ内のデータは  
全てバケットに格納する必要がある
入子構造にできない
作成と削除セイゲインがある為バケットを少なく設計することを推奨
バケット作成時にグローバルに一意な名前と地理的ロケーション、ストレージクラスを指定する
作成後ストレージクラスの変更ができる
バケット名とロケーション変更はバケットを削除して再度作成しないとできないバケット名はリダイレクトで使用するのでDNS命名規則に準じる
バケットラベルは仮想マシンインスタンス や永続ディスクなどのリソースと共にバケットをグループ化できるkey-valueです
</details>

<details><summary>オブジェクト</summary>
Cloud Storage　内に保存するここのデータ
オブジェクトデータとオブジェクトメタデータでコンポーネントが構成
オブジェクトデータはCloud Storageに保存するファイル
オブジェクトメタデータはオブジェクトの様々な性質を記述した名前と値のペア集合
オブジェクト名はオブジェクトメタデータとして扱われる(UTF-8)
オブジェクト名に/(スラッシュ)を入れることで階層状ディレクトリ構造の中に保存されているように見えるが実際には階層関係の無いオブジェクトとして認識する
メタデータは作成後に編集できるものとできないもの、表示しかできないものある

Cloud Storageのオブジェクトは複数のバージョンを持つことができる
デフォルトではオブジェクトを上書きすると古いバージョンを削除して新しいバージョンに置き換わる。バケットでオブジェクトのバージョニングを有効にすることで上書きまたは削除が行われても古いバージョンがバケットに残る
バージョンはメタデータに含まれる世代番号によって識別される

固有キーメタデータ
・アクセス制御 (IAM ACL)
・Content-Disposition 転送データ
・Content-Encoding 圧縮型
・Content-language 言語
・コンテンツタイプ ブラウザが読むこむための指標？

</details>

<details><summary>リソース</summary>
Google Cloud 内のエンティティ
プロジェクト　バケット　オブジェクトがリソース

リソース名　（使用はPub/Sub Notifications for Cloud Storage と Identity and Access Managementに限られている)
リソースにはファイル名のような固有名がついている
パケットのリソース名の形式は以下のようになる
`projects/_/buckets/[BUCKET_NAME]`
BUCKET_NAMEにバケットID
オブジェクトリソースだと
`projects/_/buckets/[BUCKET_NAME]/objects/[OBJECT_NAME]`
OBJECT_NAMEはオブジェクトID
リソース名の末尾に付加されるのは#[NUMBER]でオブジェクトの特定世代を表す

</details>

<details><summary>地域的な冗長性</summary>
地理的に冗長なデータは少なくとも100マイル離れている２つ以上の場所に保存されている
マルチリージョンとデュアルリージョンには地理的に冗長と呼べる
天才や災害が発生しても可用性が最大確保できる

</details>

<details><summary>データの不透明性</summary>
オブジェクトのデータコンポーネントはCloud Storageに対して完全に不透明
Cloud Storageは単なるデータの塊として認識されない
</details>

<details><summary>オブジェクトの不変性</summary>
後からプロジェクトに付加や切り捨てなどのオペレートで部分的な変更を加えることはできない
上書きすることはできる
一秒間に一回しか上書きできない(429 Too Many Requestsエラー)

</details>

<details><summary>Cloud Filestore</summary>
フルマネージドファイルストレージ
データ用のファイルシステムインターフェースと共有ファイルシステムを必要とするアプリ向け
ファイルシステムの機能を必要にするときに使用する
Filestore を使用すると、Google Compute Engine や Kubernetes Engine のインスタンスでマネージド NAS（ネットワーク接続ストレージ）を立ち上げ、ネイティブに使用できる
フルマネージメントNoOpsサービス
ファイルの共有はCompute Engine VMにマウント
k8sと統合できるので複数のコンテナから同じ共有データを参照できる
Elastifile(グーグルが買収したNFSサーバー提供会社)を使用するとファイルストレージを柔軟にスケールすることができ、GCPやGUIやAPIベースの制御でクラスタ拡張縮小が可能

上記ではわかりにくいので使用例
レンタリング(共有作業の効率化)
アプリケーションの移行(ファイルシステムの共有)
ウェブコンテンツ管理
メディア処理(大きなメディアファイル共有作業化)
ホームディレクトリ
</details>

<details><summary>ストレージオプション(永続ディスク)</summary>
Compute Engine には、インスタンス向けに複数のストレージ オプションが用意されています

マルチリーダー機能
スナップショット機能
リソースを中断せずにスケール
自動暗号化

ストレージオプション
ゾーン標準ディスク
リージョン永続ディスク
ゾーンSSD永続ディスク
リージョンSSD永続ディスク
ローカルSSD
Coud Storage パケット

ゾーン永続ディスクはインスタンス からアクセスできる
永続ディスク上のデータは複数の物理ディスクに分散(冗長の確保)
永続ディスクはVMとは独立しているのでインスタンスを削除しても保持できる。パフォーマンスはサイズに合わせてスケールされる

リージョン永続ディスク
堅牢なシステム設計をCompute Enigneで実現したい場合はこちらを使う
同じリージョンないに二つのゾーン間でのレプリケーションに対応
アプリレベルでのレプリケーションをする場合は同期レプリケーションを使用する
ゾーンが停止してもフェイルオーバーできる

ローカルSSDはVMインスタンス をホストするサーバーに物理的に接続
高スループット低レイテンシ
インスタンス が停止、削除されるとデータを保持できない
パフォーマンスの向上の代償として可用性、耐久性、柔軟性をある程度トレードオフする
インターフェースをSCSIかNVMeを選択できる(SSD接続するためのインターフェース)
自動的に書き込まれるとき暗号化されるが顧客指定の暗号化は使用きない（グーグル提供のみ)

Cloud StorageバケットはVMインスタンス で利用できる
アプリで低レイテンシの永続ディスク及ローカルSSDが特に必要なければデータを格納できる
データセンターメンテナンス中でもデータの可用性がある
全てのCloudStorageオペレーションに対してチェックサムが計算され読み取ったデータと書き込んだデータが一致する確認が容易
永続ディスクとは異なりインスタンスが存在するゾーンに限定しなくバケットに対して複数のインスタンスからデータを同時に読み書きできる
ファイルシステムとしてインスタンス にCloudeStorageバケットをマウントできる
マウントされたバケットはファイルの読み書きにたいして永続ディスクと同じように機能する
しかしバケットはPOSIXファイルと同等の書き込み制約が無いためブートディスクとして使用できない
さらに同時にデータに書き込んでいる他のインスタンス の重要なデータが上書きされる可能性もある
永続ディスクと同じように顧客指定の暗号鍵でバケット暗号できる

</details>

<details><summary>Cloud Storage for Firebase</summary>
Cloud StorageをFirebaseで使用する
コンテンツ（動画画像等)を簡単に保存提供
SDKを使用することでクライアントから直接ファイルのアップロードとダウンロードを行う。ネットワーク接続がよく無い場合、動作が停止したところから再試行できる
個々のファイルやファイル グループごとにアクセス制御を設定できる宣言型セキュリティ言語を備えているため、必要に応じてファイルを公開したり非公開にしたりできる
</details>

<details><summary>Cloud Bigtable</summary>
大規模な分析ワークロードと運用ワークロードに対応
ペタバイト規模のフルマネージドNoSQL
アドテック(広告)、フィンテック(金融)、lotに最適
プロビジョニングとスケーリングの上限は数百ペタバイト、毎秒数百万のオペレーションを処理する
レプリケーションに
よってリアルタイムアプリの可用性がまし、データ提供や分析の目的に応じてワークロードを分離できる
Hadoop、Cloud Dataflow、Cloud Dataproc
などの一般ビックデータツールと統合でき、オープンソースでHBaseAPIもサポートしている。

財務分析中ら不正パターンを継続的に更新することでリアルタイムのトランザクションと比較する

時系列データ
複数のサーバーにおける時間の経過に伴う CPU とメモリの使用状況など。

マーケティング データ
購入履歴やお客様の好みなど。

金融データ
取引履歴、株価、外国為替相場など。

IoT（モノのインターネット）データ。電力量計と家庭電化製品からの使用状況レポートなど。

グラフデータ
ユーザー間の接続状況に関する情報など。

散在して格納するテーブル
数十億行から数千列の規模にスケール可能
各行の値がインデックスに登録され、行キーとなる
低いレイテンシで単一キーの超大容量を格納するのに向いている
MapReduceオペレーションが理想的なデータソース

ストレージモドエル
Key-Vule
行と列で構成されている
それぞれの行と列が交差する場所はタイムスタンプの異なるセルバージョンを含めることができるため保存されたデータが時間の経過とともにどのように変化されたかが記録できる
データベースはスパースで格納されていないセルが領域を奪うことは無い

全てのクライアントリクエストはフロントエンドサーバーを経由してノードに送信される。これらのノードをタブレットサーバーという
ノードはクラスタとして編成される。
クラスタはCloud Bigtableのインスタンスのコンテナに属している。
ノードはクラスタに対するリクエストを一部処理する。
クラスタにノードを追加することで処理できるリクエストや全体のスループットを増やせる。
レプリケーションを有効にするとクラスタごとに異なる種類のトラフィックを送信することや、一方のクラスタが使用できなかった時にフェイルオーバーできる。
Cloud Bigtableテーブルは連続する行ブロックでタブレットとして共有される。タブレットはHBaseリージョンに相当する。
タブレットはGoogleのファイルシステムである
ColossusにSSTable形式で格納
SSTableは永続的な順序付きの、キーから値への不変マップとなっています。
ここで、キーと値はどちらも任意のバイト文字列です
格タブレットはBigtableノードに関連づけられる
全ての書き込みはSSTableファイルに格納されるだけではなくBigtableに認識されると直ちにColossusの共有ログにも格納され耐久性がます

重要なことは
データはcloud Bigtableノード自体に格納されていないこと
各ノードはタブレットのセット(Colossus)に対するポインタを保持している
これにより以下を実現できる
・ノード間のタウブレット移動が高速になる（ポインタ
変更のみのため)
・Bigtableのノード障害復旧が高速に実行(置換先に新しいノードにメターデータのみを移動するため)
・Bigtableのノードが障害を起こしてもデータは失われない

負荷分散
Bigtabelゾーンはマスタープロセスによって管理される
マスタープロセスはクラスタ内の負荷とデータ量の均衡を図る。マスターはアクセス数の多い大量のタブレットをノード間で半分に分割しアクセスの少ないタブレットを結合する。
特定のタブレットのトラフィックが突出している場合、マスターはそのタブレットを2分割し、その一方を別のノードに移動する。これによりユーザーが手動でタブレットを操作する必要はない
Bigtableで最高パフォーマンスを実現するためには書き込み作業をできるだけ均等にノード間に分散することが重要です。目標を達成するには予測可能な順番に従わない行キーを使用する方法があります。例えばユーザー名はアルファベット順にほぼ均等に分散する傾向があるためユーザー名を行キーの先頭で使用すると書き込みの分散が均等になりやすくなります。
関連する行をグループ化して近くにまとまるようにすると便利です。これにより複数の行を同時に読み取る処理が効率的になります。
例
時間の経過に伴い様々な出いの天気情報データを書くのする場合、データ取集した場所とタイムスタンプを連結したものを行キーとして使用できます（例: WashingtonDC#201803061617）
このような行キーを使用すると１つの場所から得られた全てのデータが行の連続した範囲としてグループ化されます。他の場所については行が異なる識別子で始まります。多数の場所で同じ速度でデータが収集されるため書き込みはタブレット間で均等に分散されます。

Bigtableはアルゴリズムによりデータを自動圧縮する。
圧縮方法は変更することはできない。
ランダムデータはパターン化されたデータ（テキストなど）よりも圧縮効率が低くなる
圧縮は同じ値が互いに近接した場所にある場合動作効率が最も良くなる(同じデータチャンクが格納された行が互いに隣接するように行キーを調整すれば、データを効率的に圧縮できます)


セキュリティ
Cloud Bigtable テーブルへのアクセスは、Google Cloud プロジェクトと、ユーザーに割り当てた Cloud Identity and Access Management 役割によって制御されます。
プロジェクト、インスタンス、テーブルの各レベルでセキュリティを管理できます。Cloud Bigtable では、行レベル、列レベル、セルレベルでのセキュリティ制限をサポートしていません。


1TB未満のソーリューションには向いていない

Bigtabelインスタンスはデータのコンテナです。インスタンには１つ以上のクラスタがあり、別のゾーンの配置されているます。各クラスタには１以上のノードがあります。
テーブルはクラスタやノードではなくインスタンスに属します。インスタンに複数のクラスタがある場合は、レプリケーションを使用します。ここのクラスタにテーブル割り当てはできません。またインスタンス内のクラスタごとに一意のガベージコレクションポリシーを作成することができない。また各クラスタで同じテーブルに異なるデータセットを格納することもできない。

ストレージタイプは永続SSDまたは永続HDDを選択
インスタンス内の全てのクラスタが同じストレージタイプを使用しなければならない

インスタンスを作成するとBigtableはそのインスタンス使用してアプリケーションプロファイルを保存します。レプリケーションを使用する場合アプリプロフィルはアプリケーションがインスタンスのクラスタにどのように接続するかを制御します。レプリケーションを使用しなくともアプリ プロファイルを使用して、アプリケーション単位か 1 つのアプリケーション内の関数単位で、個別の識別子を指定できます。そうすると、アプリ プロファイルごとに個別のグラフを Cloud Console に表示できます。


クラスタは特定のロケーションにあるBigtableサービスを表します。各クラスタは１つのBigtableインスタンス に属し、１つのインスタンには最大で４つのクラスタがあります。アプリケーションがBigtableにリクエストを送信するとそのリクエストはインスタンスのいずれかによって処理される。
各クラスタは１つのゾーンに配置されまています。インスタンスの各クラスタは、それぞれ異なるゾーン内に存在する必要があります。Bigtabel利用可能なゾーンであればどこにでも追加クラスタを作成できます。クラスタが１つしか無い場合はレプリケーションはできない。クラスタを追加すると自動的にレプリケーションを開始する。
アプリケーションが接続するクラスタを選択できるのでトラフィックタイプ別に分離できる。またBigtableがクラスタ間でトラフィックを分散するように設定することもできる。

ノード
インスタンス内の各クラスタには、Cloud Bigtable がデータの管理に使用するコンピューティング リソースが 1 つ以上あります。
bigtableはバックグラウンドでテーブル内の全てのデータを別々のタブレットに分割する。タブレットはノードと同じゾーンにあるディスクにノートは別に格納されます。タブレットは一つのノードに関連づけられる。
役割
ディスク上の特定のタブレットをトラッキングする
受信するタブレットの読み取りと書き込みを処理する
定期的なコンパクションなどのメンテナンスタスクをタブレットで実行する

クラスタにはクラスタの現在のワークロードとクラスタに保存されているデータの量をサポートできるだけのノードが必要になります。十分なノードが供給されない場合受信されたリクエストを処理できずレイテンシが増加します。指標が推奨値と上限を超えた場合はインスタンスにノードを追加する
</details>

<details><summary>Colossus</summary>
Google内部の高い耐久性を持つファイルシステム
Googleデータセンター無いいのストレージデバイスを使用して構築されている
BigtableはHDFSクラスタや他のファイルシステムを稼働する必要はなく、インスタンス がレプリケーションを使用する場合、Bigtableはインスタンに含まれる各クラスタのデータのコピーを1つColossusに保持します。
各コピーは異なるゾーン、リージョンに配置される。
背後で独自ストレージ方式を使用して従来のHDFS3方向レプリケーションによって提供されている耐久性を超えるものを提供している
災害復旧の可能性も考えバックアップも生成している
</details>

<details><summary>Bigtableタブレットサーバ</summary>
Bigtableのテーブルデータを100m~200mbytes程度に分割した「タブレット」を管理するサーバー
一台のタブレットサーバは100個以下のタブレットを保存することができる
</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

<details><summary></summary>

</details>

## 教材の資料箇条書きメモ
IaaSの未加工のコンピューティング、 ストレージ、ネットワークは データセンターと同様に編成されます
PaaSでは 作成するアプリコードが ライブラリにバインドされるため 必要なインフラにアクセスできます そのため アプリのロジックのみに集中できます
IaaSモデルでは 割り当てた分の料金を支払います
PaaSモデルでは使用した分を支払います
Google検索、Gmail、ドキュメント、 ドライブなどの人気アプリはSaaSアプリですエンドユーザーが インターネットで直接利用するからです


ゾーンは GCPリソースのデプロイ領域です
ゾーンはリージョンという 個々の地域にグループ化されています
リージョン内のゾーン間では 高速ネットワーク接続を使用できます
リソースをリージョン内の 複数のゾーンに分散できます こうするとアプリを 予期せぬ障害から保護できます
リソースは複数リージョンで実行できます
アプリを世界中のユーザーの 近くに配置するためです
さらに 自然災害などによる リージョン全体の機能停止からも保護できます
データの冗長性を確保するために 欧州内の160km以上離れた ２つ以上の場所にデータを保管できます


予算は請求先アカウントごと またはGCPプロジェクトごとに定義できます 予算には上限を設けることも 別の指標を関連付けることもできます
課金データエクスポートでは 詳細な課金情報を 分析用に取得しやすい場所に保管できます(Cloud Storageバケットなど)
レポートはGCP Console内の ビジュアルツールです 利用額を監視できます 割り当ても実装しています
これはアカウント所有者と GCPコミュニティ全体を保護する手段です エラーや悪意のある攻撃による リソースの過剰消費を防ぐことができます
割り当てには２種類あります
頻度に基づく割り当ては 一定期間後にリセットされます
数量に基づく割り当ては プロジェクトで使用できる リソースの数を制御します


Google Cloud Identity and Access Management（IAM）を使用して 誰が何をできるかをコントロールします
GCPのお客様はIAMを使用して最小権限を実装し こうした誤りを防ぐことができます GCPの管理レイヤを操作するには ４つの方法があります
ウェブベースのConsole、 SDKとコマンドラインツール、 API、モバイルアプリです
下位層のセキュリティはGoogleが管理します
セキュリティスタックの上位層は 引き続きお客様の管理になります
GoogleはIAMなどのツールを提供して お客様が上位層で任意のポリシーを 実装できるようにしています


VM、Cloud Storageバケット テーブル、BigQueryなどすべてが プロジェクトに整理されます
加えてプロジェクトをフォルダに まとめることもできます
フォルダには他のフォルダも格納できます
組織が使用する全フォルダとプロジェクトは 組織ノードの下にまとめられます
プロジェクト、フォルダ、組織ノードには まとめてポリシーを定義できます
一部のGCPリソースでは 個別にポリシーを定義できます
ポリシーは階層の下位に 継承される
GCPリソースは １つのプロジェクトに属します
プロジェクトはGCPサービスを 使用する際の基本単位です
APIの管理、課金の有効化、 共同編集者の追加と削除などを行います
各プロジェクトは独立した区画であり 各リソースは 1 つの区画にのみ属します
プロジェクトごとに異なるオーナーと ユーザーを作成して個別に管理できます
各GCPプロジェクトに 名前とプロジェクトIDを割り当てます
プロジェクトIDは永続的かつ不変で GCP全体で一意である必要があります
このIDをさまざまなコンテキストで使用して GCPに作業対象のプロジェクトを指示します
プロジェクトには 好きな名前を付けられます
各プロジェクトには固有の プロジェクト番号も割り当てられ さまざまなコンテキストで表示されます
プロジェクトIDは人が読める文字列にします
プロジェクトはフォルダにまとめることができます
フォルダは作業を楽にするためのツールです
フォルダ内のリソースは そのフォルダのIAMポリシーを継承します
フォルダを使用するには 階層の最上位に組織ノードが必要です
社内の全プロジェクトは １つの構造にまとめることができます
ほとんどの企業では リソースの使用状況の確認と ポリシーの適用を一元的に行う必要があります
それを可能にするのが組織ノードです 組織ノードは階層の最上位階層であり 特別な役割を持っています
たとえば 組織ポリシー管理者を指定して 管理者だけがポリシーを変更できるようにします
G Suiteドメインがある場合 GCPプロジェクトは 自動的に組織ノードに属します
そうでない場合は Google Cloud Identityを 使用して作成できます
新しい組織ノードを作成した時点では ドメイン内の全員が引き続き プロジェクトと請求先アカウントを作成できます
新しい組織ノードを作成したら まずこれらの操作を許可する チームメンバーを決定しましょう
組織ノードを作成すれば その下にフォルダを作成して そこにプロジェクトを配置できます
プロジェクトはいつでもフォルダに移せます リソースは親リソースからポリシーを継承します
プロジェクト内のすべてのリソースが ポリシーを継承します
階層の上位で実装されたポリシーが それより下位で付与された アクセス権限を削除することはできません




IAMを使えば特定のリソースへの 操作権限をユーザーに付与できます
IAMポリシーは「誰が」「何を」 「どのリソースに」対して行えるかを定義します
「何を」はIAM役割で定義します IAM役割とは権限の集合です
「誰が」は Googleアカウント、Googleグループ サービスアカウント、G Suite全体、 Cloud Identityドメインのいずれかになります
IAM役割には３種類あります
基本の役割は広範です GCPプロジェクトに適用するとそのプロジェクトの全リソースに適用されます
基本の役割には オーナー、編集者、閲覧者があります
閲覧者はリソースを確認できますが 状態の変更はできません
編集者は閲覧者の権限に加えて リソースの状態を変更できます
オーナーは編集者の権限に加えて リソースの役割と権限を管理できます
オーナーには 支払い / 請求の設定がある
通常 請求管理の担当者には プロジェクトリソースの変更権限は与えません
そのために 課金管理者の役割を付与できます
機密データが含まれるプロジェクトに 複数のメンバーが取り組む場合は注意が必要です
基本の役割では広範すぎるかもしれません
GCP IAMにはよりきめ細かい役割もあります
各GCPサービスには 独自の定義済みの役割があり 役割を適用できる対象が定義されています


Compute Engineの InstanceAdmin役割を持つユーザーは VMに対して特定の操作を行うことができます
たとえば VMの一覧表示、 構成の読み取りと変更、VMの起動と停止です 操作対象のVMは 役割の適用先によって決まります
ここでは 特定のGoogleグループの ユーザー全員がこの役割を持っています
この役割はproject_aの全VMに適用されます
さらにきめ細かい役割が必要な場合は カスタムの役割があります
多くの会社では最小権限のモデルを使って 各メンバーに必要最小限の 権限のみを付与しています
たとえば InstanceOperator役割を定義して 特定のユーザーにCompute EngineとVMの 起動と停止を許可し 再構成は許可しないとします
カスタムの役割を使えばこれを実現できます ただし注意点があります 第一に カスタムの役割を使うことを 明確に決める必要があります
権限の管理が必要になるからです 会社によっては 事前定義済みの役割を選択しています
第二に カスタムの役割を使用できるのは プロジェクトまたは組織レベルのみです フォルダレベルでは使用できません
権限を付与する対象がユーザーではなく Compute Engine VMだとしたら？ その場合はサービスアカウントを使用します
たとえばVMで実行しているアプリのデータを Google Cloud Storageに保管するとします
そのデータへのアクセスは インターネット上の全員に許可するのではなく VMだけに許可します
そこで Cloud Storageに対してVMを 認証するためのサービスアカウントを作成します
サービスアカウントの名前は メールアドレスにします ただし パスワードではなく 暗号鍵でリソースにアクセスします
こちらの例では サービスアカウントにCompute Engineの InstanceAdmin役割が付与されています
VMで実行中のアプリはこのアカウントを使って 他のVMを作成、変更、削除できます
また サービスアカウントの管理も必要です
たとえば Aliceが特定のサービスアカウントで 実行可能な操作を管理するとします
一方 Bobは表示さえできれば十分です サービスアカウントはIDであると同時に リソースでもあるため
IAMポリシーをそれ自体に適用できます サービスアカウントでAliceには編集者の役割を
Bobには閲覧者の役割を付与できます 他のGCPリソースの役割を 付与する場合と同じです
プロジェクト内のVMのグループごとに 異なるIDを付与できます
その結果 グループごとに 異なる権限を管理しやすくなります
また VMを再作成しなくても サービスアカウントの権限を変更できます

Consoleはウェブベースの 管理インターフェースです GCPでアプリを作成するときに使用します
Consoleではすべてのプロジェクトと 使用するリソースを確認、管理できます
GCPサービスのAPIの 有効化、無効化、確認も可能です Cloud Shellにもアクセスできます
Cloud ShellはGCPの コマンドラインインターフェースで ブラウザで簡単に使用できます
Cloud Shellでは Google Cloudソフトウェア開発キット（SDK） に含まれるツールを使用できます
インストールは不要です
Google Cloud SDKは GCPでリソースとアプリを 管理するためのツールの一式です
SDKに含まれるgcloudツールは GCPのプロダクトとサービスのメインの コマンドラインインターフェースです
Cloud Storage用のgsutilと BigQuery用のbq（BigQuery）も含まれています
SDKコマンドにアクセスするには ConsoleのCloud Shellボタンを クリックするのが簡単です
SDKコマンドがすでにインストールされた VM上のウェブブラウザに コマンドラインが表示されます
SDKを自分のマシンに インストールすることもできます
SDKはDockerイメージとしても提供されており システムを非常に簡単に扱うことができます
GCPを構成するサービスには APIが用意されています こうしたAPIは RESTfulと呼ばれます
APIではリソースとGCPをURLで指名します
コードでAPIに情報を渡すには JSONを使用します
GCP Consoleでは APIを有効または無効にできます 割り当てと制限も適用されます
必要なAPIだけを有効にして リソースが追加で必要になったら 割り当ての増加をリクエストできます
Googleのクライアントライブラリを使えば コードからGCPを呼び出す 面倒な作業を大幅に軽減できます
ライブラリには２種類あります Cloudクライアントライブラリは Google CloudのAPIに推奨される 最新のライブラリです
各言語のネイティブスタイルと イディオムを採用しています ただし 最新のサービスと機能を サポートしていない場合もあります
その場合は 使用する言語に対応する Google APIクライアントライブラリを使用します
こうしたライブラリは普遍性と完全性を 重視して設計されています
GCPで使用しているリソースを調べて管理できる AndroidとiOS向けのモバイルアプリです



最小限の作業ですぐに GCPの使用を開始するには GCP Marketplaceが便利です
GCPにソフトウェアパッケージを 迅速にデプロイするためのツールです
ソフトウェア、VMインスタンス、ストレージ、 ネットワークの手動構成は不要です
必要に応じて起動前に変更できます
GCP Marketplaceの ソフトウェアパッケージの大半は GCPリソースの通常料金の他に追加料金はかかりません
一部のGCP Marketplaceイメージでは 利用料がかかります
サードパーティが商用ライセンスソフトウェアで 公開しているものなどです
その場合は起動する前に 月額利用料の見積りが示されます
ネットワーキング費用は 見積りに含まれないことがあります
アプリの使用方法によって異なるためです
GCPでは重大な問題と脆弱性の修正のため ソフトウェアのベースイメージが更新されます
デプロイ後のソフトウェアは更新されません
デプロイ済みのシステムに アクセスすることは可能であるため 自分で保守することはできます

Compute EngineではVMを Googleのグローバルインフラで実行できます
VMの利点の１つは 本格的なOSの処理能力と普遍性を 備えていることです
VMは物理サーバーと同じように構成できます CPU処理能力、メモリ量、
ストレージの容量とタイプ、OSを指定できます VMは柔軟に再構成できます
さらにGoogle Cloudで稼働するVMには 比類ないネットワーク接続性があります

VPCネットワークがGCPリソースの相互接続と インターネットとの接続を可能にします
ネットワークをセグメント化し ファイアウォールルールで インスタンスへのアクセスを制限できます
静的ルートを作成すれば トラフィックを特定の宛先に転送できます
定義するVPCネットワークが グローバルスコープを持つということです
世界中のどのGCPリージョンにも サブネットを持てます
サブネットはリージョン内の 複数ゾーンをまたぐことも可能です
グローバルスコープのネットワーク レイアウトを簡単に定義できます
同じサブネットで複数ゾーンに リソースを配置することもできます
カスタムネットワーク内のサブネットの サイズは動的に拡大できます
割り当てるIP範囲を拡大するだけです

Compute EngineではVMを作成してGoogleのインフラで実行できます
先行投資は要りません
高速で一貫したパフォーマンスのシステムで 数千もの仮想CPUを実行できます
VMインスタンスを作成するには GCP Consoleまたは gcloudコマンドラインツールを使います
VMで実行できるLinuxまたは Windows Serverイメージには Google提供のものとカスタマイズバージョンがあります
物理サーバーからイメージを インポートすることも可能です
VMを作成するときにマシンタイプを選びます タイプによってメモリ量と 仮想CPUの数が決まります
タイプにはごく小さなものから 非常に大きなものまであります
事前定義済みのタイプで要件を満たせない場合は カスタムVMを作成できます
処理能力については 機械学習やデータ処理など GPUを利用できるワークロード向けに
GCPの多くのゾーンでは GPUを利用できます 物理的なマシンと同じように VMにもディスクが必要です
永続ストレージは２種類から選択できます 標準とSSDです
アプリに高パフォーマンスの 一時的領域が必要な場合は ローカルSSDを接続できます
ただし永続的な価値のあるデータは 別の場所に保管してください
ローカルSSDのコンテンツは VMが終了すると消去されるからです
もう１種類は 永続ディスクです　ブートイメージも選べます
さまざまなバージョンの LinuxとWindowsが用意されています
独自のイメージもインポートできます　
GCP VM起動スクリプトを渡すのが一般的です 他の種類のメタデータを渡すこともできます
VMが稼動したら 簡単にディスクのスナップショットを取れます バックアップとして保管したり
別のリージョンへのVMの移行時に 使用したりできます
完了するまで人が介入しない ワークロードがあるとします 大規模なデータセットを 分析するバッチジョブなどです
プリエンブティブルVMでジョブを実行すると 費用を節約できます
プリエンプティブルVMには通常の Compute Engine VMと異なる点が１つあります
他でリソースが必要になった場合に Compute Engineがそれを終了できるという点です
Compute Engine の余剰のキャパシティを利用する機能であり、使用できるかどうかは利用状況に応じて異なります
プリエンプティブルVMでは 費用を大幅に節約できますが 停止と再開が可能なジョブに使用してください
インスタンスに応じた適切なマシンは 仮想CPUの数やメモリ量を基に選択できます
事前定義済みマシンタイプを 使用することも カスタムマシンタイプを 作成することもできます
Compute Engineの 自動スケーリング機能を使用すると 負荷の指標に基づいて アプリのVM数を増減できます
この仕組みの一環として 着信トラフィックの負荷がVM間で分散されます


VPCでもルーティングテーブルを使用します 同じネットワーク内のインスタンス間で トラフィックを転送するためです
サブネット間やGCPゾーン間でも 外部IPアドレスを使用せずに転送できます
VPCルーティングテーブルはプロビジョニングや管理は不要です
ファイアウォールインスタンスの プロビジョニングと管理も不要です
VPCのグローバルな分散型ファイアウォールを使用してインスタンスへの送受信トラフィックを制限できます
ファイアウォールル―ルの定義では インスタンスのメタデータタグを使用できます
たとえばすべてのウェブサーバーに 「web」というタグを付けるとします
ファイアウォールルールで ポート80または443での受信トラフィックを 「web」タグが付いたVMに許可します
IPアドレスは何であろうと関係ありません VPCはGCPプロジェクトに属します
複数のGCPプロジェクトがありVPC間の通信が必要な場合は単に２つのVPC間にピアリング関係を確立してVPCピアリングを使用できます
IAMを機能を最大限に利用して別のプロジェクトのVPCに対して誰が何の操作を行えるか制御するには共有VPCを使用できます
その時々でアプリを提供するVMの数が変わる場合Cloud Load Balancingです
これはソフトウェアで定義された 完全分散型のマネージドサービスです
ロードバランサは管理対象のVM内で実行されないためスケーリングも管理も不要です
Cloud Load Balancingはすべての トラフィックに対応しています
これにはHTTPとHTTPS、 その他のTCPとSSLトラフィック、 UDPトラフィックも含まれます
Cloud Load Balancingでは １つのエニーキャストIPが 世界中のリージョンのバックエンドインスタンスのフロントエンドとなります
負荷はリージョン間で分散されます
さらに自動マルチリージョンフェイルオーバーにより バックエンドの不調時には トラフィックを分割して移動します
Cloud Load Balancingは ユーザー、トラフィック、バックエンドの状態、ネットワーク条件などの変化に瞬時に対応します
ウェブアプリの負荷をリージョン間で分散する場合は HTTPS負荷分散を使用します
HTTP以外のSSLトラフィックにはグローバルSSLプロキシロードバランサを使用します
SSLを使用しないTCPトラフィックであればグローバルTCPプロキシロードバランサを使用します
この２種類のプロキシサービスは 特定のポート番号とTCPでのみ機能します
UDPトラフィックや任意のポート番号の トラフィックを負荷分散する場合は リージョンロードバランサで リージョン全体に負荷を分散できます
これらすべてのサービスの共通点はインターネットから送信されるトラフィックを対象としていることです
アプリのプレゼンテーション層と ビジネスロジック層の間での負荷分散などは内部ロードバランサを使用します
GCP内部IPアドレスでの受信トラフィックの 負荷をCompute Engine VM間に分散します
GCPではCloud DNSを提供していますこれはGoogleと同じインフラで実行されるマネージドDNSサービスです
低レイテンシと高可用性を実現し 費用効率の高い方法で アプリとサービスをユーザーに提供できます
DNS情報を公開すると その情報は 全世界のあらゆる場所から配信されます
Cloud DNSはプログラムも可能です 数百万ものDNSゾーンとレコードを 公開して管理するには
GCP Console、コマンドライン インターフェース、APIを使用できます
Googleにはグローバルな エッジキャッシュシステムがあります
このシステムを使ってアプリのコンテンツ配信を加速化するには Google Cloud CDNを使用します
ユーザーは低レイテンシを実感するでしょう コンテンツの発信元の負荷が減り 費用も節約できまます
HTTPS負荷分散を設定した後にチェックボックスをオンにするだけで Cloud CDNを有効にできます
CDNは他にもたくさん存在します すでにCDNを使用している場合
GCPのCDN Interconnectパートナー プログラムの対象である可能性がありますその場合はそのまま使用できます
GCPのお客様の多くはGoogle VPCと 他のネットワークの相互接続を必要とします
オンプレミスネットワークや他の クラウド内のネットワークなどです
選択肢はたくさんあります 多くのお客様は 仮想プライベートネットワークを IPSECプロトコルを使用してインターネットで接続します
さらに 動的な接続にするために Cloud RouterというGCP機能を使用します
この機能を使用すると 他のネットワークとGoogle VPCの間で BGPを使って VPN経由でルート情報を交換できます
たとえば 新しいサブネットを Google VPCに追加すると オンプレミスネットワークが自動的に そのルートを取得します
インターネットを使用したくないお客様もいます
その場合はGoogleとの ダイレクトピアリングを検討できます
ピアリングとはルーターを Google POPと同じデータセンターに配置して トラフィックを交換することです
Googleは世界中に 100を超えるPOPを設けています POPでまだ接続を確立していない場合は
キャリアピアリングプログラムの パートナーに接続を依頼できます
ピアリングには欠点が１つあります それはGoogleのSLAの対象ではないことです
 Googleとの相互接続で 高い稼働率が必要な場合は Dedicated Interconnectを使用してください
Googleとの１つ以上の直接プライベート接続を確立できます
接続形態がGoogleの仕様を満たす場合 その接続は最大で 稼働率99.99％のSLAの対象になります

Cloud Storageについて説明しましょう
オブジェクトストレージとは何でしょう
フォルダの階層としてデータを管理する ファイルストレージとは異なります
OSがデータをディスクの塊として 管理するブロックストレージとも異なります
オブジェクトストレージとは データを保管するとその一連のバイトが オブジェクトとして扱われ
固有のキーでデータをアドレス指定できる ストレージを意味します
これらの固有のキーはURL形式です
Cloud Storageの仕組みも同じです
スケーラブルな フルマネージドサービスです つまり 容量の事前プロビジョニングは不要です
オブジェクトを作成するだけで 耐久性と可用性に優れたデータ保存が可能になります
Cloud Storageはウェブサイトコンテンツの配信や アーカイブ・復旧用データの保管
ユーザーの直接ダウンロードによる 大容量データの配布などで使用されます
Cloud Storageは ファイルシステムではありません
格納されているオブジェクトごとに URLがあるからです
各オブジェクトは多くの点で ファイルのようなものなので
オブジェクトを「ファイル」という言葉で 説明しても構いませんが 正確にはファイルシステムとは違います
Linuxマシンのルートファイルシステムとして Cloud Storageを使うことはありません
Cloud Storageはバケットで構成されます
ユーザーがバケットを作成して構成し そこにオブジェクトを格納します
ストレージオブジェクトは不変です
インプレースで編集するのではなく 新しいバージョンを作成します
Cloud Storageは必ずサーバー側で データを暗号化してからディスクに書き込みます
暗号化の追加料金はありません
またデフォルトでは 転送中のデータがHTTPSで暗号化されます
データ転送については 大量のデータをCloud Storageに 保存できる便利なサービスもあります
Cloud Storageに格納されたデータは他のGCPストレージサービスに移動できます
バケットの作成時に グローバルに一意の名前を付けます
バケットとそのコンテンツを保管する 地理的ロケーションを指定し デフォルトの ストレージクラスを選択します
ユーザーにとってレイテンシが最小になる ロケーションを選んでください
オブジェクトとバケットへのユーザー アクセスを制御する方法はいくつかあります
通常はCloud IAMで十分です 役割はプロジェクトから バケット、オブジェクトへと継承されます
よりきめ細かい制御が必要な場合は アクセス制御リスト（ACL）を作成します
ACLで定義するのはバケットとオブジェクトに アクセスできるユーザーと ユーザーのアクセスレベルです
各ACLは２つの情報で構成されます
１つは指定の操作を実行できるユーザーを 定義する「スコープ」で特定のユーザーや ユーザーグループを定義します
もう１つは実行できる操作を定義する 「権限」です
読み取り権限や書き込み権限などです
先ほど述べたように Cloud Storageオブジェクトは不変です
必要であればバケットでオブジェクトのバージョニングを有効にできます
その場合 Cloud Storageは 変更履歴を保持します
つまり バケット内の全オブジェクトを 上書きまたは削除します
オブジェクトのアーカイブバージョンを 一覧表示して オブジェクトを前の状態に復元したり
完全にバージョンを削除したりできます
オブジェクトバージョニングを 有効にしていない場合は 新しいオブジェクトが常に 古いオブジェクトを上書きします
バージョニングは便利ですが ゴミが溜まるのが心配であれば
Cloud Storageの ライフサイクル管理ポリシーを使用するといいでしょう


Cloud Storageではストレージクラスを ４つの中から選択できます
Multi-RegionalとRegionalは 高パフォーマンスのオブジェクトストレージです
NearlineとColdlineは バックアップとアーカイブ用のストレージです
いずれのストレージクラスにも Cloud Storage APIで同じようにアクセスできすべてミリ秒単位でアクセス時間が計測されます
Regionalでは 特定のGCPリージョンにデータを保管できます
us-central1、europe-west1、 asia-east1のいずれかです
Multi-Regionalより安価ですが 冗長性は低くなります
Multi-Regionalでは料金は高くなりますが地理的冗長性が確保されます
米国、EU、アジアなどの大まかな 地理的ロケーションを選ぶと
Cloud Storageが160km以上離れた２か所の 地理的ロケーションにデータを保管します
Multi-Regionalが適しているのは 頻繁にアクセスするデータです
たとえば ウェブサイトのコンテンツや インタラクティブなワークロード モバイルアプリやゲームアプリの データなどです
Regionalが適しているのは Compute Engine、VM、Kubernetes Engine クラスタの近くにデータを保管する場合です
データ集約型の計算パフォーマンスが 向上するためです
Nearlineは安価で 耐久性に優れたサービスです アクセス頻度が低い データの保管に適しています
このストレージクラスが Multi-RegionalやRegionalよりも適しているのは データの読み取りや変更を行うのが 平均で月に１回以下の場合です
Coldlineは非常に安価な 耐久性に優れたサービスで データアーカイブ、オンラインバックアップ、障害復旧に適しています
Coldlineは年に１度程度しか アクセスしないデータの保管に最適です なぜなら可用性が若干低く 90日の最小保存期間があるからです
データアクセスに費用がかかり １オペレーションあたりの費用も高めです
たとえば データのアーカイブや 障害復旧での使用に適しています
可用性はストレージクラスによって異なります
最も高いのは可用性99.95％の Multi-Regionalです 次は可用性99.9％のRegionalです
NearlineとColdlineの可用性は99％です
料金については すべてのクラスで１か月あたりの データ保存量に対しGB単位で料金が発生します
料金が最も高いのは Multi-Regionalで 最も低いのはColdlineです
下りトラフィックと データ転送の料金がかかることもあります
これらの料金に加えて Nearlineではデータ読み取りにも GB単位の料金が発生します
ColdlineではGB単位の データ読み取り料金はさらに高くなります
どのストレージクラスでも 複数の方法でデータをCloud Storageに取り込めます
多くのお客様は gsutil(コマンドラインアプリ)を使用しています
これはCloud SDKに含まれる Cloud Storageコマンドです
Chromeブラウザを使用していれば GCP Consoleでドラッグ＆ドロップでの データ移動も可能です
テラバイトからペタバイト規模の データをアップロードする場合は
GCPのオンラインStorage Transfer Serviceと オフラインTransfer Applianceを利用できます
Storage Transfer Serviceでは別のクラウドプロバイダ、別のリージョン、 HTTPSエンドポイントから
Cloud Storageへの一括転送を スケジュールして管理できます
Transfer Applianceはラックマウント型の大容量ストレージ サーバーで Google Cloudからリースできます
ネットワークに接続してデータを読み込んでからアップロード施設に配送するだけでデータがCloud Storageにアップロードされます
このサービスを使えば１台の機器で最大１ペタバイトのデータを安全に転送できます
Cloud Storageにデータを格納する方法は他にもあります
このストレージはGCPの多数のプロダクトと サービスと密接に統合されているためです
たとえば BigQueryとCloud SQLとの間で テーブルをインポート、エクスポートできます
App EngineのログやCloud Datastoreのバックアップ App Engineで使用するイメージなどのオブジェクトも保管できます
他にもインスタンスの起動スクリプトや Compute Engineイメージ Compute Engineアプリの オブジェクトなども保管できます
つまりCloud Storageはクラウドへの データ取り込みポイントになり データを長期間保存する場所としても 頻繁に使用されています

Cloud Bigtableはビッグデータ用の NoSQLデータベースサービスです
リレーショナルデータベースは 各行に一連の同じ列があるテーブルの 集合だと考えてください
このルールと各テーブルに指定したルールを データベースエンジンが適用します
これはデータベーススキーマと呼ばれます
スキーマが大きな助けになるアプリもあれば大きな障害になるアプリもあります
一部のアプリではもっと柔軟な手法が必要です たとえば NoSQLスキーマです
すべての行に同じ列がある必要はありません
データベースによってはこれを活かすためにデータを低密度で行に取り込みます
これはNoSQLデータベースの特徴の１つです
Bigtableにもこの特徴があります
Bigtableは低密度に格納されるテーブルで
数十億行、数千列にスケールして 数ペタバイトのデータを保管できます
GCPのフルマネージドサービスなので構成や調整は不要です
Bigtableが適しているのは単一の参照キーを持つデータです
一部のアプリ開発者はBigtableを 永続ハッチテーブルとみなしています
Bigtableは極めて低いレイテンシで 大容量データを格納するのに最適です
高スループットの読み書きに対応するため運用アプリと分析アプリの両方に理想的です
Cloud BigtableはHBaseと同じ オープンソースAPIを介して提供されます
HBaseはApache Hadoopプロジェクトの ネイティブデータベースです
同じAPIを使用するということは HBaseとBigtableの間で アプリを移植できるということです
独自のApache HBaseインストール環境を 管理している場合 なぜBigtableを選択するのか 疑問に思うかもしれません
その理由をいくつか説明します まず スケーラビリティです
独自のHbaseインストール環境ではある時点で１秒あたりのクエリ数をスケールするのが難しくなります
Bigtableではマシンの数を増やすだけでスケールできます
ダウンタイムも必要ありません
またBigtableはアップグレードや再起動などの管理タスクを透過的に処理します
Bigtable内のデータはすべて処理中にも保存時にも暗号化されます
IAM権限を使用してBigtableデータにアクセスできるユーザーも制御できます
Bigtableは Googleの多くのコアサービスを 支えるデータベースです
Google検索、アナリティクス、 マップ、Gmailなどのサービスです
Cloud Bigtableは GCPエコシステムの一部であるため
他のGCPサービスや サードパーティクライアントと連携できます
アプリのAPIの観点から見ると Cloud Bigtableでのデータの読み書きは データサービス層で行えます
つまりマネージドVMやHBase RESTサーバーHBaseクライアントを使用する Javaサーバーなどで行えます
通常はここでアプリ、ダッシュボード、 データサービスにデータが提供されます
各種のストリーム処理フレームワークでデータをストリーミングすることも可能です
Cloud Dataflow Streaming、 Spark Streaming、Stormなどを使えます
ストリーミングできない場合は Hadoop Map/Reduce、Dataflow、Sparkで データの読み書きを一括処理できます
通常は 集約データおよび 新しく計算されたデータが Cloud Bigtableまたは 下流のデータベースに書き込まれます

リレーショナルデータベース  これらのサービスは データベーススキーマを使用して アプリのデータの 一貫性と正確性を保ちます
トランザクションに役立つことです
データベースの一連の変更をアプリで オールオアナッシングとして指定できます
変更はすべて成功か すべて失敗のどちらかです
データベーストランザクションがなければ オンラインバンクで 預金を口座間で移動できません
たとえば ある口座から １万ドルを引き出したのに なんらかの不具合で振替先口座に 預金が移動できなかったとしましょう
銀行が１万ドルを 誤って移動したからかもしれません
リレーショナルデータベースの 設定、保守、管理には手間がかかります
これらの作業に時間を取られたくないが リレーショナルデータベースによる保護は必要という場合は Cloud SQLを検討してください
このフルマネージドサービスでは MySQLまたはPostgreSQLの データベースエンジンを選択できます
Cloud SQLのMySQLとPostgreSQLのデータベースはどちらもテラバイト規模のデータを処理できます
Compute Engine VM内で 独自のデータベースサーバーを実行できます
GCPの多くのお客様がそうしています
一方で Cloud SQLマネージドサービスには いくつかの利点があります
まず Cloud SQLは 複数のレプリカサービスを提供します
リード、フェイルオーバー、 外部レプリカなどです
あるゾーンが停止状態になっても
Cloud SQLの自動フェイルオーバーによってゾーン間でデータをレプリケートできます
オンデマンドまたはスケジュール設定した
バックアップでデータをバックアップできます
マシンタイプの変更による垂直スケーリングと リードレプリカによる 水平スケーリングも可能です
セキュリティについては Cloud SQLインスタンスには ネットワークファイアウォールがあり
顧客データは Googleの内部ネットワーク上でも データベーステーブル、一時ファイル、 バックアップ内でも暗号化されます
Cloud SQLインスタンスのもう１つの利点は 他のGCPサービスや外部サービスから アクセスできることです
Compute Engineインスタンスに Cloud SQLインスタンスへのアクセスを許可して
VMと同じゾーン内で Cloud SQLインスタンスを構成できます
Cloud SQLはSQL WorkBenchや Toadなどのアプリやツールに加え 標準のMySQLドライバを使った 外部アプリにも対応しています
水平スケーリングが必要なため Cloud SQLで対応できない場合は Cloud Spannerを検討してください
グローバル規模のトランザクション整合性、 スキーマ、SQLを提供し 自動同期レプリケーションで 高可用性を実現します
ペタバイト規模の容量も提供できます
Cloud Spannerを検討するのは リレーショナルデータベースの 容量を超えた場合 高スループットを得るために
シャーディングする場合 トランザクションの整合性、 グローバルデータ、強整合性が必要な場合 データベースを強化する場合などです
金融アプリや在庫管理アプリなどの ユースケースに適しています

Cloud Datastore App Engineアプリの 構造化データの格納に使用されます
App EngineとCompute Engineをまたぐ ソリューションを構築する際に Cloud Datastoreを統合ポイントにできます
フルマネージドサービスなのでシャーディングとレプリケーションは自動処理されます
高可用性と耐久性を兼ね備えているため自動でスケールして負荷に対処します
Cloud Bigtableとは異なり複数のデータベース行を対象としたトランザクションも実行できます
SQLのようなクエリも可能です
Cloud Datastoreには １日の無料割り当てがあるので
保存、読み取り、書き込み、削除などの 小規模オペレーションを無料で行えます
Cloud Datastoreを検討するのは 非構造化オブジェクトを格納する場合
またはトランザクションとSQLに似た クエリのサポートが必要な場合です
このサービスは テラバイト規模の容量を提供します
最大ユニットサイズは エンティティあたり１MBです

Cloud Bigtableを検討するのは 大量の構造化オブジェクトを格納する場合
Cloud BigtableはSQLクエリも 複数行のトランザクションもサポートしません
このサービスは ペタバイト規模の容量を提供します 最大ユニットサイズは セルあたり10MB、行あたり100MBです

Cloud Storageを検討するのは 大きな画像や映画などの 10MGを超える不変blobを格納する場合です
このサービスは ペタバイト規模の容量を提供します
最大ユニットサイズは オブジェクトあたり５TBです

Cloud SQLまたはCloud Spannerを 検討するのはオンライントランザクション処理システムで 完全SQLサポートが必要な場合です
容量については Cloud SQLはテラバイト規模 Cloud Spannerはペタバイト規模です

Cloud SQLのリードレプリカで対応できない 水平スケーリングが必要な場合は
Cloud Spannerの使用を検討してください

通常 BigQueryにデータを格納する目的は ビッグデータ分析とインタラクティブな クエリや機能を使用するためです
BigQueryは オンラインアプリの バックアップ保存先などには適しません

Cloud Datastoreは 半構造化データの格納に最適です
つまり App Engineアプリで 使用するデータです

Bigtableは 読み書きの多い 分析データの格納に最適です AdTech、金融、IoTのデータなどです

Cloud Storageは構造化、非構造化、 バイナリ、オブジェクトデータに最適です 画像、大きなメディアファイル、 バックアップなどです

SQLはウェブフレームワークと 既存アプリでの使用に最適です
ユーザー認証情報や顧客の注文を 格納する場合などです

Cloud Spannerは２TBを超える 大規模なデータベースアプリに最適です
金融取引やeコマースの ユースケースなどに適しています

Compute Engineは GCPのIaaSサービスです
クラウドでVMを実行して 永続ストレージと ネットワーキングを使用します

App EngineはGCPのPaaSサービスです

Kubernetes Engine
インフラの面倒な作業を省けるという点では IaaSサービスと似ています
PaaSサービスにも似ています
IaaSサービスはコンピューティング リソースを共有可能にするために
ハードウェアを仮想化するということです
App Engineにデプロイする場合 アプリに必要なサービスファミリーにアクセスします
必要な作業は 該当するサービスを使用したコードと 自己完結型ワークロードを作成して
独立したライブラリを組み込むことだけです アプリの需要が増加すると
プラットフォームがアプリをシームレスにスケールします
ワークロードとインフラとは 別に行われます スケールは迅速に行われますが
基のサーバーアーキテクチャーはコントロールできません
そこで登場するのがコンテナです
コンテナとは PaaSのようなワークロードの独立した環境によるスケーラビリティと
IaaS環境のようなOSとハードウェアの 抽象化層を提供するものです
コンテナはコードとその依存関係が存在する 見えないボックスであり
ファイルシステムとハードウェアの 独自のパーティションにのみアクセスできます
Windows、Linux、その他のOSでは プロセスとは実行中プログラムの インスタンスのことです
コンテナは新しいプロセスとして 迅速に起動します
各ホストで必要なのはコンテナをサポートするOSとコンテナランタイムだけです
この環境はPaaSのようにスケールする一方 IaaSと同等の柔軟性を備えています
コンテナによる抽象化はコードの移植性を高めます
OSとハードウェアを ブラックボックスとして扱えるからです
コードを開発環境からステージ環境、本番環境に移行する際も
ノートパソコンからクラウドに移行する際も 変更したり再構築したりする必要はありません
Kubernetesを使用すると 多数のホスト上の多数のコンテナのオーケストレーション スケール、
新しいバージョンのロールアウト 以前のバージョンへのロールバックを 簡単に行えます


Kubernetesはオープンソースの コンテナオーケストレーターです アプリの管理とスケーリングに役立ちます
Kubernetesが提供するAPIでは 許可されたユーザーのみが 複数のユーティリティを使って そのオペレーションを制御できます
Kubernetesでは「クラスタ」という 一連のノードにコンテナをデプロイできます
クラスタとは マスターコンポーネントのセットで システム全体と コンテナを実行する 一連のノードをコントロールするものです
Kubernetesでは ノードとは コンピューティングインスタンスであり
Google Cloudでは ノードとは Compute Engine内で実行されるVMです
Kubernetesを使用する際は 一連のアプリとアプリ間の対話方法を記述すれば
それらの実行方法がKubernetesで自動的に識別されます
Kubernetesを使用すると 前のレッスンで作成したような コンテナ化アプリを簡単に実行できますが
Kubernetesクラスタは どのように取得するのでしょうか
いつでもハードウェア上で自分で作成できます
あるいはVMを提供する環境でも可能です
自分で作成した場合は保守が必要になります
これは大変な作業です 保守作業に追われるのは 有意義な時間の使い方ではないため
Google Cloudでは Kubernetes Engineを提供しています
クラウド内のマネージドサービスとしての Kubernetesです
これを使えばGCP Consoleで Kubernetesクラスタを作成できます
Cloud SDKに含まれる gcloudコマンドでも作成できます
GKEクラスタはカスタマイズできます
各種マシンタイプ、多数のノード、 ネットワーク設定がサポートされています
進捗状況はConsoleで確認できます
Kubernetesがコンテナや 一連の関連コンテナをデプロイするときは 常に「ポッド」という 抽象化層の中にデプロイします
ポッドはKubernetesの最小デプロイ単位であり クラスタで実行中のプロセスのようなものです
アプリの一部であることも アプリ全体であることもあります
通常は各ポッドに １つのコンテナをデプロイしますが 強い依存関係を持つコンテナが複数ある場合は
単一のポッドにパッケージ化できます
これらは自動的にネットワークを共有し 共通のディスクストレージ ボリュームを使用できます
Kubernetesの各ポッドにはコンテナ用に固有のIPアドレスとポートが割り当てられます
ポッド内のコンテナ同士はローカルホストネットワークインターフェースで通信するため
デプロイされているノードは認識されません
kubectl runコマンドを実行すると ポッド内の実行中コンテナで Deploymentが起動されます
この例のポッド内で実行されるコンテナは nginxオープンソース ウェブサーバーのイメージです kubectlコマンドによって
リクエストしたバージョンのnginxイメージが Container Registryから取得されます
Deploymentとは何でしょう Deploymentは 同じポッドの レプリカのグループを表します
ノードのいずれかで障害が発生しても ポッドの実行状態を保つことができます
Deploymentにはアプリの一部またはアプリ全体を含めることができます
この例では nginxウェブサーバーが含まれています 実行中のnginxポッドを表示するには 「kubectl get pods」コマンドを実行します
デフォルトではDeployment内のポッドには クラスタ内からしかアクセスできません
では nginxウェブサーバーの コンテンツへのアクセスを インターネット上の全員に 許可するには？
Deployment内のポッドを一般公開するには ロードバランサを接続します
kubectl expose」コマンドで接続します KubernetesでServiceを作成し
そこにポッドの固定IPアドレスを設定します Serviceとは Kubernetesで 負荷分散を表す基本手法です
つまり Kubernetesに対して パブリックIPアドレスで外部ロードバランサを Serviceに接続するように指定し
クラスタの外部から アクセスできるようにしています
GKEではこうしたロードバランサは ネットワークロードバランサとして作成されます
これはCompute EngineがVMに提供する
マネージド負荷分散サービスの１つです
GKEではコンテナで この負荷分散を簡単に使用できます
このIPアドレスにアクセスするクライアントは Service背後のポッドにルーティングされます
この例ではポッドは１つしかありません
シンプルなnginxポッドです ではServiceとは厳密には何でしょう
Serviceは一連のポッドをグループ化して 安定したエンドポイントを提供するものです
ネットワークロードバランサが 管理するパブリックIPアドレスです
ただし 他の選択肢もあります ではなぜServiceが必要なのでしょう
ポッドのIPアドレスを 直接使用できないのでしょうか たとえばアプリがフロントエンドと
バックエンドで構成されているとします フロントエンドからバックエンドには
ポッドの内部IPアドレスでアクセスできるので Serviceは不要なはずです
しかし管理の問題があります
Deploymentがポッドを作成して破棄すると
ポッドに固有のIPアドレスが割り当てられますが このアドレスは変わります
Serviceは安定したエンドポイントを提供します

Kubernetesでは「クラスタ」という 一連のノードにコンテナをデプロイできます
クラスタとは マスターコンポーネントのセットで システム全体と コンテナを実行する 一連のノードをコントロールするものです
Kubernetesでは ノードとは コンピューティングインスタンスであり
Google Cloudでは ノードとは Compute Engine内で実行されるVMです
Kubernetesを使用する際は 一連のアプリとアプリ間の対話方法を記述すれば それらの実行方法がKubernetesで自動的に識別されます
Kubernetesを使用すると 前のレッスンで作成したような コンテナ化アプリを簡単に実行できますが
Kubernetesクラスタは どのように取得するのでしょうか
いつでもハードウェア上で自分で作成できます あるいはVMを提供する環境でも可能です
自分で作成した場合は保守が必要になります これは大変な作業です
保守作業に追われるのは 有意義な時間の使い方ではないため Google Cloudでは Kubernetes Engineを提供しています
クラウド内のマネージドサービスとしての Kubernetesです
これを使えばGCP Consoleで Kubernetesクラスタを作成できます
Cloud SDKに含まれる gcloudコマンドでも作成できます
GKEクラスタはカスタマイズできます 各種マシンタイプ、多数のノード、 ネットワーク設定がサポートされています
GKEを使用してKubernetesクラスタを作成するコマンドの一例を紹介しましょう
「gcloud container clusters create k1」です このコマンドでは 「K1」というクラスタが作成されます
 すぐに使える構成済みのクラスタです 進捗状況はConsoleで確認できます
 Kubernetesがコンテナや 一連の関連コンテナをデプロイするときは 常に「ポッド」という 抽象化層の中にデプロイします
ポッドはKubernetesの最小デプロイ単位であり
クラスタで実行中のプロセスのようなものです
アプリの一部であることも アプリ全体であることもあります
通常は各ポッドに １つのコンテナをデプロイしますが
強い依存関係を持つコンテナが複数ある場合は 単一のポッドにパッケージ化できます
これらは自動的にネットワークを共有し 共通のディスクストレージ ボリュームを使用できます
Kubernetesの各ポッドにはコンテナ用に固有のIPアドレスとポートが割り当てられます
ポッド内のコンテナ同士はローカルホスト ネットワークインターフェースで通信するため
デプロイされているノードは認識されません
Kubernetesでポッド内のコンテナを 実行する１つの方法は「kubectl run」コマンドです
このコマンドを使えばすぐに開始できます kubectl runコマンドを実行すると
ポッド内の実行中コンテナで Deploymentが起動されます
この例のポッド内で実行されるコンテナは nginxオープンソース ウェブサーバーのイメージです
kubectlコマンドによって リクエストしたバージョンのnginxイメージが
Container Registryから取得されます
Deploymentとは何でしょう
Deploymentは 同じポッドの レプリカのグループを表します
ノードのいずれかで障害が発生しても ポッドの実行状態を保つことができます
Deploymentにはアプリの一部 またはアプリ全体を含めることができます
この例では nginxウェブサーバーが含まれています
実行中のnginxポッドを表示するには 「kubectl get pods」コマンドを実行します
デフォルトではDeployment内のポッドには クラスタ内からしかアクセスできません
ではnginxウェブサーバーの コンテンツへのアクセスを インターネット上の全員に 許可するには？
Deployment内のポッドを一般公開するには ロードバランサを接続します
「kubectl expose」コマンドで接続します KubernetesでServiceを作成し
そこにポッドの固定IPアドレスを設定します
Serviceとは Kubernetesで 負荷分散を表す基本手法です
つまり Kubernetesに対して パブリックIPアドレスで外部ロードバランサを
Serviceに接続するように指定しクラスタの外部からアクセスできるようにしています
GKEではこうしたロードバランサはネットワークロードバランサとして作成されます
これはCompute EngineがVMに提供する
マネージド負荷分散サービスの１つです
GKEではコンテナでこの負荷分散を簡単に使用できます
このIPアドレスにアクセスするクライアントは Service背後のポッドにルーティングされます
この例ではポッドは１つしかありません シンプルなnginxポッドです
ではServiceとは厳密には何でしょう
Serviceは一連のポッドをグループ化して安定したエンドポイントを提供するものです
この例では ネットワークロードバランサが 管理するパブリックIPアドレスです
他の選択肢もあります ではなぜServiceが必要なのでしょう
ポッドのIPアドレスを直接使用できないのでしょうか
たとえばアプリがフロントエンドと バックエンドで構成されているとします
フロントエンドからバックエンドには ポッドの内部IPアドレスでアクセスできるので Serviceは不要なはずです
しかし管理の問題があります Deploymentがポッドを作成して破棄すると
ポッドに固有のIPアドレスが割り当てられますが このアドレスは変わります
Serviceは安定したエンドポイントを提供します
Kubernetesについて学習を進めれば 内部のアプリバックエンドに適する 他のServiceタイプがわかってくるでしょう
「kubectl get services」コマンドで ServiceのパブリックIPアドレスを確認できます
クライアントはこのアドレスで リモートからnginxコンテナにアクセスできます 追加の処理能力が必要になったら
「kubectl scale」コマンドで Deploymentをスケールできます
この例のDeploymentには ３つのnginxウェブサーバーがあります いずれもServiceの背後にあり
１つの固定IPアドレスでアクセスできます 自動スケーリングでも 便利なパラメータを設定できます
たとえばCPU使用率に応じて Deploymentを自動スケールするとします
このコマンドでは 最小ポッド数を10に指定しています 最大ポッド数は15です
スケールアップの基準として CPU使用率が処理能力の80％に達した時点で
ポッド数をスケールアップします ここまでは 命令型コマンドの実行方法を説明しました
exposeやscaleなどです
命令型は Kubernetesの 段階的な学習やテストには役立ちますが
Kubernetesの真の強みは宣言型です
コマンドを実行する代わりに 構成ファイルを渡します
このファイルで目的の状態を指定すれば Kubernetesがその方法を判断します
こうした構成ファイルは管理ツールになります
変更を加えるには 構成ファイルを編集し 変更後のバージョンをKubernetesに提示します
スライドのコマンドは これまでの作業に基づく構成ファイルの 操作の開始点として使用できます
バージョン管理システムに保存して インフラの変更を追跡することもできます
この例のDeployment構成ファイルは nginxポッドのレプリカ数を ３として宣言しています
selectorフィールドを定義して 特定のポッドをレプリカとして グループ化する方法を指示しています
ポッドを特定できるのは ラベルが共有されているためです
該当するポッドのアプリには 「nginx」のラベルが付いています
３つではなく５つのレプリカを実行する場合 Deployment構成ファイルを編集して ３を５に変更するだけです
非常に柔軟です そして「kubectl apply」コマンドを実行して 更新後のファイルが使用されるようにします
「kubectl get replicasets」コマンドで レプリカを表示して更新後の状態を確認します
さらに「kubectl get pods」コマンドで ポッドがオンラインになるのを観察します この出力例では５つのポッドがすべて 実行状態になっています
現時点で GKEでは nginxポッドの５つのコピーが実行されていて １つのServiceで５つのポッドへの トラフィックをプロキシしています
Kubernetesではこの手法により 負荷を分散してServiceをスケールします
前のレッスンでは Pythonアプリをコンテナ化しました それをnginxに置き換えて
同じツールを使って デプロイとスケールを行えます 最後にアプリのバージョンを 更新する方法を説明します
コンテナを更新して新しいコードを できるだけ早く適用する必要があります
しかし すべての変更を一度に ロールアウトするのはリスクが伴います
アプリの再ビルドと再デプロイの間 ユーザーがダウンタイムを 経験するのは避けたいはずです
そのため Deploymentには 更新戦略という属性があります
これはローリングアップデートの例です Deploymentのローリングアップデートを選択して
管理対象ソフトウェアの 新しいバージョンを指定すると Kubernetesが新しいバージョンの
ポッドを１つずつ作成し 各ポッドが使用可能になるのを待ってから
古いバージョンのポッドを破棄します ローリングアップデートを使用すれば ダウンタイムを生じさせることなく
アプリのバージョンを迅速に更新できます

典型的なオンプレミスの 分散システムアーキテクチャを見てみましょう
クラウドが登場するまで 企業はこの方法で コンピューティングニーズに対応していました
ほとんどの企業向けアプリケーションは 分散システムとして設計されます
サービス提供に必要なワークロードが 複数のネットワークサーバーに分散されます
ワークロードをマイクロサービスに分割し 管理と拡張を容易にする方法として ここ数年でコンテナの人気が高まっています
従来 企業向けシステムとそのワークロードは コンテナ化の有無にかかわらず
オンプレミスに格納されてきました
つまり自社のネットワークやデータセンター内の 一連の大容量サーバー上に格納されていました
この場合 アプリのコンピューティングニーズに 利用可能なリソースで対応しきれなくなると より高性能なサーバーが必要になります
サーバーをインストールするには ネットワークの変更や拡張が必要です
新しいサーバーを構成して そこにアプリとその依存関係を読み込まなければ
リソースのボトルネックを解決できません
このようなオンプレミスの アップグレードを完了するには 数か月から１年以上かかることもあります
サーバーの平均耐用年数が３～５年であることを 考えるとかなりの費用がかかります
今すぐコンピューティング能力の 増強が必要な場合はどうでしょう
または 一部のワークロードを オンプレミスからクラウドに再配置して
コスト削減と高可用性を実現したい一方で オンプレミスネットワークから アプリを移行したくない場合はどうでしょう
クラウドでしか利用できない サービスが必要な場合はどうでしょう
そこで役立つのが最新のハイブリッド/ マルチクラウドアーキテクチャです
この方法ではシステムインフラの一部を オンプレミスに維持したまま 他の部分をクラウドに移行できます
したがってニーズに応じた 固有の環境を構築できます ご自分のペースで特定のワークロードだけを クラウドに移行できます
なぜなら完全に移行する必要はないからです
クラウドの柔軟性、スケーラビリティ、 コスト削減を実現しながら 移行を決めたワークロードを実行できます
機械学習、コンテンツキャッシュ、データ分析、 長期保存、IoTなどの専門サービスも リソースツールキットに追加できます
ハイブリッドアーキテクチャによる 分散システムとサービスの運用は 最近盛んに話題になっています
AnthosはGoogleの ハイブリッド/マルチクラウドソリューションで
分散システムとサービス管理ソフトウェアの 最新技術が採用されています
Anthosフレームワークの基盤となるのは オンプレミスのKubernetesと Google Kubernetes Engine（GKE）です
これをアーキテクチャの基盤として ポリシーベースのライフサイクルをサポートする
中央コントロールプレーンを介し ハイブリッド/マルチクラウド環境を一元管理します
Anthosにはアプリの整合性をモニタリングし 維持するためのツールも揃っているので
オンプレミス、クラウド、複数のクラウドでも ネットワーク全体で整合性を維持できます
Anthosで最新のハイブリッドインフラスタックを 段階的に構築してみます
ハイブリッドネットワークのクラウド側の GKEを見てみましょう
GKEはコンテナ化アプリをデプロイするためのマネージド型の本番環境です
高可用性とSLAによりシームレスに動作します
Certified Kubernetesが実行されるためクラウドとオンプレミス間を自由に移動できます
自動ノード修復、自動アップグレード、 自動スケーリングも組み込まれています
リージョンクラスタを使用するため複数のマスターで高可用性を維持します
複数のゾーン間でノードのストレージをレプリケートします
ハイブリッドネットワークのオンプレミス側にもGKEがデプロイされます
オンプレミス側のGKEは本番環境レベルのターンキーKubernetesでベストプラクティスの構成が事前に読み込まれています
Googleが検証、テストしたKubernetesの 最新リリースに簡単にアップグレードできます
GCP上のコンテナサービスにもアクセスできます
たとえばCloud Build、Container Registry、 監査ロギングなどです
Istio、Knative、Marketplaceの 各ソリューションも統合されます
クラウド環境とオンプレミス環境での Kubernetesのバージョンと操作は一貫しています
クラウドとオンプレミスのGKEはどちらも Marketplaceと統合するため
ネットワーク内のクラスタは オンプレミスでもクラウドでも コンテナ化アプリの 同じリポジトリにアクセスできます
これによりネットワークのどちら側でも 同じ構成を使用できるためアプリの開発時間が短縮されます
正しい構成をどこにでもレプリケートしてクラスタ間の整合性を維持できます
アプリで何百ものマイクロサービスを使用してワークロードを処理することもあります
これだけの数のサービスを追跡して 正常性をモニタリングするのは至難の業です
AnthosはIstioオープンソースサービスメッシュとして勘に頼った判断をマイクロサービスの管理とセキュリティから完全に排除します
サービスメッシュのレイヤはハイブリッド ネットワークと通信する際にCloud Interconnectで データを同期して渡します
StackdriverはGogle Cloudに組み込まれた ロギングとモニタリングのソリューションです
完全に管理されたロギング、指標の収集、 モニタリング、ダッシュボード、アラートにより
ハイブリッド/マルチクラウドネットワークの あらゆる側面を監視します
簡単に構成できて高性能なクラウドベース可観測性ソリューションをお求めの場合Stackdriverが最適です
１つのダッシュボードですべての環境をモニタリングすることも可能です
最後に Anthos Configuration Managementはクラスタ構成の信頼できる唯一の情報源を提供します
この情報源が保持されるポリシーリポジトリは 実際にはGitリポジトリです
この図のリポジトリは オンプレミス側にありますが クラウドでホストすることもできます
Anthos Configuration Managementエージェントは ポリシーリポジトリを使って
各環境でローカルに構成を適用することで複数の環境でクラスタを所有する際の複雑さを省きます
Anthos Configuration Managementでは管理者とデベロッパー向けに
単一のリポジトリコミットでコード変更をデプロイする機能も提供しています
名前空間による構成の継承も実装できます

Compute EngineとKubernetes Engine
この２つの共通点はアプリを実行する インフラを選択できることです
Compute EngineではVM
Kubernetes Engineでは コンテナを基に選択します
 しかし インフラを 気にしたくない場合もあります コードのみに集中したい場合です
 そのためにあるのがApp Engineです
 PaaSは 「サービスとしてのプラットフォーム
 App Engineプラットフォームが コードの実行に必要なハードウェアとネットワークインフラを管理します
App Engineにアプリをデプロイするには コードを提供するだけです
残りの処理はApp Engineが行います
App Engineには多くのウェブアプリに必要なサービスが組み込まれています
NoSQLデータベース、インメモリキャッシュ、 負荷分散、ヘルスチェック、ロギング ユーザー認証機能などです
これらのサービスを利用する アプリコードを作成すれば App Engineがサービスを提供します
App Engineは受信トラフィック量に応じて アプリを自動的にスケールします
料金は使用したリソースの分だけです サービスのプロビジョニングや保守も不要です
したがってApp Engineは ワークロードが変動しやすいか予測できない
ウェブアプリやモバイルバックエンドに 特に適しています
App Engineにはスタンダード環境と フレシキブル環境の２つがあります

シンプルなのはスタンダード環境です フレキシブル環境よりもデプロイが簡単できめ細かい自動スケーリングが可能です
どちらの環境でも 一部のサービスに １日の無料割り当て使用量が設定されています
しかしスタンダード環境の特徴は 使用量の少ないアプリは 無料で実行できる場合があることです
GoogleではApp Engineソフトウェア開発 キットを複数言語で提供しているため
アプリをローカルでテストしてから App Engineサービスにアップロードできます
SDKには単純な デプロイコマンドも含まれています コードは実際にどこで実行されるのでしょうか
実行可能バイナリとは 何を意味するのでしょうか
App Engineではこのバイナリを「ランタイム」と呼びます
スタンダード環境ではGoogle提供のランタイムを使用します
選択肢について説明します
App Engineスタンダード環境で 使用できるランタイムは
特定のバージョンの Java、Python、PHP、Goです
ランタイムにはApp Engine API対応の ライブラリも組み込まれています
多くのアプリでは スタンダード環境のランタイムと ライブラリだけで十分です
他の言語でコードを作成する場合 スタンダード環境は適しません
フレキシブル環境をご検討ください
スタンダード環境ではコードの制限があり
サンドボックスでコードが実行されます
これはハードウェア、OS、物理的なサーバーの 場所に依存しないソフトウェア構成概念です
このサンドボックスこそが スタンダード環境でアプリをきめ細かく
スケールして管理できる理由の１つです
通常 サンドボックスには いくつかの制約があります
たとえば アプリは ローカルファイルシステムに書き込めません
データを存続させるには データベースサービスに書き込む必要があります
また アプリが受信するすべてのリクエストは 60秒でタイムアウトします
任意のサードパーティソフトウェアは インストールできません
以上の制約が問題になる場合は フレキシブル環境を選択してください
これはApp Engineスタンダード環境の 使用方法を示す図です
App Engine SDKを使ってアプリを開発し テストバージョンをローカルで実行します
準備ができたら SDKを使用して アプリをデプロイします
各App Engineアプリは GCPプロジェクト内で実行されます
App Engineが自動的にサーバーインスタンスを
プロビジョン、スケール、負荷分散します 一方 アプリは専用のAPIを使って
各種サービスを呼び出すことができます
たとえば データを保持するNoSQLデータストア
そのデータをキャッシュするMemcache 検索、ロギング、ユーザーログイン ユーザーリクエスト以外によって
アクションを開始できる タスクキューやタスクスケジューラなどです

スタンダード環境のサンドボックスモデルの制約がネックになっているとします
それでもApp Engineを利用したい場合 App Engineフレキシブル環境があります
App Engineフレキシブル環境では サンドボックスではなく App Engineを実行するコンテナを指定します
アプリはCompute EngineのVM上の Dockerコンテナ内で実行されます
App Engineが Compute Engine VMを管理します
ヘルスチェックを行い 必要に応じて修復します
VMを実行する地理的リージョンは ユーザーが選択します
さらに下位互換性を維持するための重要なOS更新も自動的に適用されます
その結果ユーザーはコードに集中できます
App Engineフレキシブル環境のアプリは
標準ランタイムを使用し App Engineのデータストア、Memchach、タスクキューなどのサービスにアクセスできます
スタンダード環境のほうがアプリのインスタンスを短時間で起動できます
ただしアプリを実行するインフラへの アクセスは制限されます
フレキシブル環境では アプリを実行するVMにSSHで接続できます
ローカルディスクへの書き込みが可能です
サードパーティソフトウェアも インストールできます
アプリがApp Engineを介さずに ネットワークを呼び出すことも可能です
スタンダード環境では アプリが完全にアイドル状態であれば 請求料金はゼロになります
前述のようにApp Engineは Dockerコンテナを使用するため
App EngineとKubernetes Engineの 違いも気になると思います
App Engineスタンダード環境は アプリのデプロイとスケーリングを 最大限コントロールしたい場合に適しています
Kubernetes Engineではアプリオーナーは Kubernetesの柔軟性を活用できます
App Engineフレキシブル環境は これらの中間に位置するものです
App Engine環境ではコンテナを 目的を達成する手段として扱いますが Kubernetes Engineでは コンテナは構築の基盤になります

ソフトウェアサービスの実装は 複雑で変わりやすいものです
たとえば 他のソフトウェアが そのサービスを利用するたびに
その動作を詳細に知る 必要があるとしたら非常に面倒です
そのためアプリデベロッパーは ソフトウェアを構造化して 簡潔で明快なインターフェースで 不要な詳細を抽象化し その情報をドキュメント化します
これがAPIです APIが変更されない限り 基盤となる実装はいくらでも変更できます
APIを利用している他のソフトウェアがその変更を知る必要はありません
機能の追加や廃止のためにAPIの変更が必要になることもあります
こうしたAPIの変更を適切に行うため デベロッパーはAPIのバージョン管理を行います
バージョン２のAPIにバージョン１にはない呼び出しが含まれるとします
このAPIを利用するプログラムでは呼び出しの際にAPIバージョンを指定できます
APIへの対応は非常に重要です GCPには２つのAPI管理ツールが用意されています
問題に対してのアプローチが異なりそれぞれの長所があります
ソフトウェアサービスとGCPのバックエンドを開発しているとします
APIを簡単に公開して信頼できるデベロッパーのみに使用してもらいたいと考えています
使用状況を監視して記録する
APIが呼び出し側のエンドユーザーを把握するための統一的な方法も必要です
そこで役立つのがCloud Endpointsです Cloud Endpointsでは簡単にデプロイできる
プロキシを使用して必要な機能を実装できます
さらにAPIコンソールの使いやすい インターフェースで機能を管理できます
Cloud EndpointsはGCPで実行される
アプリをサポートします アプリで使用している言語やクライアントテクノロジーは問いません
Apigee EdgeもAPIプロキシを 開発、管理するためのプラットフォームです
ただし位置付けが異なります レート制限、割り当て、分析などの ビジネス的な問題に重点を置いています
Apigee Edgeの多くのユーザーは 他社にソフトウェアサービスを提供しているため
こうした機能が重要になります Apigee EdgeはGCP外部の バックエンドサービスにも対応するため
エンジニアがレガシーアプリを 「分解」するときによく使われます
モノリシックアプリを 一度に移行することはリスクがありますが
Apigee Edgeを使用すれば サービスを１つずつ分離し レガシーアプリが完全に使用されなくなるまで
マイクロサービスに分解して 順番に実装することができます

開発、デプロイ、モニタリング用の 一般的なツールはGCPでも機能します
GCPに密接に統合されているツールも使用できます
GCPの多くのお客様はGitを使用して ソースコードツリーを保管、管理しています
独自のGitインスタンスを実行するかホスト型Gitプロバイダを使用しています
独自のインスタンスの利点は完全な制御です
ホスト型Gitプロバイダの利点は作業負担の軽減です
３つ目の手段としてコードの公開をGCPプロジェクトに限定してIAM権限で保護しながら
Gitインスタンスの保守を省けるとしたらどうでしょう
その手段がまさにCloud Source Repositoriesです
Gitバージョン管理によってチームによるアプリやサービスの開発をサポートします
App Engine、Compute Engine、Kubernetes Engineで実行するアプリなどです
Cloud Source RepositoriesではプライベートGitリポジトリをいくつでも使用できるので
クラウドプロジェクトの関連コードを任意の方法で整理できます
Cloud Source Repositoriesにはソースビューアもあります
GCP Console内からリポジトリのファイルを参照して表示できます
多くのアプリにはイベントで駆動される部分があります
たとえばユーザーが画像をアップロードできるアプリではアップロードのたびに画像を複数の方法で処理する必要があります
標準の画像形式に変換し複数のサムネイルを作成してサイズ別にリポジトリに保管するなどです
このような関数はアプリに統合できますがそれを処理するコンピューティングリソースが必要です
必要な画像処理を行う単一目的の関数を作成するだけで画像がアップロードされるたびに自動的に実行されると便利です
それを可能にするのがCloud Functionsです
サーバーやランタイムバイナリを気にする必要はありません
GCPのNode.js環境対応のコードをJavaScriptで作成して起動の条件を構成するだけです
サーバーの使用料金は不要です関数の実行時間分の料金を100ミリ秒単位で支払うだけです
Cloud Functionsのトリガーの基準は Cloud Sotrage、Cloud Pub/Sub、HTTP呼び出しのイベントです
Cloud Functionを設定するには まず対象のイベントを選択します
Cloud Functionsに各イベントタイプを指示します
この宣言は「トリガー」と呼ばれます
次に JavaScript関数をトリガーに関連付けます
以降は該当するイベントが発生するたびに関数が応答します
マイクロサービスアーキテクチャを使用するアプリなどは Cloud Functions内で完全に実装できます
Cloud Functionsは既存のアプリを拡張するためにも使用されています スケーリングの心配がなくなります


命令型アプローチではこれらを手動で行います
つまり意図した環境を設定するためのコマンドを見つける必要があります環境に変更を加える場合は
新しい状態に変更するためのコマンドを見つけます
環境のクローンを作成するにはすべてのコマンドを再び実行します
これは大変な作業です
テンプレートを使用したほうが効率的ですテンプレートとは目的とする環境の仕様です
命令型に対して宣言型の方法です
GCPのDeployment Managerではこれが可能です
このインフラ管理サービスはGCPリソースの作成と管理を自動化します
これを使用するにはテンプレートファイルを作成しYAMLマークアップ言語またはPythonを使用して環境に必要なコンポーネントを記述します
そのテンプレートをDeployment Managerに渡すと記述された環境の作成に必要なアクションが判断され実行されます
環境を変更する場合はテンプレートを編集し環境を更新するようDeployment Managerに指示します
テンプレートを保管して バージョン管理するには Cloud Source Repositoriesを利用します

モニタリングによりアプリに加えた変更の有効性を判断できます
アプリがダウンしたと苦情が来ても情報をもとに落ち着いて対処できます
Stackdriverはモニタリング、 ロギング、診断用のGCPツールです
Stackdriverでは 各種シグナルにアクセスできます
インフラプラットフォーム、 VM、コンテナ、ミドルウェア アプリ層、ログ、指標、 トレースなどのシグナルです
アプリの正常性、パフォーマンス、 可用性の分析情報を取得できます
Stackdriverのコアコンポーネントは Monitoring、Logging、Trace、 Error Reporting、Debuggingです
Stackdriver Monitoringがチェックするのは クラウド環境内のウェブアプリや インターネットでアクセスできる
その他のサービスのエンドポイントです
稼働時間チェックを構成して URL、グループのほか インスタンスや ロードバランサなどのリソースを関連付けます
基準に基づくアラートも設定できます
アクションが必要なヘルスチェック結果や稼働時間の減少などの基準です
Monitoringは多数の通知ツールと 組み合わせて使用できます
アプリの状態を可視化する ダッシュボードも作成できます
Loggingではアプリのログを 表示、フィルタ、検索できます
ログの内容に基づく指標を定義して ダッシュボードとアラートに 統合することもできます
ログはBigQuery、Cloud Storage、 Cloud Pub/Subにエクスポートできます
Error Reportingは アプリのエラーを追跡、グループ化し 新しいエラーが検出されると通知します
TraceではApp Engineアプリの レイテンシを抜き出して URLごとの統計レポートを作成できます
Debuggerでは別の方法を使用できます
アプリの本番環境データを ソースコードに関連付けて 本番環境の任意のコード位置でアプリの状態を調べられるようにします
したがってログステートメントを 追加しなくてもアプリの状態を確認できます
Debuggerが本領を発揮するのは アプリのソースコードが使用できる場合です
したがって Cloud Source Repositoriesなどの リポジトリにコードを保管すると役立ちます


Google Cloudの ビッグデータソリューションは 有用なデータ分析情報によってビジネスと ユーザーエクスペリエンスを変革します
Googleではこれを「統合サーバーレス プラットフォーム」と呼んでいます
つまり「サーバーレス」とはジョブを実行するインスタンスのプロビジョニングが不要ということです
フルマネージドサービスで かかるのはリソース使用分の料金だけです
プラットフォームは統合型です
Apache Hadoopはビッグデータ対応のオープンソースフレームワークです
ベースとなるのはGoogleが開発したMapReduceプログラミングモデルです(reduce　減らす)
MapReduceモデルの最もシンプルな形では 「map関数」と呼ばれる関数が並行して膨大なデータセットを処理し
それぞれに中間結果を生成します
そして別の「reduce関数」という関数がすべての中間結果に基づいて最終的な結果セットを生成します
「Hadoop」という用語は Apache Hadoop自体と関連プロジェクトの総称としてよく使用されます
Apache Spark、Apache Pig、 Apache Hiveなどのプロジェクトです
Cloud Dataprocという高速で使いやすいマネージドサービスを使用すると
Hadoop、Spark、Hive、Pigを GCP上で実行できます
Hadoopクラスタをリクエストするだけで90秒以内にクラスタが自動作成されます
クラスタを構成するCompute Engine VMの 数とタイプは指定できクラスタの実行中に
処理能力を増減する必要がある場合はスケールアップまたはダウンできます
クラスタではHadoopソフトウェアのデフォルト構成を使用することも構成をカスタマイズすることもできます
さらにStackdriverでクラスタをモニタリングできます
Hadoopジョブをオンプレミスで実行する場合はハードウェアへの資本投資が必要です
Cloud Dataprocで実行すればクラスタの存続中に使用したハードウェアリソースの料金を支払うだけです
料金設定は時間単位ですがCloud Dataprocの課金は秒単位です
すべてのCloud Dataprocクラスタは 秒単位で課金されます
最小課金時間は１分です クラスタを使い終わって削除すれば 課金は停止されます
オンプレミスのハードウェア資産よりも 俊敏にリソースを使用できます
費用を節約するためにCloud Dataprocでの一括処理に プリエンプティブルCompute Engine インスタンスを使用することもできます
終了されても正常に再起動できるジョブであればこの方法でインスタンスの費用を大幅に削減できます
Dataprocクラスタの費用に含まれるのはインスタンスの費用だけではありませんがかなりの部分を占めます
データがクラスタに取り込まれたらSparkとSpark SQLを使用して データマイニングを行えます
MLibというApache Sparkの 機械学習ライブラリを使用して 機械学習でパターンを検出することもできます

Cloud Dataprocが役立つのはデータセットのサイズが明らかな場合やクラスタサイズを自分で管理する場合です
一方リアルタイムのデータやデータのサイズとレートが予測できない場合はCloud Dataflowが最適です
この統合プログラミングモデル （マネージドサービス）を使えば 広範なデータ処理パターンを 開発して実行できます
抽出、変換、読み取り（ETL）から、 バッチ計算、連続計算にまで対応します
Dataflowで作成するデータパイプラインは バッチデータとストリーミングデータの 両方に適用できます
クラスタの起動も インスタンスのサイズ変更も不要です
処理に必要なリソースが何であれCloud Dataflowがリソース管理を完全に自動化します
Cloud Dataflowを使用すればリソース管理やパフォーマンス最適化などの作業から解放されます
この例のDataflowパイプラインでは「ソース」で BigQueryテーブルからデータを読み込み
「変換」で各種の方法でデータを処理し「シンク」で出力をCloud Storageに書き込んでいます
変換にはMapオペレーションとReduceオペレーションがあり
非常に高機能なパイプラインを構築できます
パイプラインの各ステップは 柔軟にスケールされます
クラスタの起動や管理は不要です
このサービスがすべてのリソースをオンデマンドで提供します
最適化された組み込みの自動パーティショニング機能により遅れている作業が動的に再調整されるためホットキーに関する懸念が減ります
過度に大きい入力チャンクが 同じクラスタにマップされるといった懸念です
Dataflowはさまざまな ユースケースで使用されます
前述のとおり これは汎用のETLツールです
さらにデータ分析エンジンとして使用するとさまざまな分野で役立ちます
たとえば不正検出、金融サービス、IoT分析、製造 ヘルスケア、ロジスティクス、クリックストリーム
小売業のPoSや セグメンテーション分析などです
パイプラインは外部サービスを含む 複数のサービスをオーケストレートできるため
パーソナライズされたゲーム体験などを 提供するリアルタイムアプリに使用できます

動的パイプラインではなく膨大なデータを探索してデータを実行したいとします
膨大なデータセットに対する アドホックSQLクエリが必要です
これを可能にするのがBigQueryです
ペタバイト規模で低料金のフルマネージド分析データウェアハウスです
インフラの管理は不要なので 有用な情報を見つけるための データ分析に専念できます
使い慣れたSQLを使えるだけでなく従量課金制モデルを利用できます
BigQueryにデータを取り込むのは簡単です
Cloud Storageや Cloud Datastoreから読み込んだり
BigQueryに1秒あたり最大10万行をストリーミングしたりできます
BigQuery内の数テラバイトのデータに対して わずか数秒でSQLクエリを実行できます
Googleインフラの処理能力を利用するからです
さらにCloud Dataflow、Hadoop、Sparkを使ってBigQuery内のデータを簡単に読み書きできます
BigQueryはスタートアップ企業から Fortune 500企業まで あらゆる組織で使用されています
小さな組織では 毎月の無料割り当てが 大きな組織では シームレスなスケーリングと 可用性99.9％のSLAが好評です
Googleのインフラと同じく BigQueryもグローバルです
BigQueryではデータを保持する リージョンを指定できます
たとえばデータをヨーロッパで保持する場合 ヨーロッパにクラスタを設定する必要はありません
データセットを作成する EUロケーションを指定するだけです
USとアジアのロケーションも選択できます BigQueryではストレージと 計算処理が分離されるため
クエリとデータストレージの 料金は別々に支払います
つまり クエリの料金を支払うのは 実際に実行しているときだけです
BigQuery内のデータへの ユーザーアクセスを完全に制御でき
プロジェクト間での データセットの共有も制御できます
料金やパフォーマンスに影響しない データセットを共有した場合
共有相手が実行したクエリの料金は 共有相手が支払います
BigQueryに長期間保存されているデータには長期保存割引料金が自動的に適用されます
データの保存期間が90日に達すると 自動的にストレージ料金が引き下げられます

リアルタイムのイベントを扱うときは メッセージングサービスが役立ちます
Cloud Pub/Subです ストリーム分析のための シンプルで信頼性の高いスケーラブルな基盤です
これを使えば 構築した個別のアプリ間で メッセージを送受信できます
アプリが分割されるため 独立してスケールできます
Pub/Subの「Pub」はパブリッシャーの略、 「Sub」はサブスクライバーの略です
アプリがメッセージをパブリッシュすると １つ以上のサブスクライバーが受信します
メッセージの受信は必ずしも 同期する必要はありません そのためPub/Subはシステムを分離するのに便利です
「at least once」（最低 １ 回）の 配信を低レイテンシで行う設計になっています
「at-least-once配信」とは メッセージが複数回配信される可能性が
 わずかにあることを意味します アプリの作成時は この点に注意してください
Cloud Pub/Subはオンデマンドでスケールし １秒あたり100 万件以上の メッセージを処理できます
IoTシステムなどです ストリーミングデータを分析する場合 Cloud DataflowとPub/Subを 組み合わせて使用できます
GCPのコンピューティングプラットフォームで 構築されたアプリにも使用できます
サブスクライバーを構成してpushまたはpullベースでメッセージを受信します
つまり サブスクライバーが 新着メッセージの通知を受けるようにするか
定期的に新着メッセージを確認するように構成できます
ノートブックのホスト環境として 一般的なのはProject Jupyterです
Pythonコードを含むウェブベースの ノードブックを作成して保守できるので
インタラクティブにコードを実行して 結果を確認できます Cloud Datalabはこの自然な手法から 管理作業を取り除きます
Compute Engine VM内で稼働するからです
Cloud Datalabを使うには VMのタイプと VMを実行するGCPリージョンを指定します
Datalabを起動すると すぐに使える インタラクティブなPython環境が提供されます
複数のGCPサービスが自動的にオーケストレートされるのでデータの探索に専念できます
料金は使用したリソースの分だけです
Datalab自体の追加料金はありません
BigQuery、Compute Engine、 Cloud Storageと統合されているため
データにアクセスする際の認証の煩わしさはありません
稼動中はGoogle Chartsでデータを可視化したり 線グラフを描画したりできます
活発なPythonコミュニティの公開ノートブックで 学習することもできます
統計や機械学習などに対応する 多数のパッケージもあります

機械学習（ML）を使用している主要なGoogleアプリには YouTube、フォト、Googleモバイルアプリ、 Google翻訳などがあります
Google MLプラットフォームがクラウドサービスとして提供されているので
革新的な機能を独自のアプリに追加できます
Cloud Machine Learning Platformは最新のMLサービスを提供します
事前トレーニング済みモデルを備え カスタムモデルも生成できます
他のGCPサービスと同様にサービスの幅は広く汎用サービスからカスタマイズ済みのサービスまであります
TensorFlowという オープンソースのソフトウェアライブラリは ニューラルネットワークなどのMLアプリで 並外れた効果を発揮します
これはGoogle Brainが社内用に開発し世界に役立つようオープンソース化したものです
TensorFlowはどこでも実行できますが理想的な場所はGCPです
MLモデルには大量のオンデマンドリソースとトレーニングデータが必要だからです
TensorFlowでは Tensor Processing Unit（TPU）も利用できます
これはTesorFlowでのMLワークロードを加速化できるハードウェアデバイスです
GCPではCompute Engine VMを使って クラウドでTPUを利用できます
Cloud TPU１個あたりのパフォーマンスは 最大180 TFLOPSです
料金は使用した分だけなので先行資本投資は不要です
より高レベルな マネージドサービスが必要な場合はGoogle Cloud Machine Learning Engineを
使用すればサイズを問わずあらゆるデータのMLモデルを簡単に構築できます
任意のTensorFlowモデルを使用して大規模なトレーニングをマネージドクラスタ上で行えます
アプリにさまざまなML機能を追加したいが機能の細々とした仕組みについては気にしたくない場合は
Google Cloudの特定の目的用の一連のML APIを利用することができます
これについては後ほど説明します
Cloud Machine Learning Platformはさまざまなアプリに使用されています
用途には主に２つのカテゴリがあります
構造化データの処理と非構造化データの処理です
構造化データを処理する場合 MLを使用して各種の分類タスクと回帰タスクを行うことができます
顧客離れ分析、 製品の診断、予測などです
レコメンデーションエンジンの中心としてコンテンツのパーソナライズ、クロスセルアップセルに対応できます
MLを使って不正検出、センサー診断、 ログ指標で異常を検出することも可能です
非構造化データを処理する場合 MLを画像分析に使用して 配送品の損傷やスタイルの識別、
コンテンツの報告などを行えます。テキスト分析にも使用できます。
コールセンター、ブログ分析、言語の識別、 トピックの分類、感情分析などです
とりわけ革新的なMLアプリの多くはこうした複数のアプリを組み合わせたものです
ある顧客が SNS で あなたの商品に好意的な投稿をした際にアプリが自動的にその顧客に連絡して
顧客が好みそうな別の商品の割引を提示したとしたらどうでしょう
Google Cloud Machine Learning Platformでは こうした双方向性を簡単に実現できます

Cloud Vision APIを使用して 画像の内容を理解することができます
このAPIは画像を何千ものカテゴリに高速で分類します
ヨット、ライオン、エッフェル塔などに分類して 画像内の個々の物体を検出したり
画像内の印刷文字を見つけて読み上げたりできます
ここで取り上げる他のAPIと同じように使いやすいAPIの背後には高度なMLモデルが組み込まれています
このAPIを使用して画像カタログのメタデータの作成不適切なコンテンツの管理画像の感情分析を行えます
Cloud Speech APIで音声をテキストに変換できます
グローバルなユーザーベースに対応するためこのAPIは80を超える言語と方言を認識します
アプリのマイクで入力された音声の文字起こしや音声コマンドコントロールの有効化、
音声ファイルの文字起こしが可能です
Cloud Natural Language APIは 自然言語を理解するためのさまざまなテクノロジーを提供します
各トークンで名詞、動詞、形容詞などの 品詞を識別して単語間の関係を把握します
エンティティ認識も可能です
テキストを解析して 人、組織、場所、イベント、商品、 メディアの言及にフラグを立てます
テキストブロックで表現されている 感情を総合的に読み取ることもできます
これらの機能は英語、スペイン語、日本語など 複数の言語で使用できます
Cloud Translation APIを使ってシンプルでプログラム可能なインターフェースで任意の文字列を
サポートされている言語に翻訳できます
原文の言語が不明でもAPIが特定できます
Cloud Video Intelligence APIは各種形式の動画にアノテーションを
付け動画内の主要エンティティ（名詞）を識別し それらが出現するタイミングを特定できます
このAPIを使用すれば動画コンテンツの 検索と検出が可能になります
